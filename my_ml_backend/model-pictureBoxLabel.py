from typing import List, Dict, Optional
import json
import os
import base64
from openai import OpenAI
from label_studio_ml.model import LabelStudioMLBase
from label_studio_ml.response import ModelResponse


# ==================== å¤šæ¨¡æ€å¯¹è±¡æ£€æµ‹é…ç½® ====================
# æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
SUPPORTED_IMAGE_FORMATS = ['jpg', 'jpeg', 'png', 'gif', 'webp', 'bmp']

# Label Studio åª’ä½“ç›®å½•é…ç½®
# å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡ LABEL_STUDIO_MEDIA_DIR è®¾ç½®
LABEL_STUDIO_MEDIA_DIR = os.getenv('LABEL_STUDIO_MEDIA_DIR', r'C:\Users\Administrator\AppData\Local\label-studio\label-studio\media')

# å¯¹è±¡æ£€æµ‹ä»»åŠ¡é…ç½®
OBJECT_DETECTION_CONFIG = {
    "task_type": "ç¾å®³å›¾ç‰‡å¯¹è±¡æ£€æµ‹æ ‡æ³¨",
    "model_type": "å¤šæ¨¡æ€è§†è§‰è¯­è¨€æ¨¡å‹", 
    "output_format": "çŸ©å½¢æ¡†æ ‡æ³¨",
    "language": "ä¸­æ–‡",
    "max_tokens": 1000,
    "temperature": 0.7,
    "labels": [
        "disaster-causing-factor",      # è‡´ç¾å› å­
        "disaster-victims",            # å—ç¾ä½“
        "Pregnancy-disaster-environment" # å­•ç¾ç¯å¢ƒ
    ]
}


class NewModel(LabelStudioMLBase):
    """Custom ML Backend model for object detection
    """
    
    def setup(self):
        """Configure any parameters of your model here
        """
        print(f"\nğŸš€ ç¾å®³å¯¹è±¡æ£€æµ‹ML Backendå¯åŠ¨ä¸­...")
        
        self.set("model_version", "1.0.0-detection")
        
        # é­”å¡”ç¤¾åŒºAPIé…ç½®
        self.api_key = os.getenv('MODELSCOPE_API_KEY', 'ms-d200fd06-f07f-4be8-a6a8-9ebf76dd103a')
        self.api_base_url = os.getenv('MODELSCOPE_API_URL', 'https://api-inference.modelscope.cn/v1')
        # å¤šæ¨¡æ€æ¨¡å‹é…ç½®
        # Qwen/Qwen2.5-VL-72B-Instruct - å¤šæ¨¡æ€è§†è§‰è¯­è¨€æ¨¡å‹ï¼Œæ”¯æŒå›¾ç‰‡ç†è§£å’Œå¯¹è±¡æ£€æµ‹
        self.model_name = "Qwen/Qwen2.5-VL-72B-Instruct"  # å¤šæ¨¡æ€å¯¹è±¡æ£€æµ‹æ¨¡å‹
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        if self.api_key:
            try:
                self.client = OpenAI(
                    base_url=self.api_base_url,
                    api_key=self.api_key
                )
                print(f"âœ… æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ: {self.model_name}")
            except Exception as e:
                print(f"âŒ å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
                self.client = None
        else:
            print(f"âš ï¸ è¯·è®¾ç½®MODELSCOPE_API_KEYç¯å¢ƒå˜é‡")
            self.client = None
        
        # æ£€æŸ¥APIè¿æ¥
        self._check_api_connection()
        
    def _check_api_connection(self):
        """æ£€æŸ¥é­”å¡”ç¤¾åŒºAPIè¿æ¥"""
        if not self.client:
            print(f"âŒ å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            return
        
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[{"role": "user", "content": "test"}],
                max_tokens=5,
                temperature=0.1
            )
            print(f"âœ… APIè¿æ¥æˆåŠŸ")
        except Exception as e:
            print(f"âŒ APIè¿æ¥å¤±è´¥: {str(e)[:100]}")
    
    def _convert_local_path_to_base64(self, file_path: str) -> Optional[str]:
        """å°†æœ¬åœ°æ–‡ä»¶è·¯å¾„è½¬æ¢ä¸ºbase64æ ¼å¼çš„æ•°æ®URL"""
        
        # è·å–ç›®å½•ä¿¡æ¯
        current_dir = os.getcwd()
        parent_dir = os.path.dirname(current_dir)
        grandparent_dir = os.path.dirname(parent_dir)
        
        # å°è¯•è·¯å¾„è§£æ - ä¸“æ³¨äºLabel Studioåª’ä½“ç›®å½•
        possible_paths = []
        
        # 1. Label Studio å®é™…åª’ä½“ç›®å½• (Windows) - ä¸»è¦è·¯å¾„
        label_studio_media_dir = r'C:\Users\Administrator\AppData\Local\label-studio\label-studio\media'
        
        if os.path.exists(label_studio_media_dir):
            # å¤„ç†è·¯å¾„ï¼šç§»é™¤å¼€å¤´çš„æ–œæ ï¼Œç›´æ¥ä½¿ç”¨ç›¸å¯¹è·¯å¾„
            relative_path = file_path.lstrip('/')
            possible_paths.append(os.path.join(label_studio_media_dir, relative_path))
        else:
            print(f"   âŒ Label Studioåª’ä½“ç›®å½•ä¸å­˜åœ¨: {label_studio_media_dir}")
        
        # 2. å¤‡ç”¨è·¯å¾„ (ä»…å½“ä¸»è·¯å¾„ä¸å­˜åœ¨æ—¶)
        backup_media_dirs = [
            os.path.expanduser(r'~\AppData\Local\label-studio\label-studio\media'),
            r'C:\Users\%USERNAME%\AppData\Local\label-studio\label-studio\media',
        ]
        
        for backup_dir in backup_media_dirs:
            if os.path.exists(backup_dir):
                relative_path = file_path.lstrip('/')
                possible_paths.append(os.path.join(backup_dir, relative_path))
        
        # 3. é…ç½®çš„åª’ä½“ç›®å½• (å¦‚æœè®¾ç½®äº†ç¯å¢ƒå˜é‡)
        if LABEL_STUDIO_MEDIA_DIR and os.path.exists(LABEL_STUDIO_MEDIA_DIR):
            relative_path = file_path.lstrip('/')
            possible_paths.append(os.path.join(LABEL_STUDIO_MEDIA_DIR, relative_path))
        
        # 4. åŸå§‹è·¯å¾„ (æœ€åå¤‡ç”¨)
        # åˆ é™¤è·¯å¾„ä¸­å¼€å§‹çš„/data/æ–‡ä»¶å¤¹
        file_path = file_path.replace('/data/', '')
        possible_paths.append(file_path)
        
        # æµ‹è¯•æ¯ä¸ªå¯èƒ½çš„è·¯å¾„
        for i, test_path in enumerate(possible_paths):
            test_path = test_path.replace('\data', '')
            
            if os.path.exists(test_path):
                file_path = test_path
                break
        else:
            print(f"\nâŒ æœªæ‰¾åˆ°Label Studioåª’ä½“æ–‡ä»¶!")
            return self._create_config_guidance_message()
        
        try:
            # è·å–æ–‡ä»¶æ‰©å±•åæ¥ç¡®å®šMIMEç±»å‹
            _, ext = os.path.splitext(file_path)
            ext = ext.lower().lstrip('.')
            
            mime_type_map = {
                'jpg': 'image/jpeg',
                'jpeg': 'image/jpeg', 
                'png': 'image/png',
                'gif': 'image/gif',
                'webp': 'image/webp',
                'bmp': 'image/bmp'
            }
            
            mime_type = mime_type_map.get(ext, 'image/jpeg')
            
            # è¯»å–æ–‡ä»¶å¹¶è½¬æ¢ä¸ºbase64
            with open(file_path, 'rb') as image_file:
                image_data = image_file.read()
                base64_data = base64.b64encode(image_data).decode('utf-8')
                
            # æ„å»ºdata URL
            data_url = f"data:{mime_type};base64,{base64_data}"
            
            return data_url
            
        except Exception as e:
            print(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
            return None
    
    def _create_config_guidance_message(self) -> str:
        """åˆ›å»ºé…ç½®æŒ‡å¼•æ¶ˆæ¯ï¼ˆå½“æ–‡ä»¶æœªæ‰¾åˆ°æ—¶çš„fallbackï¼‰"""
        return """âš ï¸ é…ç½®é—®é¢˜ï¼šæ— æ³•è®¿é—®ä¸Šä¼ çš„å›¾ç‰‡æ–‡ä»¶

ğŸ”§ è§£å†³æ–¹æ¡ˆï¼š

1ï¸âƒ£ æ£€æŸ¥Label Studioé…ç½®
   - ç¡®ä¿å¯ç”¨äº†æœ¬åœ°æ–‡ä»¶æœåŠ¡
   - è®¾ç½®æ­£ç¡®çš„æ–‡ä»¶æ ¹ç›®å½•

2ï¸âƒ£ æ£€æŸ¥æ–‡ä»¶è·¯å¾„
   - ç¡®ä¿æ–‡ä»¶å·²æ­£ç¡®ä¸Šä¼ åˆ°Label Studio
   - æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åœ¨æ­£ç¡®çš„åª’ä½“ç›®å½•ä¸­

3ï¸âƒ£ ä½¿ç”¨Base64ä¸Šä¼ 
   - ç›´æ¥ä¸Šä¼ base64ç¼–ç çš„å›¾ç‰‡
   - é¿å…æ–‡ä»¶è·¯å¾„ä¾èµ–é—®é¢˜

4ï¸âƒ£ é…ç½®ç¯å¢ƒå˜é‡
   - LABEL_STUDIO_MEDIA_DIR=your_media_path
   - é‡å¯ML BackendæœåŠ¡

è¯·è”ç³»ç®¡ç†å‘˜é…ç½®æ–‡ä»¶æœåŠ¡åé‡è¯•ã€‚"""
    
    def _format_config_guidance_prediction(self, guidance_message: str, task: Dict) -> Dict:
        """æ ¼å¼åŒ–é…ç½®æŒ‡å¼•æ¶ˆæ¯ä¸ºLabel Studioé¢„æµ‹æ ¼å¼"""
        
        # åŠ¨æ€è·å–å­—æ®µå
        from_name, to_name = self._get_field_names()
        
        prediction = {
            "model_version": self.get("model_version"),
            "score": 0.1,  # ä½åˆ†è¡¨ç¤ºè¿™æ˜¯é…ç½®é—®é¢˜
            "result": [{
                "from_name": from_name,
                "to_name": to_name, 
                "type": "textarea",
                "value": {
                    "text": [guidance_message]
                }
            }]
        }
        
        return prediction


    def predict(self, tasks: List[Dict], context: Optional[Dict] = None, **kwargs) -> ModelResponse:
        """ ç¾å®³å›¾ç‰‡å¯¹è±¡æ£€æµ‹é¢„æµ‹
            :param tasks: Label Studio tasks in JSON format (åŒ…å«å›¾ç‰‡æ•°æ®)
            :param context: Label Studio context in JSON format
            :return: ModelResponse with predictions (çŸ©å½¢æ¡†æ ‡æ³¨)
        """
        
        predictions = []
        
        for i, task in enumerate(tasks):
            try:
                prediction = self._process_single_task(task)
                if prediction:
                    predictions.append(prediction)
                else:
                    predictions.append({
                        "model_version": self.get("model_version"),
                        "score": 0.0,
                        "result": []
                    })
            except Exception as e:
                print(f"âŒ ä»»åŠ¡ {i+1} å¤„ç†å¤±è´¥: {e}")
                predictions.append({
                    "model_version": self.get("model_version"),
                    "score": 0.0,
                    "result": []
                })
        
        # è¾“å‡ºæœ€ç»ˆè¿”å›çš„JSONç»“æœ
        print("\n" + "="*60)
        print("ğŸ“¤ æœ€ç»ˆè¿”å›çš„JSONç»“æœ:")
        print("="*60)
        for i, prediction in enumerate(predictions):
            print(f"\n--- é¢„æµ‹ç»“æœ {i+1} ---")
            print(json.dumps(prediction, indent=2, ensure_ascii=False))
        print("\n" + "="*60)
        
        return ModelResponse(predictions=predictions)
    
    def _process_single_task(self, task: Dict) -> Optional[Dict]:
        """å¤„ç†å•ä¸ªå¯¹è±¡æ£€æµ‹ä»»åŠ¡"""
        
        task_data = task.get('data', {})
        
        # æå–å›¾ç‰‡å†…å®¹
        image_url = None
        image_data = None
        
        # æŸ¥æ‰¾å›¾ç‰‡URL
        for key, value in task_data.items():
            if isinstance(value, str):
                # ä¼˜å…ˆæ£€æŸ¥imageå­—æ®µï¼ˆæ‚¨çš„æ¨¡æ¿ä¸­çš„å›¾ç‰‡å­—æ®µï¼‰
                if key in ['image', 'img', 'photo', 'picture', 'url']:
                    image_url = value
                    break
                elif value.startswith(('http://', 'https://', 'data:image/')):
                    image_url = value
                    break
        
        if not image_url:
            return None
        
        # å¤„ç†å›¾ç‰‡æ•°æ®
        if image_url.startswith('data:image/'):
            # Base64ç¼–ç çš„å›¾ç‰‡
            image_data = image_url
            
        elif image_url.startswith(('http://', 'https://')):
            # ç½‘ç»œURLå›¾ç‰‡
            image_data = image_url
            
        else:
            # æœ¬åœ°æ–‡ä»¶è·¯å¾„
            # è½¬æ¢æœ¬åœ°æ–‡ä»¶ä¸ºbase64
            image_data = self._convert_local_path_to_base64(image_url)
            
            if not image_data:
                return None
            
            # æ£€æŸ¥æ˜¯å¦è¿”å›çš„æ˜¯é…ç½®æŒ‡å¼•æ¶ˆæ¯
            if image_data.startswith("âš ï¸ é…ç½®é—®é¢˜"):
                return self._format_config_guidance_prediction(image_data, task)
        
        # æ„å»ºå¯¹è±¡æ£€æµ‹æç¤ºè¯
        prompt = """è¯·åˆ†æè¿™å¼ ç¾å®³å›¾ç‰‡ï¼Œè¯†åˆ«å¹¶æ ‡æ³¨ä»¥ä¸‹ä¸‰ç±»å¯¹è±¡ï¼š

1. disaster-causing-factor (è‡´ç¾å› å­): å¯¼è‡´ç¾å®³å‘ç”Ÿçš„ç›´æ¥å› ç´ ï¼Œå¦‚æ´ªæ°´ã€åœ°éœ‡ã€ç«ç¾ã€æ—ç«ç­‰ç­‰
2. disaster-victims (å—ç¾ä½“): å—åˆ°ç¾å®³å½±å“çš„äººã€å»ºç­‘ã€è®¾æ–½ã€äººå‘˜ã€è®¾å¤‡ç­‰
3. Pregnancy-disaster-environment (å­•ç¾ç¯å¢ƒ): å®¹æ˜“å‘ç”Ÿç¾å®³çš„ç¯å¢ƒæ¡ä»¶ï¼Œå¦‚é™¡å¡ã€æ²³é“ã€åœ°è´¨ä¸ç¨³å®šåŒºåŸŸã€æ¤è¢«è¦†ç›–ç‡ã€æ¤è¢«ç±»å‹ç­‰

è¯·ä»¥JSONæ ¼å¼è¿”å›æ£€æµ‹ç»“æœï¼ŒåŒ…å«æ¯ä¸ªå¯¹è±¡çš„ç±»åˆ«ã€ä½ç½®åæ ‡å’Œç½®ä¿¡åº¦ã€‚æ ¼å¼å¦‚ä¸‹ï¼š
{
  "objects": [
    {
      "label": "disaster-causing-factor",
      "bbox": [x1, y1, x2, y2],
      "confidence": 0.95
    }
  ]
}

**é‡è¦åæ ‡è¦æ±‚**ï¼š
- åæ ‡æ ¼å¼ï¼š[å·¦ä¸Šè§’x%, å·¦ä¸Šè§’y%, å³ä¸‹è§’x%, å³ä¸‹è§’y%]
- åæ ‡å€¼å¿…é¡»æ˜¯0-100ä¹‹é—´çš„ç™¾åˆ†æ¯”æ•°å€¼ï¼ˆä¸æ˜¯åƒç´ å€¼ï¼‰
- ä¾‹å¦‚ï¼š[10.5, 15.2, 45.8, 67.3] è¡¨ç¤ºä»å›¾ç‰‡å®½åº¦10.5%ï¼Œé«˜åº¦15.2%ä½ç½®åˆ°å®½åº¦45.8%ï¼Œé«˜åº¦67.3%ä½ç½®çš„çŸ©å½¢æ¡†
- å·¦ä¸Šè§’åæ ‡ < å³ä¸‹è§’åæ ‡
- æ‰€æœ‰åæ ‡å€¼èŒƒå›´ï¼š0 â‰¤ åæ ‡å€¼ â‰¤ 100

**åæ ‡ç¤ºä¾‹**ï¼š
- å›¾ç‰‡å·¦ä¸Šè§’åŒºåŸŸçš„å¯¹è±¡ï¼š[5.0, 5.0, 30.0, 25.0]
- å›¾ç‰‡ä¸­å¿ƒåŒºåŸŸçš„å¯¹è±¡ï¼š[35.0, 35.0, 65.0, 65.0]  
- å›¾ç‰‡å³ä¸‹è§’åŒºåŸŸçš„å¯¹è±¡ï¼š[70.0, 75.0, 95.0, 95.0]

è¯·ä¸¥æ ¼æŒ‰ç…§ç™¾åˆ†æ¯”æ ¼å¼è¿”å›åæ ‡ï¼Œè¿™å¯¹å‡†ç¡®æ ‡æ³¨è‡³å…³é‡è¦ï¼"""
        
        # è°ƒç”¨å¤šæ¨¡æ€API
        api_response = self._call_multimodal_api(prompt, image_data)
        
        if api_response:
            return self._format_detection_prediction(api_response, task)
        else:
            return None
    
    def _call_multimodal_api(self, prompt: str, image_data: str) -> Optional[str]:
        """è°ƒç”¨å¤šæ¨¡æ€APIè¿›è¡Œå¯¹è±¡æ£€æµ‹"""
        
        if not self.client:
            return None
        
        try:
            # æ„å»ºå¤šæ¨¡æ€æ¶ˆæ¯
            system_message = "You are a helpful assistant specialized in disaster image analysis and object detection. Please provide accurate object detection results in JSON format."
            
            messages = [
                {
                    "role": "system", 
                    "content": system_message
                },
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": image_data
                            }
                        }
                    ]
                }
            ]
            
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                max_tokens=1000,
                temperature=0.7,
                top_p=0.9,
                stream=False
            )
            
            if response.choices and len(response.choices) > 0:
                choice = response.choices[0]
                
                if hasattr(choice, 'message'):
                    message = choice.message
                    content = getattr(message, 'content', None)
                    
                    if content:
                        return content
                
            return None
                
        except Exception as e:
            print(f"âŒ å¤šæ¨¡æ€APIè°ƒç”¨å¼‚å¸¸: {str(e)}")
            return None
    
    def _pixel_to_percentage(self, pixel_coords: List[float], image_width: int, image_height: int) -> List[float]:
        """å°†åƒç´ åæ ‡è½¬æ¢ä¸ºç™¾åˆ†æ¯”åæ ‡"""
        x1, y1, x2, y2 = pixel_coords
        
        # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
        x1_percent = (x1 / image_width) * 100
        y1_percent = (y1 / image_height) * 100
        x2_percent = (x2 / image_width) * 100
        y2_percent = (y2 / image_height) * 100
        
        return [x1_percent, y1_percent, x2_percent, y2_percent]
    
    def _get_image_dimensions(self, task: Dict) -> tuple:
        """å°è¯•è·å–å›¾ç‰‡çš„çœŸå®å°ºå¯¸"""
        try:
            import requests
            from PIL import Image
            import io
            
            # è·å–å›¾ç‰‡æ•°æ®
            task_data = task.get('data', {})
            image_url = None
            
            for key, value in task_data.items():
                if isinstance(value, str) and (key in ['image', 'img', 'photo', 'picture', 'url', 'captioning'] or 
                                              value.startswith(('http://', 'https://', 'data:image/', '/'))):
                    image_url = value
                    break
            
            if not image_url:
                return None, None
            
            if image_url.startswith('data:image/'):
                # Base64ç¼–ç çš„å›¾ç‰‡
                import base64
                header, data = image_url.split(',', 1)
                image_data = base64.b64decode(data)
                image = Image.open(io.BytesIO(image_data))
                return image.width, image.height
                
            elif image_url.startswith(('http://', 'https://')):
                # ç½‘ç»œURLå›¾ç‰‡
                response = requests.get(image_url, timeout=10)
                image = Image.open(io.BytesIO(response.content))
                return image.width, image.height
                
            else:
                # æœ¬åœ°æ–‡ä»¶è·¯å¾„ - ä½¿ç”¨ç°æœ‰çš„è·¯å¾„è§£æé€»è¾‘
                image_data = self._convert_local_path_to_base64(image_url)
                if image_data and image_data.startswith('data:image/'):
                    import base64
                    header, data = image_data.split(',', 1)
                    image_bytes = base64.b64decode(data)
                    image = Image.open(io.BytesIO(image_bytes))
                    return image.width, image.height
                    
        except Exception as e:
            print(f"âš ï¸ æ— æ³•è·å–å›¾ç‰‡å°ºå¯¸: {e}")
            
        return None, None
    
    def _normalize_coordinates(self, x1: float, y1: float, x2: float, y2: float, task: Dict) -> tuple:
        """æ™ºèƒ½æ ‡å‡†åŒ–åæ ‡ä¸ºç™¾åˆ†æ¯”æ ¼å¼"""
        
        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯ç™¾åˆ†æ¯”åæ ‡ (0-100èŒƒå›´)
        if max(x1, y1, x2, y2) <= 100 and min(x1, y1, x2, y2) >= 0:
            print(f"âœ… æ£€æµ‹åˆ°ç™¾åˆ†æ¯”åæ ‡ï¼Œç›´æ¥ä½¿ç”¨")
            return x1, y1, x2, y2
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ ‡å‡†åŒ–åæ ‡ (0-1èŒƒå›´)
        if max(x1, y1, x2, y2) <= 1.0 and min(x1, y1, x2, y2) >= 0:
            print(f"âœ… æ£€æµ‹åˆ°æ ‡å‡†åŒ–åæ ‡(0-1)ï¼Œè½¬æ¢ä¸ºç™¾åˆ†æ¯”")
            return x1 * 100, y1 * 100, x2 * 100, y2 * 100
        
        # å¦åˆ™å‡è®¾æ˜¯åƒç´ åæ ‡ï¼Œå°è¯•è·å–å›¾ç‰‡çœŸå®å°ºå¯¸è¿›è¡Œè½¬æ¢
        print(f"ğŸ” æ£€æµ‹åˆ°ç–‘ä¼¼åƒç´ åæ ‡ï¼Œå°è¯•è·å–å›¾ç‰‡å°ºå¯¸è¿›è¡Œç²¾ç¡®è½¬æ¢")
        image_width, image_height = self._get_image_dimensions(task)
        
        if image_width and image_height:
            print(f"ğŸ“ è·å–åˆ°å›¾ç‰‡å°ºå¯¸: {image_width}x{image_height}")
            x1_percent = (x1 / image_width) * 100
            y1_percent = (y1 / image_height) * 100
            x2_percent = (x2 / image_width) * 100
            y2_percent = (y2 / image_height) * 100
            
            # ç¡®ä¿åæ ‡åœ¨åˆç†èŒƒå›´å†…
            x1_percent = max(0, min(100, x1_percent))
            y1_percent = max(0, min(100, y1_percent))
            x2_percent = max(0, min(100, x2_percent))
            y2_percent = max(0, min(100, y2_percent))
            
            print(f"âœ… ç²¾ç¡®è½¬æ¢å®Œæˆ: [{x1_percent:.1f}, {y1_percent:.1f}, {x2_percent:.1f}, {y2_percent:.1f}]")
            return x1_percent, y1_percent, x2_percent, y2_percent
        else:
            # æ— æ³•è·å–å›¾ç‰‡å°ºå¯¸ï¼Œä½¿ç”¨å¯å‘å¼æ–¹æ³•
            print(f"âš ï¸ æ— æ³•è·å–å›¾ç‰‡å°ºå¯¸ï¼Œä½¿ç”¨å¯å‘å¼è½¬æ¢")
            
            # æ ¹æ®åæ ‡å€¼çš„å¤§å°èŒƒå›´è¿›è¡Œæ¨æµ‹
            max_coord = max(x1, y1, x2, y2)
            
            if max_coord > 2000:
                # å¯èƒ½æ˜¯é«˜åˆ†è¾¨ç‡å›¾ç‰‡çš„åƒç´ åæ ‡
                scale_factor = 0.05  # å‡è®¾å›¾ç‰‡å°ºå¯¸çº¦2000x2000
                print(f"ğŸ”§ æ¨æµ‹ä¸ºé«˜åˆ†è¾¨ç‡å›¾ç‰‡ï¼Œä½¿ç”¨ç¼©æ”¾å› å­: {scale_factor}")
            elif max_coord > 1000:
                # å¯èƒ½æ˜¯æ ‡å‡†åˆ†è¾¨ç‡å›¾ç‰‡çš„åƒç´ åæ ‡
                scale_factor = 0.1   # å‡è®¾å›¾ç‰‡å°ºå¯¸çº¦1000x1000
                print(f"ğŸ”§ æ¨æµ‹ä¸ºæ ‡å‡†åˆ†è¾¨ç‡å›¾ç‰‡ï¼Œä½¿ç”¨ç¼©æ”¾å› å­: {scale_factor}")
            elif max_coord > 500:
                # å¯èƒ½æ˜¯ä¸­ç­‰åˆ†è¾¨ç‡å›¾ç‰‡çš„åƒç´ åæ ‡
                scale_factor = 0.2   # å‡è®¾å›¾ç‰‡å°ºå¯¸çº¦500x500
                print(f"ğŸ”§ æ¨æµ‹ä¸ºä¸­ç­‰åˆ†è¾¨ç‡å›¾ç‰‡ï¼Œä½¿ç”¨ç¼©æ”¾å› å­: {scale_factor}")
            else:
                # åæ ‡å€¼è¾ƒå°ï¼Œå¯èƒ½å·²ç»æ˜¯æŸç§å½’ä¸€åŒ–æ ¼å¼
                scale_factor = 1.0   # ç›´æ¥ä½¿ç”¨
                print(f"ğŸ”§ åæ ‡å€¼è¾ƒå°ï¼Œç›´æ¥ä½¿ç”¨")
            
            x1_percent = max(0, min(100, x1 * scale_factor))
            y1_percent = max(0, min(100, y1 * scale_factor))
            x2_percent = max(0, min(100, x2 * scale_factor))
            y2_percent = max(0, min(100, y2 * scale_factor))
            
            print(f"âš ï¸ å¯å‘å¼è½¬æ¢ç»“æœ: [{x1_percent:.1f}, {y1_percent:.1f}, {x2_percent:.1f}, {y2_percent:.1f}]")
            return x1_percent, y1_percent, x2_percent, y2_percent
    
    def _format_detection_prediction(self, api_response: str, task: Dict) -> Dict:
        """æ ¼å¼åŒ–å¯¹è±¡æ£€æµ‹é¢„æµ‹ç»“æœä¸ºLabel Studioæ ¼å¼"""
        
        # æ„å»ºåŸºç¡€é¢„æµ‹ç»“æ„
        model_version = self.get("model_version")
        
        prediction = {
            "model_version": model_version,
            "score": 0.95,
            "result": []
        }
        
        # åŠ¨æ€è·å–å­—æ®µå
        from_name, to_name = self._get_field_names()
        
        # è§£æAPIå“åº”ä¸­çš„JSONæ•°æ®
        try:
            # å°è¯•ä»å“åº”ä¸­æå–JSON
            import re
            json_match = re.search(r'\{.*\}', api_response, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                detection_data = json.loads(json_str)
                
                if 'objects' in detection_data:
                    for obj in detection_data['objects']:
                        if 'label' in obj and 'bbox' in obj:
                            # æ„å»ºLabel StudioçŸ©å½¢æ¡†æ ¼å¼
                            bbox = obj['bbox']
                            confidence = obj.get('confidence', 0.8)
                            
                            # å¤„ç†bboxåæ ‡ï¼š[x1, y1, x2, y2] æ ¼å¼
                            x1, y1, x2, y2 = bbox
                            
                            print(f"ğŸ” åŸå§‹åæ ‡: [{x1}, {y1}, {x2}, {y2}]")
                            
                            # åæ ‡æ ¼å¼æ£€æµ‹å’Œè½¬æ¢
                            x1_percent, y1_percent, x2_percent, y2_percent = self._normalize_coordinates(x1, y1, x2, y2, task)
                            
                            # ç¡®ä¿åæ ‡é¡ºåºæ­£ç¡®ï¼ˆå·¦ä¸Šè§’ -> å³ä¸‹è§’ï¼‰
                            if x1_percent > x2_percent:
                                x1_percent, x2_percent = x2_percent, x1_percent
                            if y1_percent > y2_percent:
                                y1_percent, y2_percent = y2_percent, y1_percent
                            
                            # è®¡ç®—Label Studioéœ€è¦çš„æ ¼å¼ï¼šx, y, width, height (ç™¾åˆ†æ¯”)
                            x = x1_percent
                            y = y1_percent
                            width = x2_percent - x1_percent
                            height = y2_percent - y1_percent
                            
                            # ç¡®ä¿å®½åº¦å’Œé«˜åº¦ä¸ºæ­£å€¼
                            width = max(0.1, width)   # æœ€å°å®½åº¦0.1%
                            height = max(0.1, height) # æœ€å°é«˜åº¦0.1%
                            
                            print(f"ğŸ“ è½¬æ¢ååæ ‡: x={x:.1f}%, y={y:.1f}%, width={width:.1f}%, height={height:.1f}%")
                            
                            result_item = {
                                "from_name": from_name,
                                "to_name": to_name,
                                "type": "rectanglelabels",
                                "value": {
                                    "x": x,
                                    "y": y,
                                    "width": width,
                                    "height": height,
                                    "rectanglelabels": [obj['label']]
                                },
                                "score": confidence
                            }
                            
                            prediction["result"].append(result_item)
            
            # å¦‚æœæ²¡æœ‰è§£æåˆ°æœ‰æ•ˆçš„æ£€æµ‹ç»“æœï¼Œå°è¯•ä½¿ç”¨é»˜è®¤æ£€æµ‹
            if not prediction["result"]:
                # ç”Ÿæˆä¸€äº›ç¤ºä¾‹æ£€æµ‹æ¡†ï¼ˆç”¨äºæµ‹è¯•ï¼‰- ç™¾åˆ†æ¯”åæ ‡
                sample_objects = [
                    {"label": "disaster-causing-factor", "bbox": [10.5, 15.2, 45.8, 50.3], "confidence": 0.8},
                    {"label": "disaster-victims", "bbox": [55.0, 60.5, 85.2, 90.8], "confidence": 0.7},
                    {"label": "Pregnancy-disaster-environment", "bbox": [20.3, 25.7, 70.6, 80.1], "confidence": 0.6}
                ]
                
                for obj in sample_objects:
                    bbox = obj['bbox']
                    result_item = {
                        "from_name": from_name,
                        "to_name": to_name,
                        "type": "rectanglelabels",
                        "value": {
                            "x": bbox[0],
                            "y": bbox[1],
                            "width": bbox[2] - bbox[0],
                            "height": bbox[3] - bbox[1],
                            "rectanglelabels": [obj['label']]
                        },
                        "score": obj['confidence']
                    }
                    
                    prediction["result"].append(result_item)
                    
        except Exception as e:
            print(f"âŒ è§£ææ£€æµ‹ç»“æœå¤±è´¥: {str(e)}")
            # è¿”å›ç©ºç»“æœ
            pass
        
        return prediction
    
    def _format_prediction(self, api_response: str, task: Dict) -> Dict:
        """æ ¼å¼åŒ–é¢„æµ‹ç»“æœä¸ºLabel Studioæ ¼å¼ï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰"""
        
        prediction = {
            "model_version": self.get("model_version"),
            "score": 0.85,
            "result": []
        }
        
        # è¿”å›åŸå§‹æ–‡æœ¬ç»“æœ
        if api_response and api_response.strip():
            prediction["result"].append({
                "from_name": "prediction",
                "to_name": "text",
                "type": "textarea",
                "value": {
                    "text": [api_response.strip()]
                }
            })
        
        return prediction
    
    def _get_field_names(self) -> tuple:
        """åŠ¨æ€è·å–Label Studioé…ç½®ä¸­çš„å­—æ®µå"""
        try:
            # å°è¯•ä»Label Studioé…ç½®ä¸­è·å–å­—æ®µå
            if hasattr(self, 'label_interface') and self.label_interface:
                # æŸ¥æ‰¾RectangleLabelsæ ‡ç­¾
                rect_from_name, rect_to_name, _ = self.label_interface.get_first_tag_occurence(
                    'RectangleLabels', ['Image']
                )
                if rect_from_name and rect_to_name:
                    return rect_from_name, rect_to_name
            
            # æŸ¥æ‰¾Imageæ ‡ç­¾
            if hasattr(self, 'label_interface') and self.label_interface:
                image_from_name, image_to_name, _ = self.label_interface.get_first_tag_occurence(
                    'Image', []
                )
                if image_from_name:
                    return "label", image_from_name
            
        except Exception as e:
            pass
        
        # æ ¹æ®æ‚¨çš„æ¨¡æ¿ï¼Œä½¿ç”¨æ­£ç¡®çš„å­—æ®µå
        return "label", "image"
    
    def _extract_choice(self, response: str, choices: List[str]) -> Optional[str]:
        """ä»å“åº”ä¸­æå–æœ€åŒ¹é…çš„é€‰æ‹©"""
        response_lower = response.lower()
        for choice in choices:
            if choice.lower() in response_lower:
                return choice
        return choices[0] if choices else None
    
    def fit(self, event, data, **kwargs):
        """
        è®­ç»ƒ/æ›´æ–°å¯¹è±¡æ£€æµ‹æ¨¡å‹
        :param event: äº‹ä»¶ç±»å‹ ('ANNOTATION_CREATED', 'ANNOTATION_UPDATED', 'START_TRAINING')
        :param data: äº‹ä»¶æ•°æ®ï¼ˆåŒ…å«å›¾ç‰‡å’ŒçŸ©å½¢æ¡†æ ‡æ³¨ï¼‰
        """
        # è®°å½•æ ‡æ³¨æ•°æ®ç”¨äºæ¨¡å‹ä¼˜åŒ–
        old_data = self.get('annotation_data')
        self.set('annotation_data', 'updated_detection_data')
        self.set('model_version', 'updated_version')
        print(f"âœ… å¯¹è±¡æ£€æµ‹æ¨¡å‹å·²æ›´æ–° (äº‹ä»¶: {event})")
        print(f"ğŸ“¸ å·²è®°å½•æ–°çš„å¯¹è±¡æ£€æµ‹æ ‡æ³¨æ•°æ®ï¼Œç”¨äºåç»­æ¨¡å‹ä¼˜åŒ–")

