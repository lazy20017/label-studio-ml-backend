from typing import List, Dict, Optional
import json
import os
import base64
from openai import OpenAI
from label_studio_ml.model import LabelStudioMLBase
from label_studio_ml.response import ModelResponse


# ==================== å¤šæ¨¡æ€å›¾æ¡†é€‰æ ‡æ³¨é…ç½® ====================
# æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
SUPPORTED_IMAGE_FORMATS = ['jpg', 'jpeg', 'png', 'gif', 'webp', 'bmp']

# Label Studio åª’ä½“ç›®å½•é…ç½®
# å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡ LABEL_STUDIO_MEDIA_DIR è®¾ç½®
LABEL_STUDIO_MEDIA_DIR = os.getenv('LABEL_STUDIO_MEDIA_DIR', r'C:\Users\Administrator\AppData\Local\label-studio\label-studio\media')

# å›¾æ¡†é€‰æ ‡æ³¨ä»»åŠ¡é…ç½®
RECTANGLE_ANNOTATION_CONFIG = {
    "task_type": "ç¾å®³å›¾ç‰‡æ¡†é€‰æ ‡æ³¨",
    "model_type": "å¤šæ¨¡æ€è§†è§‰è¯­è¨€æ¨¡å‹", 
    "output_format": "çŸ©å½¢æ¡†æ ‡æ³¨",
    "language": "ä¸­æ–‡",
    "max_tokens": 1000,
    "temperature": 0.7,
    "labels": [
        "ç§¯æ°´æ·¹æ²¡åŒºåŸŸ",      # è“è‰²
        "å—ç¾å»ºç­‘ç‰©",        # çº¢è‰²
        "å—ç¾é“è·¯",          # æ©™è‰²
        "å—ç¾äººå‘˜",          # ç²‰è‰²
        "å—ç¾è½¦è¾†",          # ç´«è‰²
        "æ•‘æ´äººå‘˜",          # ç»¿è‰²
        "æ•‘æ´è½¦è¾†",          # é’è‰²
        "æ ‘æœ¨å†œç”°å—æŸåŒº",    # æ£•è‰²
        "ç”µåŠ›è®¾æ–½",          # é»„è‰²
        "æ¡¥æ¢å ¤å",          # æ·±æ©™è‰²
        "äº¤é€šè®¾æ–½",          # ç°è‰²
        "æ¼‚æµ®ç‰©"             # æµ…è“è‰²
    ]
}

# ==================== ğŸŒ å…¨å±€çŠ¶æ€ç®¡ç† - API Keyå’Œæ¨¡å‹åˆ‡æ¢ ====================
# ä½¿ç”¨å…¨å±€å˜é‡ç»Ÿä¸€ç®¡ç†å½“å‰çŠ¶æ€ï¼Œé¿å…å¤æ‚çš„åˆ‡æ¢é€»è¾‘
api_key_list = [
    "ms-758c9c64-2498-467c-a0de-8b32a1370bc1",
    "ms-376c277c-8f18-4c42-9ba9-c4b0911fa9b0",
    "ms-78247b29-fd23-4ef9-a86a-0e792da83f3e",
    "ms-89acac3e-5ed3-4c06-ad67-8941aef812d1",
    'ms-b980f2d1-86e3-43bc-a72e-30c6849b3148',
    'ms-6a7bc978-f320-48bc-aa67-f9c2e6c9d5c6',
    'ms-7fa00741-856a-4134-80d2-f296b15c0e76',
    'ms-ca41cec5-48ca-4a9e-9fdf-ac348a638d11',
]

# ğŸ”‘ å…¨å±€API KeyçŠ¶æ€
GLOBAL_API_KEY_INDEX = 0
GLOBAL_CURRENT_API_KEY = api_key_list[GLOBAL_API_KEY_INDEX]

# ğŸ¤– å…¨å±€æ¨¡å‹çŠ¶æ€ - å¤šæ¨¡æ€æ¨¡å‹åˆ—è¡¨
available_models_global = [ 

"stepfun-ai/step3",
"Qwen/Qwen2.5-VL-72B-Instruct",
]

GLOBAL_MODEL_INDEX = 0
GLOBAL_CURRENT_MODEL = available_models_global[GLOBAL_MODEL_INDEX]

# ğŸ”„ ç®€åŒ–çš„åˆ‡æ¢å‡½æ•°
def switch_to_next_api_key():
    """åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªAPI Key"""
    global GLOBAL_API_KEY_INDEX, GLOBAL_CURRENT_API_KEY, GLOBAL_MODEL_INDEX, GLOBAL_CURRENT_MODEL
    
    old_api_key = GLOBAL_CURRENT_API_KEY
    GLOBAL_API_KEY_INDEX = (GLOBAL_API_KEY_INDEX + 1) % len(api_key_list)
    GLOBAL_CURRENT_API_KEY = api_key_list[GLOBAL_API_KEY_INDEX]
    
    # åˆ‡æ¢API Keyæ—¶é‡ç½®åˆ°ç¬¬ä¸€ä¸ªæ¨¡å‹
    GLOBAL_MODEL_INDEX = 0
    GLOBAL_CURRENT_MODEL = available_models_global[GLOBAL_MODEL_INDEX]
    
    print(f"ğŸ”‘ API Keyåˆ‡æ¢: ***{old_api_key[-8:]} â†’ ***{GLOBAL_CURRENT_API_KEY[-8:]}")
    print(f"ğŸ”„ é‡ç½®åˆ°ç¬¬ä¸€ä¸ªæ¨¡å‹: {GLOBAL_CURRENT_MODEL}")
    return True

def switch_to_next_model():
    """åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªæ¨¡å‹"""
    global GLOBAL_MODEL_INDEX, GLOBAL_CURRENT_MODEL
    
    old_model = GLOBAL_CURRENT_MODEL
    GLOBAL_MODEL_INDEX = (GLOBAL_MODEL_INDEX + 1) % len(available_models_global)
    GLOBAL_CURRENT_MODEL = available_models_global[GLOBAL_MODEL_INDEX]
    
    print(f"ğŸ”„ æ¨¡å‹åˆ‡æ¢: {old_model.split('/')[-1]} â†’ {GLOBAL_CURRENT_MODEL.split('/')[-1]}")
    
    # å¦‚æœå›åˆ°ç¬¬ä¸€ä¸ªæ¨¡å‹ï¼Œè¯´æ˜æ‰€æœ‰æ¨¡å‹éƒ½è¯•è¿‡äº†ï¼Œåˆ‡æ¢API Key
    if GLOBAL_MODEL_INDEX == 0:
        print("âš ï¸ æ‰€æœ‰æ¨¡å‹éƒ½å·²å°è¯•ï¼Œåˆ‡æ¢API Key")
        switch_to_next_api_key()
        return True
    
    return True

def get_current_api_key():
    """è·å–å½“å‰API Key"""
    return GLOBAL_CURRENT_API_KEY

def get_current_model():
    """è·å–å½“å‰æ¨¡å‹"""
    return GLOBAL_CURRENT_MODEL

def reset_global_state():
    """é‡ç½®å…¨å±€çŠ¶æ€åˆ°åˆå§‹å€¼"""
    global GLOBAL_API_KEY_INDEX, GLOBAL_CURRENT_API_KEY, GLOBAL_MODEL_INDEX, GLOBAL_CURRENT_MODEL
    
    GLOBAL_API_KEY_INDEX = 0
    GLOBAL_CURRENT_API_KEY = api_key_list[0]
    GLOBAL_MODEL_INDEX = 0 
    GLOBAL_CURRENT_MODEL = available_models_global[0]
    
    print(f"ğŸ”„ å…¨å±€çŠ¶æ€å·²é‡ç½®: API Key ***{GLOBAL_CURRENT_API_KEY[-8:]}, æ¨¡å‹ {GLOBAL_CURRENT_MODEL.split('/')[-1]}")
    return True


class NewModel(LabelStudioMLBase):
    """Custom ML Backend model for rectangle annotation
    """
    
    def setup(self):
        """Configure any parameters of your model here
        """
        print(f"\nğŸš€ ç¾å®³å›¾æ¡†é€‰æ ‡æ³¨ML Backendå¯åŠ¨ä¸­...")
        
        self.set("model_version", "2.0.0-å¤šè´¦å·åˆ‡æ¢ç‰ˆ")
        
        # ğŸŒ ä½¿ç”¨å…¨å±€çŠ¶æ€ç®¡ç† - ç®€åŒ–æ¶æ„
        self.api_base_url = os.getenv('MODELSCOPE_API_URL', 'https://api-inference.modelscope.cn/v1')
        
        # ğŸ¯ ç®€åŒ–çš„å¤±è´¥è®¡æ•°
        self.consecutive_failures = 0  # å½“å‰æ¨¡å‹çš„è¿ç»­å¤±è´¥æ¬¡æ•°
        self.max_failures_before_switch = 2  # è¿ç»­å¤±è´¥2æ¬¡ååˆ‡æ¢
        
        # å»¶è¿Ÿåˆå§‹åŒ–å®¢æˆ·ç«¯ï¼Œåªåœ¨éœ€è¦æ—¶è¿æ¥
        self.client = None
        self._api_initialized = False
        
        print("âœ… å¤šæ¨¡æ€å›¾æ¡†é€‰æ ‡æ³¨MLåç«¯åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ¯ å½“å‰æ¨¡å‹: {get_current_model().split('/')[-1]}")
        print(f"ğŸ”‘ å½“å‰API Key: ***{get_current_api_key()[-8:]}")
        print(f"ğŸ“‹ å¯ç”¨æ¨¡å‹: {len(available_models_global)} ä¸ª")
        print(f"ğŸ”‘ å¯ç”¨API Key: {len(api_key_list)} ä¸ª")
        print(f"ğŸ”„ ç®€åŒ–åˆ‡æ¢: å¤±è´¥{self.max_failures_before_switch}æ¬¡åˆ‡æ¢æ¨¡å‹ï¼Œæ‰€æœ‰æ¨¡å‹å¤±è´¥åˆ‡æ¢API Key")
        print(f"â° è¶…æ—¶è®¾ç½®: 250ç§’ï¼ˆç»™å¤§æ¨¡å‹å……è¶³å¤„ç†æ—¶é—´ï¼‰")
        print(f"ğŸ–¼ï¸ ä¸“ä¸šé¢†åŸŸ: å¤šæ¨¡æ€å›¾æ¡†é€‰æ ‡æ³¨ v2.0.0")
        print(f"ğŸš€ ç®€åŒ–ç­–ç•¥: ä½¿ç”¨å…¨å±€çŠ¶æ€ç»Ÿä¸€ç®¡ç†API Keyå’Œæ¨¡å‹åˆ‡æ¢")
    
    def reset_state(self):
        """ğŸ”„ é‡ç½®çŠ¶æ€åˆ°åˆå§‹çŠ¶æ€ï¼ˆä½¿ç”¨å…¨å±€çŠ¶æ€ï¼‰"""
        print("ğŸ”„ é‡ç½®çŠ¶æ€åˆ°åˆå§‹çŠ¶æ€...")
        reset_global_state()
        self.consecutive_failures = 0
        
        # é‡ç½®APIè¿æ¥
        self._api_initialized = False
        self.client = None
        
        print(f"âœ… çŠ¶æ€å·²é‡ç½®")
        return True
    
    def _handle_failure(self, reason: str = "æœªçŸ¥é”™è¯¯", force_switch: bool = False):
        """ğŸš¨ ç®€åŒ–çš„å¤±è´¥å¤„ç†é€»è¾‘"""
        self.consecutive_failures += 1
        current_model = get_current_model()
        
        print(f"âŒ æ¨¡å‹å¤±è´¥: {current_model.split('/')[-1]} - {reason} (è¿ç»­: {self.consecutive_failures}/{self.max_failures_before_switch})")
        
        # åˆ¤æ–­æ˜¯å¦éœ€è¦åˆ‡æ¢
        should_switch = force_switch or (self.consecutive_failures >= self.max_failures_before_switch)
        
        if should_switch:
            print(f"ğŸ”„ {'å¼ºåˆ¶' if force_switch else 'è¾¾åˆ°é˜ˆå€¼'}åˆ‡æ¢æ¨¡å‹")
            switch_to_next_model()  # ä½¿ç”¨å…¨å±€å‡½æ•°åˆ‡æ¢
            self.consecutive_failures = 0  # é‡ç½®å¤±è´¥è®¡æ•°
            
            # é‡ç½®APIè¿æ¥
            self._api_initialized = False
            self.client = None
            return True
        
        return False
    
    def _handle_success(self):
        """âœ… å¤„ç†æˆåŠŸï¼Œé‡ç½®å¤±è´¥è®¡æ•°"""
        if self.consecutive_failures > 0:
            print(f"âœ… æ¨¡å‹æ¢å¤æ­£å¸¸")
            self.consecutive_failures = 0
    
    def _should_switch_immediately(self, error_str: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦ç«‹å³åˆ‡æ¢æ¨¡å‹ï¼ˆä¸é‡è¯•ï¼‰"""
        immediate_switch_patterns = [
            # APIé™æµé”™è¯¯ - ç«‹å³åˆ‡æ¢
            "429",
            "Too Many Requests", 
            "Request limit exceeded",
            "Rate limit exceeded",
            "Quota exceeded",
            "è¯·æ±‚è¶…é™",  # ä¸­æ–‡é”™è¯¯ä¿¡æ¯
            "è¯·æ±‚é™åˆ¶",
            "è¶…å‡ºé™åˆ¶",
            "è¾¾åˆ°é™åˆ¶",
            "Exceeded limit",
            "API rate limit",
            "Usage limit exceeded",
            "Daily limit exceeded",
            "Monthly limit exceeded",
            
            # è®¤è¯/æƒé™é”™è¯¯ - ç«‹å³åˆ‡æ¢
            "401", 
            "403",
            "Unauthorized",
            "Forbidden",
            "Invalid API key",
            "API key expired",
            
            # æ¨¡å‹ä¸å¯ç”¨é”™è¯¯ - ç«‹å³åˆ‡æ¢
            "404",
            "Model not found",
            "Model unavailable",
            "Service unavailable",
            "Model is overloaded",
            
            # æœåŠ¡å™¨å†…éƒ¨é”™è¯¯ - ç«‹å³åˆ‡æ¢
            "500",
            "502", 
            "503",
            "504",
            "Internal server error",
            "Bad gateway",
            "Gateway timeout",
            
            # å‚æ•°é”™è¯¯ - ç«‹å³åˆ‡æ¢ï¼ˆæ¨¡å‹ä¸æ”¯æŒå½“å‰å‚æ•°ï¼‰
            "Invalid model",
            "Unsupported model",
            "Model does not exist",
            
            # ä¸¥é‡è¶…æ—¶é”™è¯¯ - ç«‹å³åˆ‡æ¢ï¼ˆé¿å…é•¿æ—¶é—´ç­‰å¾…ï¼‰
            "Connection timeout",  # è¿æ¥å±‚é¢çš„è¶…æ—¶
            "Read timeout",        # è¯»å–è¶…æ—¶
            "Gateway timeout"      # ç½‘å…³è¶…æ—¶
        ]
        
        error_lower = error_str.lower()
        for pattern in immediate_switch_patterns:
            if pattern.lower() in error_lower:
                return True
        
        return False
    
    def _get_error_type(self, error_str: str) -> str:
        """è·å–é”™è¯¯ç±»å‹æè¿°"""
        error_lower = error_str.lower()
        
        # ğŸš¨ é«˜ä¼˜å…ˆçº§é”™è¯¯ï¼ˆç«‹å³åˆ‡æ¢ï¼‰
        if any(x in error_lower for x in ["429", "too many requests", "rate limit", "quota exceeded", "request limit exceeded", "è¯·æ±‚è¶…é™", "è¯·æ±‚é™åˆ¶", "è¶…å‡ºé™åˆ¶", "è¾¾åˆ°é™åˆ¶", "exceeded limit", "usage limit", "daily limit", "monthly limit"]):
            return "APIé™æµ"
        elif any(x in error_lower for x in ["401", "403", "unauthorized", "forbidden", "api key"]):
            return "è®¤è¯å¤±è´¥"
        elif any(x in error_lower for x in ["404", "model not found", "model unavailable"]):
            return "æ¨¡å‹ä¸å­˜åœ¨"
        elif any(x in error_lower for x in ["500", "502", "503", "504", "internal server"]):
            return "æœåŠ¡å™¨é”™è¯¯"
        elif any(x in error_lower for x in ["invalid model", "unsupported model"]):
            return "æ¨¡å‹ä¸æ”¯æŒ"
        elif any(x in error_lower for x in ["connection timeout", "read timeout", "gateway timeout"]):
            return "ç½‘ç»œè¶…æ—¶"
        elif any(x in error_lower for x in ["timeout", "timed out"]):
            return "å¤„ç†è¶…æ—¶"
        
        # ğŸ”„ ä¸€èˆ¬é”™è¯¯ï¼ˆå¯é‡è¯•ï¼‰  
        elif any(x in error_lower for x in ["connection", "network"]):
            return "ç½‘ç»œè¿æ¥"
        elif any(x in error_lower for x in ["json", "parse", "format"]):
            return "æ ¼å¼é”™è¯¯"
        elif "empty" in error_lower or "ç©º" in error_str:
            return "ç©ºå“åº”"
        else:
            return "æœªçŸ¥é”™è¯¯"
        
    def _ensure_api_connection(self):
        """ğŸ”Œ ç¡®ä¿APIè¿æ¥å·²åˆå§‹åŒ–ï¼ˆä½¿ç”¨å…¨å±€çŠ¶æ€ï¼‰"""
        if self._api_initialized and self.client:
            return True
        
        current_api_key = get_current_api_key()
        current_model = get_current_model()
        
        try:
            print(f"ğŸ”„ è¿æ¥API... (æ¨¡å‹: {current_model.split('/')[-1]}, Key: ***{current_api_key[-8:]})")
            self.client = OpenAI(
                base_url=self.api_base_url,
                api_key=current_api_key,
                max_retries=0,  # ç¦ç”¨å†…ç½®é‡è¯•
                timeout=250.0   # 250ç§’è¶…æ—¶
            )
            
            # ç®€å•æµ‹è¯•è¿æ¥
            response = self.client.chat.completions.create(
                model=current_model,
                messages=[{"role": "user", "content": "test"}],
                max_tokens=5,
                temperature=0.1,
                timeout=250
            )
            
            self._api_initialized = True
            print(f"âœ… APIè¿æ¥æˆåŠŸ")
            return True
            
        except Exception as e:
            error_str = str(e)
            print(f"âŒ APIè¿æ¥å¤±è´¥: {error_str[:100]}")
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç«‹å³åˆ‡æ¢
            if self._should_switch_immediately(error_str):
                error_type = self._get_error_type(error_str)
                print(f"ğŸ”„ æ£€æµ‹åˆ°éœ€è¦ç«‹å³åˆ‡æ¢çš„é”™è¯¯: {error_type}")
                self._handle_failure(f"è¿æ¥-{error_type}", force_switch=True)
            else:
                self._handle_failure(f"è¿æ¥-{self._get_error_type(error_str)}")
            
            # é‡ç½®è¿æ¥çŠ¶æ€
            self.client = None
            self._api_initialized = False
            return False
    
    def _convert_local_path_to_base64(self, file_path: str) -> Optional[str]:
        """å°†æœ¬åœ°æ–‡ä»¶è·¯å¾„è½¬æ¢ä¸ºbase64æ ¼å¼çš„æ•°æ®URL"""
        
        # è·å–ç›®å½•ä¿¡æ¯
        current_dir = os.getcwd()
        parent_dir = os.path.dirname(current_dir)
        grandparent_dir = os.path.dirname(parent_dir)
        
        # å°è¯•è·¯å¾„è§£æ - ä¸“æ³¨äºLabel Studioåª’ä½“ç›®å½•
        possible_paths = []
        
        # 1. Label Studio å®é™…åª’ä½“ç›®å½• (Windows) - ä¸»è¦è·¯å¾„
        label_studio_media_dir = r'C:\Users\Administrator\AppData\Local\label-studio\label-studio\media'
        
        if os.path.exists(label_studio_media_dir):
            # å¤„ç†è·¯å¾„ï¼šç§»é™¤å¼€å¤´çš„æ–œæ ï¼Œç›´æ¥ä½¿ç”¨ç›¸å¯¹è·¯å¾„
            relative_path = file_path.lstrip('/')
            possible_paths.append(os.path.join(label_studio_media_dir, relative_path))
        else:
            print(f"   âŒ Label Studioåª’ä½“ç›®å½•ä¸å­˜åœ¨: {label_studio_media_dir}")
        
        # 2. å¤‡ç”¨è·¯å¾„ (ä»…å½“ä¸»è·¯å¾„ä¸å­˜åœ¨æ—¶)
        backup_media_dirs = [
            os.path.expanduser(r'~\AppData\Local\label-studio\label-studio\media'),
            r'C:\Users\%USERNAME%\AppData\Local\label-studio\label-studio\media',
        ]
        
        for backup_dir in backup_media_dirs:
            if os.path.exists(backup_dir):
                relative_path = file_path.lstrip('/')
                possible_paths.append(os.path.join(backup_dir, relative_path))
        
        # 3. é…ç½®çš„åª’ä½“ç›®å½• (å¦‚æœè®¾ç½®äº†ç¯å¢ƒå˜é‡)
        if LABEL_STUDIO_MEDIA_DIR and os.path.exists(LABEL_STUDIO_MEDIA_DIR):
            relative_path = file_path.lstrip('/')
            possible_paths.append(os.path.join(LABEL_STUDIO_MEDIA_DIR, relative_path))
        
        # 4. åŸå§‹è·¯å¾„ (æœ€åå¤‡ç”¨)
        # åˆ é™¤è·¯å¾„ä¸­å¼€å§‹çš„/data/æ–‡ä»¶å¤¹
        file_path = file_path.replace('/data/', '')
        possible_paths.append(file_path)
        
        # æµ‹è¯•æ¯ä¸ªå¯èƒ½çš„è·¯å¾„
        for i, test_path in enumerate(possible_paths):
            test_path = test_path.replace('\data', '')
            
            if os.path.exists(test_path):
                file_path = test_path
                break
        else:
            print(f"\nâŒ æœªæ‰¾åˆ°Label Studioåª’ä½“æ–‡ä»¶!")
            return self._create_config_guidance_message()
        
        try:
            # è·å–æ–‡ä»¶æ‰©å±•åæ¥ç¡®å®šMIMEç±»å‹
            _, ext = os.path.splitext(file_path)
            ext = ext.lower().lstrip('.')
            
            mime_type_map = {
                'jpg': 'image/jpeg',
                'jpeg': 'image/jpeg', 
                'png': 'image/png',
                'gif': 'image/gif',
                'webp': 'image/webp',
                'bmp': 'image/bmp'
            }
            
            mime_type = mime_type_map.get(ext, 'image/jpeg')
            
            # è¯»å–æ–‡ä»¶å¹¶è½¬æ¢ä¸ºbase64
            with open(file_path, 'rb') as image_file:
                image_data = image_file.read()
                base64_data = base64.b64encode(image_data).decode('utf-8')
                
            # æ„å»ºdata URL
            data_url = f"data:{mime_type};base64,{base64_data}"
            
            return data_url
            
        except Exception as e:
            print(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
            return None
    
    def _create_config_guidance_message(self) -> str:
        """åˆ›å»ºé…ç½®æŒ‡å¼•æ¶ˆæ¯ï¼ˆå½“æ–‡ä»¶æœªæ‰¾åˆ°æ—¶çš„fallbackï¼‰"""
        return """âš ï¸ é…ç½®é—®é¢˜ï¼šæ— æ³•è®¿é—®ä¸Šä¼ çš„å›¾ç‰‡æ–‡ä»¶

ğŸ”§ è§£å†³æ–¹æ¡ˆï¼š

1ï¸âƒ£ æ£€æŸ¥Label Studioé…ç½®
   - ç¡®ä¿å¯ç”¨äº†æœ¬åœ°æ–‡ä»¶æœåŠ¡
   - è®¾ç½®æ­£ç¡®çš„æ–‡ä»¶æ ¹ç›®å½•

2ï¸âƒ£ æ£€æŸ¥æ–‡ä»¶è·¯å¾„
   - ç¡®ä¿æ–‡ä»¶å·²æ­£ç¡®ä¸Šä¼ åˆ°Label Studio
   - æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åœ¨æ­£ç¡®çš„åª’ä½“ç›®å½•ä¸­

3ï¸âƒ£ ä½¿ç”¨Base64ä¸Šä¼ 
   - ç›´æ¥ä¸Šä¼ base64ç¼–ç çš„å›¾ç‰‡
   - é¿å…æ–‡ä»¶è·¯å¾„ä¾èµ–é—®é¢˜

4ï¸âƒ£ é…ç½®ç¯å¢ƒå˜é‡
   - LABEL_STUDIO_MEDIA_DIR=your_media_path
   - é‡å¯ML BackendæœåŠ¡

è¯·è”ç³»ç®¡ç†å‘˜é…ç½®æ–‡ä»¶æœåŠ¡åé‡è¯•ã€‚"""
    
    def _format_config_guidance_prediction(self, guidance_message: str, task: Dict) -> Dict:
        """æ ¼å¼åŒ–é…ç½®æŒ‡å¼•æ¶ˆæ¯ä¸ºLabel Studioé¢„æµ‹æ ¼å¼"""
        
        # åŠ¨æ€è·å–å­—æ®µå
        from_name, to_name = self._get_field_names()
        
        prediction = {
            "model_version": self.get("model_version"),
            "score": 0.1,  # ä½åˆ†è¡¨ç¤ºè¿™æ˜¯é…ç½®é—®é¢˜
            "result": [{
                "from_name": from_name,
                "to_name": to_name, 
                "type": "textarea",
                "value": {
                    "text": [guidance_message]
                }
            }]
        }
        
        return prediction


    def predict(self, tasks: List[Dict], context: Optional[Dict] = None, **kwargs) -> ModelResponse:
        """ ç¾å®³å›¾ç‰‡æ¡†é€‰æ ‡æ³¨é¢„æµ‹
            :param tasks: Label Studio tasks in JSON format (åŒ…å«å›¾ç‰‡æ•°æ®)
            :param context: Label Studio context in JSON format
            :return: ModelResponse with predictions (çŸ©å½¢æ¡†æ ‡æ³¨)
        """
        
        predictions = []
        
        for i, task in enumerate(tasks):
            try:
                prediction = self._process_single_task(task)
                if prediction:
                    predictions.append(prediction)
                else:
                    predictions.append({
                        "model_version": self.get("model_version"),
                        "score": 0.0,
                        "result": []
                    })
            except Exception as e:
                print(f"âŒ ä»»åŠ¡ {i+1} å¤„ç†å¤±è´¥: {e}")
                predictions.append({
                    "model_version": self.get("model_version"),
                    "score": 0.0,
                    "result": []
                })
        
        # è¾“å‡ºæœ€ç»ˆè¿”å›çš„JSONç»“æœ
        print("\n" + "="*60)
        print("ğŸ“¤ æœ€ç»ˆè¿”å›çš„JSONç»“æœ:")
        print("="*60)
        for i, prediction in enumerate(predictions):
            print(f"\n--- é¢„æµ‹ç»“æœ {i+1} ---")
            print(json.dumps(prediction, indent=2, ensure_ascii=False))
        print("\n" + "="*60)
        
        return ModelResponse(predictions=predictions)
    
    def _process_single_task(self, task: Dict) -> Optional[Dict]:
        """å¤„ç†å•ä¸ªæ¡†é€‰æ ‡æ³¨ä»»åŠ¡"""
        
        task_data = task.get('data', {})
        
        # æå–å›¾ç‰‡å†…å®¹
        image_url = None
        image_data = None
        
        # æŸ¥æ‰¾å›¾ç‰‡URL
        for key, value in task_data.items():
            if isinstance(value, str):
                # ä¼˜å…ˆæ£€æŸ¥imageå­—æ®µï¼ˆæ¨¡æ¿ä¸­çš„å›¾ç‰‡å­—æ®µï¼‰
                if key in ['image', 'img', 'photo', 'picture', 'url']:
                    image_url = value
                    break
                elif value.startswith(('http://', 'https://', 'data:image/')):
                    image_url = value
                    break
        
        if not image_url:
            return None
        
        # å¤„ç†å›¾ç‰‡æ•°æ®
        if image_url.startswith('data:image/'):
            # Base64ç¼–ç çš„å›¾ç‰‡
            image_data = image_url
            
        elif image_url.startswith(('http://', 'https://')):
            # ç½‘ç»œURLå›¾ç‰‡
            image_data = image_url
            
        else:
            # æœ¬åœ°æ–‡ä»¶è·¯å¾„
            # è½¬æ¢æœ¬åœ°æ–‡ä»¶ä¸ºbase64
            image_data = self._convert_local_path_to_base64(image_url)
            
            if not image_data:
                return None
            
            # æ£€æŸ¥æ˜¯å¦è¿”å›çš„æ˜¯é…ç½®æŒ‡å¼•æ¶ˆæ¯
            if image_data.startswith("âš ï¸ é…ç½®é—®é¢˜"):
                return self._format_config_guidance_prediction(image_data, task)
        
        # æ„å»ºæ¡†é€‰æ ‡æ³¨æç¤ºè¯
        prompt = """è¯·åˆ†æè¿™å¼ ç¾å®³å›¾ç‰‡ï¼Œè¯†åˆ«å¹¶æ ‡æ³¨ä»¥ä¸‹åŒºåŸŸå’Œå¯¹è±¡ï¼š

æ ‡æ³¨ç±»åˆ«ï¼ˆè¯·ä»ä»¥ä¸‹ç±»åˆ«ä¸­é€‰æ‹©åˆé€‚çš„è¿›è¡Œæ ‡æ³¨ï¼‰ï¼š
1. ç§¯æ°´æ·¹æ²¡åŒºåŸŸ - è¢«æ´ªæ°´æ·¹æ²¡çš„åŒºåŸŸ
2. å—ç¾å»ºç­‘ç‰© - å—åˆ°ç¾å®³å½±å“çš„å»ºç­‘ç‰©
3. å—ç¾é“è·¯ - å—åˆ°ç¾å®³å½±å“çš„é“è·¯
4. å—ç¾äººå‘˜ - å—åˆ°ç¾å®³å½±å“çš„äººå‘˜
5. å—ç¾è½¦è¾† - å—åˆ°ç¾å®³å½±å“çš„è½¦è¾†
6. æ•‘æ´äººå‘˜ - å‚ä¸æ•‘æ´çš„äººå‘˜
7. æ•‘æ´è½¦è¾† - å‚ä¸æ•‘æ´çš„è½¦è¾†
8. æ ‘æœ¨å†œç”°å—æŸåŒº - å—æŸçš„æ ‘æœ¨å’Œå†œç”°åŒºåŸŸ
9. ç”µåŠ›è®¾æ–½ - ç”µåŠ›ç›¸å…³è®¾æ–½
10. æ¡¥æ¢å ¤å - æ¡¥æ¢å’Œå ¤åè®¾æ–½
11. äº¤é€šè®¾æ–½ - äº¤é€šç›¸å…³è®¾æ–½
12. æ¼‚æµ®ç‰© - æ°´ä¸­çš„æ¼‚æµ®ç‰©

è¯·ä»¥JSONæ ¼å¼è¿”å›æ ‡æ³¨ç»“æœï¼ŒåŒ…å«æ¯ä¸ªåŒºåŸŸ/å¯¹è±¡çš„ç±»åˆ«ã€ä½ç½®åæ ‡å’Œç½®ä¿¡åº¦ã€‚æ ¼å¼å¦‚ä¸‹ï¼š
{
  "annotations": [
    {
      "label": "ç§¯æ°´æ·¹æ²¡åŒºåŸŸ",
      "bbox": [x1, y1, x2, y2],
      "confidence": 0.95
    }
  ]
}

**é‡è¦åæ ‡è¦æ±‚**ï¼š
- åæ ‡æ ¼å¼ï¼š[å·¦ä¸Šè§’x%, å·¦ä¸Šè§’y%, å³ä¸‹è§’x%, å³ä¸‹è§’y%]
- åæ ‡å€¼å¿…é¡»æ˜¯0-100ä¹‹é—´çš„ç™¾åˆ†æ¯”æ•°å€¼ï¼ˆä¸æ˜¯åƒç´ å€¼ï¼‰
- ä¾‹å¦‚ï¼š[10.5, 15.2, 45.8, 67.3] è¡¨ç¤ºä»å›¾ç‰‡å®½åº¦10.5%ï¼Œé«˜åº¦15.2%ä½ç½®åˆ°å®½åº¦45.8%ï¼Œé«˜åº¦67.3%ä½ç½®çš„çŸ©å½¢æ¡†
- å·¦ä¸Šè§’åæ ‡ < å³ä¸‹è§’åæ ‡
- æ‰€æœ‰åæ ‡å€¼èŒƒå›´ï¼š0 â‰¤ åæ ‡å€¼ â‰¤ 100

**åæ ‡ç¤ºä¾‹**ï¼š
- å›¾ç‰‡å·¦ä¸Šè§’åŒºåŸŸï¼š[5.0, 5.0, 30.0, 25.0]
- å›¾ç‰‡ä¸­å¿ƒåŒºåŸŸï¼š[35.0, 35.0, 65.0, 65.0]  
- å›¾ç‰‡å³ä¸‹è§’åŒºåŸŸï¼š[70.0, 75.0, 95.0, 95.0]

è¯·ä¸¥æ ¼æŒ‰ç…§ç™¾åˆ†æ¯”æ ¼å¼è¿”å›åæ ‡ï¼Œè¿™å¯¹å‡†ç¡®æ ‡æ³¨è‡³å…³é‡è¦ï¼"""
        
        # è°ƒç”¨å¤šæ¨¡æ€APIï¼ˆä½¿ç”¨æ™ºèƒ½åˆ‡æ¢ç‰ˆæœ¬ï¼‰
        api_response = self._call_multimodal_api_with_switching(prompt, image_data)
        
        if api_response:
            return self._format_annotation_prediction(api_response, task)
        else:
            return None
    
    def _call_multimodal_api_with_switching(self, prompt: str, image_data: str) -> Optional[str]:
        """ğŸš€ æ™ºèƒ½åˆ‡æ¢ç‰ˆæœ¬çš„å¤šæ¨¡æ€APIè°ƒç”¨ï¼ˆä½¿ç”¨å…¨å±€çŠ¶æ€ç®¡ç†ï¼‰"""
        import time
        
        max_total_attempts = len(available_models_global) * 2  # æ€»å…±å°è¯•æ¬¡æ•°
        
        for attempt in range(max_total_attempts):
            # ç¡®ä¿APIè¿æ¥å¯ç”¨
            if not self._ensure_api_connection():
                continue  # å·²ç»åœ¨è¿æ¥æ—¶å¤„ç†äº†åˆ‡æ¢ï¼Œç»§ç»­ä¸‹ä¸€æ¬¡å°è¯•
            
            current_model = get_current_model()
            try:
                print(f"ğŸ”„ è°ƒç”¨å¤šæ¨¡æ€API (å°è¯• {attempt + 1}/{max_total_attempts})")
                print(f"   ğŸ“¡ æ¨¡å‹: {current_model.split('/')[-1]} | â° è¶…æ—¶: 250s | ğŸ’¾ æœ€å¤§token: 1000")
                
                start_time = time.time()
                
                # æ„å»ºå¤šæ¨¡æ€æ¶ˆæ¯
                system_message = "You are a helpful assistant specialized in disaster image analysis and rectangle annotation. Please provide accurate annotation results in JSON format."
                
                messages = [
                    {
                        "role": "system", 
                        "content": system_message
                    },
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": image_data
                                }
                            }
                        ]
                    }
                ]
                
                response = self.client.chat.completions.create(
                    model=current_model,
                    messages=messages,
                    max_tokens=1000,
                    temperature=0.7,
                    top_p=0.9,
                    stream=False,
                    timeout=250
                )
                
                end_time = time.time()
                api_duration = end_time - start_time
                
                if response.choices and len(response.choices) > 0:
                    choice = response.choices[0]
                    
                    if hasattr(choice, 'message'):
                        message = choice.message
                        content = getattr(message, 'content', None)
                        
                        if content and content.strip():
                            # æˆåŠŸ
                            self._handle_success()
                            print(f"   âœ… æˆåŠŸ (è€—æ—¶: {api_duration:.1f}s, é•¿åº¦: {len(content)})")
                            return content
                        else:
                            print(f"âš ï¸ è¿”å›ç©ºå†…å®¹")
                            self._handle_failure("ç©ºå“åº”")
                    else:
                        print(f"âš ï¸ æ— æ¶ˆæ¯å†…å®¹")
                        self._handle_failure("æ— æ¶ˆæ¯")
                else:
                    print(f"âš ï¸ æ— å“åº”choices")
                    self._handle_failure("æ— å“åº”")
                        
            except Exception as e:
                error_str = str(e)
                print(f"âŒ å¤šæ¨¡æ€APIå¼‚å¸¸: {error_str[:100]}")
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦ç«‹å³åˆ‡æ¢
                if self._should_switch_immediately(error_str):
                    error_type = self._get_error_type(error_str)
                    print(f"ğŸ”„ ç«‹å³åˆ‡æ¢é”™è¯¯: {error_type}")
                    self._handle_failure(f"ç«‹å³åˆ‡æ¢-{error_type}", force_switch=True)
                else:
                    self._handle_failure(f"APIå¼‚å¸¸-{self._get_error_type(error_str)}")
        
        print("âŒ æ‰€æœ‰å°è¯•éƒ½å¤±è´¥")
        return None
    
    def _call_multimodal_api(self, prompt: str, image_data: str) -> Optional[str]:
        """è°ƒç”¨å¤šæ¨¡æ€APIè¿›è¡Œæ¡†é€‰æ ‡æ³¨"""
        
        if not self.client:
            return None
        
        try:
            # æ„å»ºå¤šæ¨¡æ€æ¶ˆæ¯
            system_message = "You are a helpful assistant specialized in disaster image analysis and rectangle annotation. Please provide accurate annotation results in JSON format."
            
            messages = [
                {
                    "role": "system", 
                    "content": system_message
                },
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": image_data
                            }
                        }
                    ]
                }
            ]
            
            response = self.client.chat.completions.create(
                model=get_current_model(),
                messages=messages,
                max_tokens=1000,
                temperature=0.7,
                top_p=0.9,
                stream=False
            )
            
            if response.choices and len(response.choices) > 0:
                choice = response.choices[0]
                
                if hasattr(choice, 'message'):
                    message = choice.message
                    content = getattr(message, 'content', None)
                    
                    if content:
                        return content
                
            return None
                
        except Exception as e:
            print(f"âŒ å¤šæ¨¡æ€APIè°ƒç”¨å¼‚å¸¸: {str(e)}")
            return None
    
    def _pixel_to_percentage(self, pixel_coords: List[float], image_width: int, image_height: int) -> List[float]:
        """å°†åƒç´ åæ ‡è½¬æ¢ä¸ºç™¾åˆ†æ¯”åæ ‡"""
        x1, y1, x2, y2 = pixel_coords
        
        # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
        x1_percent = (x1 / image_width) * 100
        y1_percent = (y1 / image_height) * 100
        x2_percent = (x2 / image_width) * 100
        y2_percent = (y2 / image_height) * 100
        
        return [x1_percent, y1_percent, x2_percent, y2_percent]
    
    def _get_image_dimensions(self, task: Dict) -> tuple:
        """å°è¯•è·å–å›¾ç‰‡çš„çœŸå®å°ºå¯¸"""
        try:
            import requests
            from PIL import Image
            import io
            
            # è·å–å›¾ç‰‡æ•°æ®
            task_data = task.get('data', {})
            image_url = None
            
            for key, value in task_data.items():
                if isinstance(value, str) and (key in ['image', 'img', 'photo', 'picture', 'url', 'captioning'] or 
                                              value.startswith(('http://', 'https://', 'data:image/', '/'))):
                    image_url = value
                    break
            
            if not image_url:
                return None, None
            
            if image_url.startswith('data:image/'):
                # Base64ç¼–ç çš„å›¾ç‰‡
                import base64
                header, data = image_url.split(',', 1)
                image_data = base64.b64decode(data)
                image = Image.open(io.BytesIO(image_data))
                return image.width, image.height
                
            elif image_url.startswith(('http://', 'https://')):
                # ç½‘ç»œURLå›¾ç‰‡
                response = requests.get(image_url, timeout=10)
                image = Image.open(io.BytesIO(response.content))
                return image.width, image.height
                
            else:
                # æœ¬åœ°æ–‡ä»¶è·¯å¾„ - ä½¿ç”¨ç°æœ‰çš„è·¯å¾„è§£æé€»è¾‘
                image_data = self._convert_local_path_to_base64(image_url)
                if image_data and image_data.startswith('data:image/'):
                    import base64
                    header, data = image_data.split(',', 1)
                    image_bytes = base64.b64decode(data)
                    image = Image.open(io.BytesIO(image_bytes))
                    return image.width, image.height
                    
        except Exception as e:
            print(f"âš ï¸ æ— æ³•è·å–å›¾ç‰‡å°ºå¯¸: {e}")
            
        return None, None
    
    def _detect_coordinate_type(self, x1: float, y1: float, x2: float, y2: float, task: Dict) -> str:
        """æ”¹è¿›çš„åæ ‡ç±»å‹æ£€æµ‹"""
        max_coord = max(x1, y1, x2, y2)
        min_coord = min(x1, y1, x2, y2)
        
        # è·å–å›¾ç‰‡å°ºå¯¸ä½œä¸ºå‚è€ƒ
        image_width, image_height = self._get_image_dimensions(task)
        
        if image_width and image_height:
            # å¦‚æœæœ‰å›¾ç‰‡å°ºå¯¸ï¼Œæ£€æŸ¥æ˜¯å¦ä¸ºåƒç´ åæ ‡
            max_image_dim = max(image_width, image_height)
            min_image_dim = min(image_width, image_height)
            
            if max_coord > max_image_dim:
                print(f"âš ï¸ åæ ‡è¶…å‡ºå›¾ç‰‡å°ºå¯¸ï¼Œå¯èƒ½æœ‰è¯¯: max_coord={max_coord}, image_size={image_width}x{image_height}")
                return "pixel"  # ä»æŒ‰åƒç´ å¤„ç†ï¼Œä½†ä¼šè¢«é™åˆ¶
            elif max_coord > min_image_dim * 0.8:
                print(f"ğŸ” åæ ‡æ¥è¿‘å›¾ç‰‡å°ºå¯¸ï¼Œåˆ¤å®šä¸ºåƒç´ åæ ‡: max_coord={max_coord}, image_size={image_width}x{image_height}")
                return "pixel"
        
        # æ ‡å‡†åŒ–åæ ‡ (0-1)
        if max_coord <= 1.0 and min_coord >= 0:
            print(f"âœ… æ£€æµ‹åˆ°æ ‡å‡†åŒ–åæ ‡(0-1): èŒƒå›´[{min_coord:.3f}, {max_coord:.3f}]")
            return "normalized"
        
        # ç™¾åˆ†æ¯”åæ ‡ (0-100)
        elif max_coord <= 100 and min_coord >= 0:
            # è¿›ä¸€æ­¥æ£€æŸ¥ï¼šå¦‚æœæ‰€æœ‰åæ ‡éƒ½æ˜¯æ•´æ•°ä¸”è¾ƒå°ï¼Œå¯èƒ½æ˜¯åƒç´ åæ ‡
            if (all(abs(c - round(c)) < 0.01 for c in [x1, y1, x2, y2]) and 
                max_coord < 50 and 
                not image_width):  # æ²¡æœ‰å›¾ç‰‡å°ºå¯¸ä¿¡æ¯æ—¶æ›´ä¿å®ˆ
                print(f"ğŸ¤” ç–‘ä¼¼å°å°ºå¯¸åƒç´ åæ ‡: èŒƒå›´[{min_coord}, {max_coord}]ï¼ŒæŒ‰ç™¾åˆ†æ¯”å¤„ç†")
                return "percentage"  # å€¾å‘äºæŒ‰ç™¾åˆ†æ¯”å¤„ç†ï¼Œæ›´å®‰å…¨
            print(f"âœ… æ£€æµ‹åˆ°ç™¾åˆ†æ¯”åæ ‡: èŒƒå›´[{min_coord}, {max_coord}]")
            return "percentage"
        
        # åƒç´ åæ ‡ï¼ˆå¤§æ•°å€¼ï¼‰
        else:
            print(f"ğŸ” æ£€æµ‹åˆ°åƒç´ åæ ‡: èŒƒå›´[{min_coord}, {max_coord}]")
            return "pixel"
    
    def _normalize_coordinates(self, x1: float, y1: float, x2: float, y2: float, task: Dict) -> tuple:
        """æ™ºèƒ½æ ‡å‡†åŒ–åæ ‡ä¸ºç™¾åˆ†æ¯”æ ¼å¼"""
        
        # ä½¿ç”¨æ”¹è¿›çš„åæ ‡ç±»å‹æ£€æµ‹
        coord_type = self._detect_coordinate_type(x1, y1, x2, y2, task)
        
        if coord_type == "percentage":
            print(f"âœ… æ£€æµ‹åˆ°ç™¾åˆ†æ¯”åæ ‡ï¼Œç›´æ¥ä½¿ç”¨")
            return x1, y1, x2, y2
        
        elif coord_type == "normalized":
            print(f"âœ… æ£€æµ‹åˆ°æ ‡å‡†åŒ–åæ ‡(0-1)ï¼Œè½¬æ¢ä¸ºç™¾åˆ†æ¯”")
            return x1 * 100, y1 * 100, x2 * 100, y2 * 100
        
        elif coord_type == "pixel":
            # åƒç´ åæ ‡ï¼Œå°è¯•è·å–å›¾ç‰‡çœŸå®å°ºå¯¸è¿›è¡Œè½¬æ¢
            print(f"ğŸ” æ£€æµ‹åˆ°åƒç´ åæ ‡ï¼Œå°è¯•è·å–å›¾ç‰‡å°ºå¯¸è¿›è¡Œç²¾ç¡®è½¬æ¢")
            image_width, image_height = self._get_image_dimensions(task)
            
            if image_width and image_height:
                print(f"ğŸ“ è·å–åˆ°å›¾ç‰‡å°ºå¯¸: {image_width}x{image_height}")
                x1_percent = (x1 / image_width) * 100
                y1_percent = (y1 / image_height) * 100
                x2_percent = (x2 / image_width) * 100
                y2_percent = (y2 / image_height) * 100
                
                # ç¡®ä¿åæ ‡åœ¨åˆç†èŒƒå›´å†…
                x1_percent = max(0, min(100, x1_percent))
                y1_percent = max(0, min(100, y1_percent))
                x2_percent = max(0, min(100, x2_percent))
                y2_percent = max(0, min(100, y2_percent))
                
                print(f"âœ… ç²¾ç¡®è½¬æ¢å®Œæˆ: [{x1_percent:.1f}, {y1_percent:.1f}, {x2_percent:.1f}, {y2_percent:.1f}]")
                return x1_percent, y1_percent, x2_percent, y2_percent
            else:
                # æ— æ³•è·å–å›¾ç‰‡å°ºå¯¸ï¼Œä½¿ç”¨æ”¹è¿›çš„å¯å‘å¼æ–¹æ³•
                print(f"âš ï¸ æ— æ³•è·å–å›¾ç‰‡å°ºå¯¸ï¼Œä½¿ç”¨æ”¹è¿›çš„å¯å‘å¼è½¬æ¢")
                return self._heuristic_coordinate_conversion(x1, y1, x2, y2)
        
        else:
            # æœªçŸ¥ç±»å‹ï¼Œä½¿ç”¨å¯å‘å¼æ–¹æ³•
            print(f"âš ï¸ æœªçŸ¥åæ ‡ç±»å‹ï¼Œä½¿ç”¨å¯å‘å¼è½¬æ¢")
            return self._heuristic_coordinate_conversion(x1, y1, x2, y2)
    
    def _heuristic_coordinate_conversion(self, x1: float, y1: float, x2: float, y2: float) -> tuple:
        """æ”¹è¿›çš„å¯å‘å¼åæ ‡è½¬æ¢"""
        max_coord = max(x1, y1, x2, y2)
        
        # åŸºäºåæ ‡æ•°å€¼ç‰¹å¾è¿›è¡Œæ›´ç²¾ç¡®çš„æ¨æµ‹
        if max_coord > 5000:
            # è¶…é«˜åˆ†è¾¨ç‡ (4K+ å›¾ç‰‡)
            estimated_size = 6000
            print(f"ğŸ”§ æ¨æµ‹ä¸ºè¶…é«˜åˆ†è¾¨ç‡å›¾ç‰‡ (~6000px)")
        elif max_coord > 2000:
            # é«˜åˆ†è¾¨ç‡ (2K-4K å›¾ç‰‡)
            estimated_size = 3000
            print(f"ğŸ”§ æ¨æµ‹ä¸ºé«˜åˆ†è¾¨ç‡å›¾ç‰‡ (~3000px)")
        elif max_coord > 1000:
            # æ ‡å‡†åˆ†è¾¨ç‡ (1K-2K å›¾ç‰‡)
            estimated_size = 1500
            print(f"ğŸ”§ æ¨æµ‹ä¸ºæ ‡å‡†åˆ†è¾¨ç‡å›¾ç‰‡ (~1500px)")
        elif max_coord > 500:
            # ä¸­ç­‰åˆ†è¾¨ç‡ (500-1000px å›¾ç‰‡)
            estimated_size = 800
            print(f"ğŸ”§ æ¨æµ‹ä¸ºä¸­ç­‰åˆ†è¾¨ç‡å›¾ç‰‡ (~800px)")
        elif max_coord > 200:
            # å°å°ºå¯¸å›¾ç‰‡ (200-500px)
            estimated_size = 400
            print(f"ğŸ”§ æ¨æµ‹ä¸ºå°å°ºå¯¸å›¾ç‰‡ (~400px)")
        else:
            # å¾ˆå°çš„åæ ‡å€¼ï¼Œå¯èƒ½å·²ç»æ˜¯ç™¾åˆ†æ¯”æˆ–æ ‡å‡†åŒ–åæ ‡
            if max_coord > 100:
                estimated_size = 200  # æŒ‰å°å›¾ç‰‡å¤„ç†
                print(f"ğŸ”§ æ¨æµ‹ä¸ºå¾®å°å›¾ç‰‡ (~200px)")
            else:
                # ç›´æ¥æŒ‰ç™¾åˆ†æ¯”å¤„ç†
                print(f"ğŸ”§ åæ ‡å€¼å¾ˆå°ï¼Œç›´æ¥æŒ‰ç™¾åˆ†æ¯”å¤„ç†")
                return max(0, min(100, x1)), max(0, min(100, y1)), max(0, min(100, x2)), max(0, min(100, y2))
        
        # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
        x1_percent = (x1 / estimated_size) * 100
        y1_percent = (y1 / estimated_size) * 100
        x2_percent = (x2 / estimated_size) * 100
        y2_percent = (y2 / estimated_size) * 100
        
        # é™åˆ¶åœ¨åˆç†èŒƒå›´å†…ï¼Œå¹¶æ·»åŠ è¾¹ç•Œæ£€æŸ¥
        x1_final = max(0, min(100, x1_percent))
        y1_final = max(0, min(100, y1_percent))
        x2_final = max(0, min(100, x2_percent))
        y2_final = max(0, min(100, y2_percent))
        
        # æ£€æŸ¥è½¬æ¢ç»“æœçš„åˆç†æ€§
        if x2_final <= x1_final or y2_final <= y1_final:
            print(f"âš ï¸ å¯å‘å¼è½¬æ¢äº§ç”Ÿæ— æ•ˆçŸ©å½¢ï¼Œè°ƒæ•´åæ ‡")
            # ç¡®ä¿æœ€å°å°ºå¯¸
            if x2_final <= x1_final:
                x2_final = min(100, x1_final + 1.0)
            if y2_final <= y1_final:
                y2_final = min(100, y1_final + 1.0)
        
        print(f"âš ï¸ å¯å‘å¼è½¬æ¢ç»“æœ: [{x1_final:.1f}, {y1_final:.1f}, {x2_final:.1f}, {y2_final:.1f}]")
        return x1_final, y1_final, x2_final, y2_final
    
    def _validate_coordinates(self, x: float, y: float, width: float, height: float) -> tuple:
        """éªŒè¯å¹¶ä¿®æ­£åæ ‡çš„æœ‰æ•ˆæ€§"""
        # ç¡®ä¿åæ ‡åœ¨0-100èŒƒå›´å†…
        x = max(0, min(100, x))
        y = max(0, min(100, y))
        
        # ç¡®ä¿å®½åº¦å’Œé«˜åº¦ä¸ºæ­£å€¼ä¸”ä¸è¶…å‡ºè¾¹ç•Œ
        width = max(0.1, min(100 - x, width))
        height = max(0.1, min(100 - y, height))
        
        # ç¡®ä¿çŸ©å½¢ä¸ä¼šè¶…å‡ºå›¾ç‰‡è¾¹ç•Œ
        if x + width > 100:
            width = 100 - x
        if y + height > 100:
            height = 100 - y
            
        # æœ€ç»ˆæ£€æŸ¥ï¼šç¡®ä¿æœ€å°å°ºå¯¸
        if width < 0.1:
            width = 0.1
        if height < 0.1:
            height = 0.1
            
        return x, y, width, height
    
    def _format_annotation_prediction(self, api_response: str, task: Dict) -> Dict:
        """æ ¼å¼åŒ–æ¡†é€‰æ ‡æ³¨é¢„æµ‹ç»“æœä¸ºLabel Studioæ ¼å¼"""
        
        # æ„å»ºåŸºç¡€é¢„æµ‹ç»“æ„
        model_version = self.get("model_version")
        
        prediction = {
            "model_version": model_version,
            "score": 0.95,
            "result": []
        }
        
        # åŠ¨æ€è·å–å­—æ®µå
        from_name, to_name = self._get_field_names()
        
        # è§£æAPIå“åº”ä¸­çš„JSONæ•°æ®
        try:
            # å°è¯•ä»å“åº”ä¸­æå–JSON
            import re
            json_match = re.search(r'\{.*\}', api_response, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                detection_data = json.loads(json_str)
                
                if 'annotations' in detection_data:
                    for obj in detection_data['annotations']:
                        if 'label' in obj and 'bbox' in obj:
                            # æ„å»ºLabel StudioçŸ©å½¢æ¡†æ ¼å¼
                            bbox = obj['bbox']
                            confidence = obj.get('confidence', 0.8)
                            
                            # å¤„ç†bboxåæ ‡ï¼š[x1, y1, x2, y2] æ ¼å¼
                            x1, y1, x2, y2 = bbox
                            
                            print(f"ğŸ” åŸå§‹åæ ‡: [{x1}, {y1}, {x2}, {y2}]")
                            
                            # åæ ‡æ ¼å¼æ£€æµ‹å’Œè½¬æ¢
                            x1_percent, y1_percent, x2_percent, y2_percent = self._normalize_coordinates(x1, y1, x2, y2, task)
                            
                            # ç¡®ä¿åæ ‡é¡ºåºæ­£ç¡®ï¼ˆå·¦ä¸Šè§’ -> å³ä¸‹è§’ï¼‰
                            if x1_percent > x2_percent:
                                x1_percent, x2_percent = x2_percent, x1_percent
                            if y1_percent > y2_percent:
                                y1_percent, y2_percent = y2_percent, y1_percent
                            
                            # è®¡ç®—Label Studioéœ€è¦çš„æ ¼å¼ï¼šx, y, width, height (ç™¾åˆ†æ¯”)
                            x = x1_percent
                            y = y1_percent
                            width = x2_percent - x1_percent
                            height = y2_percent - y1_percent
                            
                            # ä½¿ç”¨æ”¹è¿›çš„åæ ‡éªŒè¯å‡½æ•°
                            x, y, width, height = self._validate_coordinates(x, y, width, height)
                            
                            print(f"ğŸ“ éªŒè¯ååæ ‡: x={x:.1f}%, y={y:.1f}%, width={width:.1f}%, height={height:.1f}%")
                            
                            result_item = {
                                "from_name": from_name,
                                "to_name": to_name,
                                "type": "rectanglelabels",
                                "value": {
                                    "x": x,
                                    "y": y,
                                    "width": width,
                                    "height": height,
                                    "rectanglelabels": [obj['label']]
                                },
                                "score": confidence
                            }
                            
                            prediction["result"].append(result_item)
            
            # å¦‚æœæ²¡æœ‰è§£æåˆ°æœ‰æ•ˆçš„æ ‡æ³¨ç»“æœï¼Œå°è¯•ä½¿ç”¨é»˜è®¤æ ‡æ³¨
            if not prediction["result"]:
                # ç”Ÿæˆä¸€äº›ç¤ºä¾‹æ ‡æ³¨æ¡†ï¼ˆç”¨äºæµ‹è¯•ï¼‰- ç™¾åˆ†æ¯”åæ ‡
                sample_objects = [
                    {"label": "ç§¯æ°´æ·¹æ²¡åŒºåŸŸ", "bbox": [10.5, 15.2, 45.8, 50.3], "confidence": 0.8},
                    {"label": "å—ç¾å»ºç­‘ç‰©", "bbox": [55.0, 60.5, 85.2, 90.8], "confidence": 0.7},
                    {"label": "æ•‘æ´äººå‘˜", "bbox": [20.3, 25.7, 35.6, 40.1], "confidence": 0.6}
                ]
                
                for obj in sample_objects:
                    bbox = obj['bbox']
                    result_item = {
                        "from_name": from_name,
                        "to_name": to_name,
                        "type": "rectanglelabels",
                        "value": {
                            "x": bbox[0],
                            "y": bbox[1],
                            "width": bbox[2] - bbox[0],
                            "height": bbox[3] - bbox[1],
                            "rectanglelabels": [obj['label']]
                        },
                        "score": obj['confidence']
                    }
                    
                    prediction["result"].append(result_item)
                    
        except Exception as e:
            print(f"âŒ è§£ææ£€æµ‹ç»“æœå¤±è´¥: {str(e)}")
            # è¿”å›ç©ºç»“æœ
            pass
        
        return prediction
    
    def _format_prediction(self, api_response: str, task: Dict) -> Dict:
        """æ ¼å¼åŒ–é¢„æµ‹ç»“æœä¸ºLabel Studioæ ¼å¼ï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰"""
        
        prediction = {
            "model_version": self.get("model_version"),
            "score": 0.85,
            "result": []
        }
        
        # è¿”å›åŸå§‹æ–‡æœ¬ç»“æœ
        if api_response and api_response.strip():
            prediction["result"].append({
                "from_name": "prediction",
                "to_name": "text",
                "type": "textarea",
                "value": {
                    "text": [api_response.strip()]
                }
            })
        
        return prediction
    
    def _print_status(self):
        """ğŸ“Š ç®€åŒ–çš„çŠ¶æ€æ˜¾ç¤º"""
        current_model = get_current_model()
        current_api_key = get_current_api_key()
        
        print(f"\nğŸ¤– å½“å‰çŠ¶æ€:")
        print(f"   ğŸ¯ æ¨¡å‹: {current_model.split('/')[-1]} (å¤±è´¥: {self.consecutive_failures}/{self.max_failures_before_switch})")
        print(f"   ğŸ”‘ API Key: ***{current_api_key[-8:]} ({GLOBAL_API_KEY_INDEX + 1}/{len(api_key_list)})")
        print(f"   ğŸ“‹ å¯ç”¨æ¨¡å‹: {len(available_models_global)} ä¸ª")
        print(f"   ğŸ”„ å…¨å±€çŠ¶æ€ç®¡ç†: ç®€åŒ–åˆ‡æ¢é€»è¾‘")
    
    def get_status(self) -> Dict:
        """ğŸ” è·å–ç®€åŒ–çŠ¶æ€ä¿¡æ¯"""
        return {
            "current_model": get_current_model(),
            "current_api_key": f"***{get_current_api_key()[-8:]}",
            "consecutive_failures": self.consecutive_failures,
            "max_failures_before_switch": self.max_failures_before_switch,
            "available_models": available_models_global.copy(),
            "total_api_keys": len(api_key_list),
            "global_model_index": GLOBAL_MODEL_INDEX,
            "global_api_key_index": GLOBAL_API_KEY_INDEX,
            "management_type": "simplified_global_state"
        }
    
    def _get_field_names(self) -> tuple:
        """åŠ¨æ€è·å–Label Studioé…ç½®ä¸­çš„å­—æ®µå"""
        try:
            # å°è¯•ä»Label Studioé…ç½®ä¸­è·å–å­—æ®µå
            if hasattr(self, 'label_interface') and self.label_interface:
                # æŸ¥æ‰¾RectangleLabelsæ ‡ç­¾
                rect_from_name, rect_to_name, _ = self.label_interface.get_first_tag_occurence(
                    'RectangleLabels', ['Image']
                )
                if rect_from_name and rect_to_name:
                    return rect_from_name, rect_to_name
            
            # æŸ¥æ‰¾Imageæ ‡ç­¾
            if hasattr(self, 'label_interface') and self.label_interface:
                image_from_name, image_to_name, _ = self.label_interface.get_first_tag_occurence(
                    'Image', []
                )
                if image_from_name:
                    return "label", image_from_name
            
        except Exception as e:
            pass
        
        # æ ¹æ®æ¡†é€‰æ ‡æ³¨æ¨¡æ¿ï¼Œä½¿ç”¨æ­£ç¡®çš„å­—æ®µå
        return "label", "image"
    
    def _extract_choice(self, response: str, choices: List[str]) -> Optional[str]:
        """ä»å“åº”ä¸­æå–æœ€åŒ¹é…çš„é€‰æ‹©"""
        response_lower = response.lower()
        for choice in choices:
            if choice.lower() in response_lower:
                return choice
        return choices[0] if choices else None
    
    def fit(self, event, data, **kwargs):
        """
        è®­ç»ƒ/æ›´æ–°æ¡†é€‰æ ‡æ³¨æ¨¡å‹
        :param event: äº‹ä»¶ç±»å‹ ('ANNOTATION_CREATED', 'ANNOTATION_UPDATED', 'START_TRAINING')
        :param data: äº‹ä»¶æ•°æ®ï¼ˆåŒ…å«å›¾ç‰‡å’ŒçŸ©å½¢æ¡†æ ‡æ³¨ï¼‰
        """
        # è®°å½•æ ‡æ³¨æ•°æ®ç”¨äºæ¨¡å‹ä¼˜åŒ–
        old_data = self.get('annotation_data')
        self.set('annotation_data', 'updated_annotation_data')
        self.set('model_version', 'updated_version')
        print(f"âœ… æ¡†é€‰æ ‡æ³¨æ¨¡å‹å·²æ›´æ–° (äº‹ä»¶: {event})")
        print(f"ğŸ“¸ å·²è®°å½•æ–°çš„æ¡†é€‰æ ‡æ³¨æ•°æ®ï¼Œç”¨äºåç»­æ¨¡å‹ä¼˜åŒ–")

