from typing import List, Dict, Optional
import json
import os
import time
from openai import OpenAI
from label_studio_ml.model import LabelStudioMLBase
from label_studio_ml.response import ModelResponse


# ==================== å‘½åå®ä½“é…ç½® ====================
# ä»é…ç½®æ–‡ä»¶å¯¼å…¥å®ä½“é…ç½®
try:
    from entity_config import get_entity_config, get_entity_labels, get_all_categories, get_entities_by_category
    NER_ENTITY_CONFIG = get_entity_config()
    ENTITY_LABELS = get_entity_labels()
    print(f"âœ… ä»é…ç½®æ–‡ä»¶åŠ è½½äº† {len(ENTITY_LABELS)} ç§å®ä½“ç±»å‹")
    print(f"ğŸ“‹ åŒ…å«ç±»åˆ«: {', '.join(get_all_categories())}")
except ImportError:
    # å¦‚æœé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
    print("âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œé€€å‡ºç¨‹åº!!!")
    exit()
   


# ç”Ÿæˆå®ä½“ç±»å‹è¯´æ˜æ–‡æœ¬
def get_entity_types_description():
    """ç”Ÿæˆå®ä½“ç±»å‹çš„è¯´æ˜æ–‡æœ¬"""
    descriptions = []
    for label, config in NER_ENTITY_CONFIG.items():
        descriptions.append(f"{label}({config['description']})")
    return "ã€".join(descriptions)

# ç”ŸæˆJSONæ ¼å¼ç¤ºä¾‹
def get_json_format_example():
    """ç”ŸæˆJSONæ ¼å¼ç¤ºä¾‹"""
    return """{{
  "entities": [
    {{
      "text": "å®ä½“æ–‡æœ¬",
      "start": èµ·å§‹ä½ç½®,
      "end": ç»“æŸä½ç½®,
      "label": "å®ä½“ç±»å‹"
    }}
  ]
}}"""

# ç®€åŒ–çš„æ ‡ç­¾éªŒè¯å‡½æ•°
def validate_label(label: str) -> str:
    """éªŒè¯æ ‡ç­¾æ˜¯å¦åœ¨æœ‰æ•ˆæ ‡ç­¾åˆ—è¡¨ä¸­"""
    if not label:
        return None
    
    clean_label = label.strip()
    
    # ç›´æ¥åŒ¹é…æ ‡ç­¾åç§°
    if clean_label in ENTITY_LABELS:
        return clean_label
    
    # å¦‚æœä¸åŒ¹é…ï¼Œè¿”å›None
    print(f"   âŒ æ— æ•ˆæ ‡ç­¾: '{clean_label}' (ä¸åœ¨æœ‰æ•ˆæ ‡ç­¾åˆ—è¡¨ä¸­)")
    return None

def get_valid_label_list():
    """è·å–æ‰€æœ‰æœ‰æ•ˆçš„æ ‡ç­¾åˆ—è¡¨ç”¨äºæç¤º"""
    try:
        from entity_config import get_entity_labels
        return get_entity_labels()
    except ImportError:
        return list(NER_ENTITY_CONFIG.keys())


class NewModel(LabelStudioMLBase):
    """Custom ML Backend model
    """
    
    def setup(self):
        """Configure any parameters of your model here
        """
        self.set("model_version", "0.0.1")
        
        # é­”å¡”ç¤¾åŒºAPIé…ç½®
        self.api_key = os.getenv('MODELSCOPE_API_KEY', 'ms-2c045fb7-f463-45bf-b0f9-a36d50b0400e')
        self.api_base_url = os.getenv('MODELSCOPE_API_URL', 'https://api-inference.modelscope.cn/v1')
        # æ¨èçš„æ¨¡å‹é€‰æ‹©ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰:
        # 1. Qwen/Qwen3-235B-A22B-Instruct-2507 - æœ€é€‚åˆç»“æ„åŒ–è¾“å‡º
        # 2. Qwen/Qwen3-Coder-480B-A35B-Instruct - ä»£ç å’Œç»“æ„åŒ–æ•°æ®å¤„ç†
        # 3. Qwen/Qwen3-235B-A22B-Thinking-2507 - æ€ç»´é“¾æ¨¡å‹ï¼ˆè¾“å‡ºæ ¼å¼å¤æ‚ï¼‰
        # 4. moonshotai/Kimi-K2-Instruct-0905 - æ›´é€‚åˆNERä»»åŠ¡
        # 5. Qwen/Qwen3-30B-A3B-Instruct-2507
        self.model_name = "Qwen/Qwen3-30B-A3B-Instruct-2507"  # æ›´é€‚åˆNERä»»åŠ¡
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        if self.api_key:
            try:
                self.client = OpenAI(
                    base_url=self.api_base_url,
                    api_key=self.api_key
                )
                print(f"âœ… æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ: {self.model_name}")
            except Exception as e:
                print(f"âŒ å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
                self.client = None
        else:
            print(f"âš ï¸ è¯·è®¾ç½®MODELSCOPE_API_KEYç¯å¢ƒå˜é‡")
            self.client = None
        
        # æ£€æŸ¥APIè¿æ¥
        self._check_api_connection()
        
        # æ˜¾ç¤ºå½“å‰é…ç½®çš„å®ä½“æ ‡ç­¾
        self._show_entity_config()
        
    def _check_api_connection(self):
        """æ£€æŸ¥é­”å¡”ç¤¾åŒºAPIè¿æ¥"""
        if not self.client:
            print(f"âŒ å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            return
        
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[{"role": "user", "content": "test"}],
                max_tokens=1000,
                temperature=0.1
            )
            print(f"âœ… APIè¿æ¥æˆåŠŸ")
        except Exception as e:
            print(f"âŒ APIè¿æ¥å¤±è´¥: {str(e)[:100]}")
    
    def _show_entity_config(self):
        """æ˜¾ç¤ºå½“å‰é…ç½®çš„å®ä½“æ ‡ç­¾"""
        print(f"\nğŸ“‹ å½“å‰æ”¯æŒçš„å‘½åå®ä½“ç±»å‹:")
        print("="*60)
        
        try:
            from entity_config import get_all_categories, get_entities_by_category
            categories = get_all_categories()
            
            for category in categories:
                entities = get_entities_by_category(category)
                if entities:
                    print(f"\nğŸ“‚ {category}ç±» ({len(entities)}ä¸ªå®ä½“):")
                    for i, (label, config) in enumerate(entities.items(), 1):
                        print(f"  {i:2d}. {label} - {config['description']}")
                        if config['examples']:
                            examples = "ã€".join(config['examples'][:2])
                            print(f"      ç¤ºä¾‹: {examples}")
                            
        except ImportError:
            # å¤‡ç”¨æ˜¾ç¤ºæ–¹å¼
            for i, (label, config) in enumerate(NER_ENTITY_CONFIG.items(), 1):
                print(f"  {i}. {label} - {config['description']}")
                if config['examples']:
                    examples = "ã€".join(config['examples'][:3])
                    print(f"     ç¤ºä¾‹: {examples}")
        
        print(f"\nğŸ’¡ æ€»è®¡: {len(ENTITY_LABELS)} ç§å®ä½“ç±»å‹")
        print(f"ğŸ”§ å¦‚éœ€ä¿®æ”¹å®ä½“ç±»å‹ï¼Œè¯·ç¼–è¾‘entity_config.pyæ–‡ä»¶")
        print("="*60)
    


    def predict(self, tasks: List[Dict], context: Optional[Dict] = None, **kwargs) -> ModelResponse:
        """ å‘½åå®ä½“è¯†åˆ«é¢„æµ‹
            :param tasks: Label Studio tasks in JSON format
            :param context: Label Studio context in JSON format
            :return: ModelResponse with predictions
        """
        total_tasks = len(tasks)
        predictions = []
        
        print(f"ğŸš€ å¼€å§‹å¤„ç† {total_tasks} ä¸ªä»»åŠ¡")
        print("="*60)
        
        start_time = time.time()
        
        for i, task in enumerate(tasks):
            print(f"\nğŸ”„ æ­£åœ¨å¤„ç†ä»»åŠ¡ {i+1}/{total_tasks}...")
            
            # æ˜¾ç¤ºä»»åŠ¡å†…å®¹é¢„è§ˆ
            task_data = task.get('data', {})
            text_content = ""
            for key in ['text', 'content', 'prompt', 'question', 'description', 'query']:
                if key in task_data and isinstance(task_data[key], str):
                    text_content = task_data[key]
                    break
            
            if text_content:
                preview = text_content[:50] + "..." if len(text_content) > 50 else text_content
                print(f"   ğŸ“ æ–‡æœ¬é¢„è§ˆ: {preview}")
            
            # è®°å½•å¼€å§‹æ—¶é—´
            task_start_time = time.time()
            
            try:
                prediction = self._process_single_task(task)
                task_end_time = time.time()
                task_duration = task_end_time - task_start_time
                
                if prediction and prediction.get('result') and len(prediction.get('result', [])) > 0:
                    # æˆåŠŸè¯†åˆ«åˆ°å®ä½“
                    predictions.append(prediction)
                    entities_count = len(prediction.get('result', []))
                    print(f"âœ… ä»»åŠ¡ {i+1} å¤„ç†æˆåŠŸ (è€—æ—¶: {task_duration:.2f}ç§’, å®ä½“æ•°: {entities_count})")
                else:
                    # æœªè¯†åˆ«åˆ°å®ä½“æˆ–å¤„ç†å¤±è´¥ - è¿”å›é”™è¯¯æ ‡è®°
                    failed_prediction = {
                        "model_version": self.get("model_version"),
                        "score": 0.0,
                        "result": [],
                        "error": "æœªè¯†åˆ«åˆ°ä»»ä½•å®ä½“",  # æ·»åŠ é”™è¯¯æ ‡è®°
                        "status": "failed"  # æ˜ç¡®æ ‡è®°ä¸ºå¤±è´¥
                    }
                    predictions.append(failed_prediction)
                    print(f"âŒ ä»»åŠ¡ {i+1} å¤„ç†å¤±è´¥ - æœªè¯†åˆ«åˆ°ä»»ä½•å®ä½“ (è€—æ—¶: {task_duration:.2f}ç§’)")
                    
            except Exception as e:
                task_end_time = time.time()
                task_duration = task_end_time - task_start_time
                print(f"âŒ ä»»åŠ¡ {i+1} å¤„ç†å¼‚å¸¸ (è€—æ—¶: {task_duration:.2f}ç§’): {e}")
                failed_prediction = {
                    "model_version": self.get("model_version"),
                    "score": 0.0,
                    "result": [],
                    "error": f"å¤„ç†å¼‚å¸¸: {str(e)}",  # æ·»åŠ é”™è¯¯ä¿¡æ¯
                    "status": "failed"  # æ˜ç¡®æ ‡è®°ä¸ºå¤±è´¥
                }
                predictions.append(failed_prediction)
            
            # å¼ºåˆ¶åˆ·æ–°è¾“å‡ºç¼“å†²åŒº
            import sys
            sys.stdout.flush()
        
        # å¤„ç†å®Œæˆåçš„æ€»ç»“
        end_time = time.time()
        total_duration = end_time - start_time
        processed_count = len(predictions)
        
        print(f"\nğŸ“Š å¤„ç†å®Œæˆ")
        print("="*60)
        print("ğŸ“Š å¤„ç†æ€»ç»“:")
        print(f"   å¤„ç†ä»»åŠ¡: {processed_count}/{total_tasks} ä¸ª")
        print(f"   æ€»è€—æ—¶: {total_duration:.2f}ç§’")
        print(f"   å¹³å‡è€—æ—¶: {total_duration/processed_count:.2f}ç§’/ä»»åŠ¡" if processed_count > 0 else "   å¹³å‡è€—æ—¶: N/A")
        
        # ç»Ÿè®¡æˆåŠŸå’Œå¤±è´¥çš„ä»»åŠ¡
        successful_tasks = sum(1 for p in predictions if p.get('result') and len(p.get('result', [])) > 0)
        failed_tasks = processed_count - successful_tasks
        total_entities = sum(len(p.get('result', [])) for p in predictions)
        
        print(f"   âœ… æˆåŠŸä»»åŠ¡: {successful_tasks}/{processed_count} ä¸ª ({successful_tasks/processed_count*100:.1f}%)" if processed_count > 0 else "   âœ… æˆåŠŸä»»åŠ¡: 0 ä¸ª")
        print(f"   âŒ å¤±è´¥ä»»åŠ¡: {failed_tasks}/{processed_count} ä¸ª ({failed_tasks/processed_count*100:.1f}%)" if processed_count > 0 else "   âŒ å¤±è´¥ä»»åŠ¡: 0 ä¸ª")
        print(f"   ğŸ·ï¸ æ€»å®ä½“æ•°: {total_entities} ä¸ª")
        
        if successful_tasks > 0:
            avg_entities = total_entities / successful_tasks
            print(f"   ğŸ“ˆ å¹³å‡å®ä½“æ•°: {avg_entities:.1f} ä¸ª/æˆåŠŸä»»åŠ¡")
        
        print("="*60)
        
        return ModelResponse(predictions=predictions)
    
    def _process_single_task(self, task: Dict) -> Optional[Dict]:
        """å¤„ç†å•ä¸ªä»»åŠ¡"""
        task_data = task.get('data', {})
        
        # æå–æ–‡æœ¬å†…å®¹
        text_content = ""
        text_keys = ['text', 'content', 'prompt', 'question', 'description', 'query']
        
        for key, value in task_data.items():
            if isinstance(value, str) and key in text_keys:
                text_content = value
                break
        
        if not text_content:
            return None
        
        # æ„å»ºNERæç¤ºè¯ï¼ˆä½¿ç”¨é…ç½®åŒ–çš„å®ä½“æ ‡ç­¾ï¼‰
        json_format = get_json_format_example()
        
        # æŒ‰ç±»åˆ«ç»„ç»‡å®ä½“ç±»å‹è¯´æ˜
        try:
            from entity_config import get_all_categories, get_entities_by_category
            categories = get_all_categories()
            categorized_examples = ""
            
            for category in categories:
                entities = get_entities_by_category(category)
                if entities:
                    # ç‰¹æ®Šå¤„ç†å…³ç³»æ ‡ç­¾ç±»åˆ«
                    if category == "å…³ç³»æ ‡ç­¾":
                        categorized_examples += f"\nğŸ”— {category}ç±»ï¼ˆè¯­ä¹‰å…³ç³»å®ä½“ï¼‰:\n"
                        for label_key, config in list(entities.items())[:8]:  # å…³ç³»æ ‡ç­¾æ˜¾ç¤ºæ›´å¤š
                            examples = "ã€".join(config['examples'][:3])  # å…³ç³»æ ‡ç­¾æ˜¾ç¤º3ä¸ªç¤ºä¾‹
                            description = config['description']
                            categorized_examples += f"   â€¢ {description}: {examples}\n"
                    else:
                        categorized_examples += f"\nğŸ“‚ {category}ç±»:\n"
                        for label_key, config in list(entities.items())[:5]:  # æ¯ç±»æœ€å¤šæ˜¾ç¤º5ä¸ªå®ä½“ï¼Œé¿å…æç¤ºè¯è¿‡é•¿
                            examples = "ã€".join(config['examples'][:2])  # æ¯ä¸ªå®ä½“æ˜¾ç¤º2ä¸ªç¤ºä¾‹
                            description = config['description']
                            categorized_examples += f"   â€¢ {description}: {examples}\n"
            
            # ç”Ÿæˆç®€åŒ–çš„å®ä½“åˆ—è¡¨ï¼ˆä½¿ç”¨descriptionï¼‰
            entity_descriptions = []
            for label_key in ENTITY_LABELS[:20]:  # åªæ˜¾ç¤ºå‰20ä¸ªï¼Œé¿å…è¿‡é•¿
                if label_key in NER_ENTITY_CONFIG:
                    entity_descriptions.append(NER_ENTITY_CONFIG[label_key]['description'])
                else:
                    entity_descriptions.append(label_key)
            
            entity_labels_list = "ã€".join(entity_descriptions)
            if len(ENTITY_LABELS) > 20:
                entity_labels_list += f"ç­‰{len(ENTITY_LABELS)}ç§å®ä½“ç±»å‹"
                
        except ImportError:
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨åŸæ¥çš„æ ¼å¼
            categorized_examples = ""
            for label, config in NER_ENTITY_CONFIG.items():
                examples = "ã€".join(config['examples'][:2])
                categorized_examples += f"   {label}({config['description']}): {examples}\n"
            entity_labels_list = "ã€".join(ENTITY_LABELS)
        
        # ç”Ÿæˆä¸¥æ ¼çš„æ ‡ç­¾åˆ—è¡¨ï¼ˆåªæ˜¾ç¤ºæ ‡ç­¾åç§°ï¼Œä¸æ˜¾ç¤ºæè¿°ï¼‰
        valid_labels_only = list(ENTITY_LABELS)
        labels_display = "ã€".join(valid_labels_only)
        
        prompt = f"""è¯·å¯¹ä»¥ä¸‹æ–‡æœ¬è¿›è¡Œå‘½åå®ä½“è¯†åˆ«ï¼Œè¯†åˆ«å‡ºæ–‡æœ¬ä¸­å­˜åœ¨çš„æ‰€æœ‰å®ä½“ï¼ŒåŒ…æ‹¬ä¼ ç»Ÿçš„å‘½åå®ä½“å’Œå…³ç³»è¡¨è¾¾ã€‚

ğŸ“ æ–‡æœ¬å†…å®¹ï¼š
{text_content}

ğŸ¯ æ”¯æŒçš„å®ä½“ç±»å‹åŠç¤ºä¾‹ï¼š{categorized_examples}

ğŸ”— å…³ç³»æ ‡ç­¾è¯´æ˜ï¼š
å…³ç³»æ ‡ç­¾ç”¨äºæ ‡æ³¨å®ä½“ä¹‹é—´çš„è¯­ä¹‰å…³ç³»ï¼Œé€šå¸¸æ˜¯åŠ¨è¯çŸ­è¯­æˆ–è¿æ¥è¯ã€‚è¿™äº›å…³ç³»è¯åŒæ ·ä½œä¸ºå®ä½“è¿›è¡Œæ ‡æ³¨ï¼š

ğŸ’¡ å…³ç³»æ ‡ç­¾æ ‡æ³¨åŸåˆ™ï¼š
1. æ ‡æ³¨å®Œæ•´çš„å…³ç³»è¡¨è¾¾ï¼Œè€Œä¸æ˜¯å•ä¸ªè¯æ±‡
2. åŒ…å«å…³ç³»åŠ¨è¯åŠå…¶å‰åçš„ç›¸å…³æˆåˆ†
3. å…³ç³»æ ‡ç­¾é€šå¸¸è¿æ¥ä¸¤ä¸ªæˆ–å¤šä¸ªå…¶ä»–å®ä½“
4. ç¤ºä¾‹ï¼š
   - "æ ¹æ®ã€Šé˜²æ´ªæ³•ã€‹ç¬¬åæ¡è§„å®š" â†’ "æ ¹æ®...è§„å®š"æ ‡æ³¨ä¸º"ä¾æ®å…³ç³»"
   - "æ°´åˆ©éƒ¨è´Ÿè´£å…¨å›½é˜²æ±›å·¥ä½œ" â†’ "è´Ÿè´£"æ ‡æ³¨ä¸º"è´£ä»»å…³ç³»"
   - "æ´ªæ°´å¯¼è‡´å†œç”°å—æŸ" â†’ "å¯¼è‡´"æ ‡æ³¨ä¸º"å› æœå…³ç³»"
   - "å„éƒ¨é—¨åè°ƒé…åˆæŠ¢é™©æ•‘ç¾" â†’ "åè°ƒé…åˆ"æ ‡æ³¨ä¸º"åè°ƒå…³ç³»"

âš ï¸ ä¸¥æ ¼è¦æ±‚ï¼š
1. è¯†åˆ«æ–‡æœ¬ä¸­çœŸå®å­˜åœ¨çš„æ‰€æœ‰å®ä½“ï¼ŒåŒ…æ‹¬ä¼ ç»Ÿå®ä½“å’Œå…³ç³»
2. å‡†ç¡®æ ‡æ³¨å®ä½“çš„èµ·å§‹å’Œç»“æŸä½ç½®ï¼ˆåŸºäºå­—ç¬¦ä½ç½®ï¼‰
3. æ ‡ç­¾åç§°å¿…é¡»ä¸¥æ ¼ä½¿ç”¨ä¸‹é¢åˆ—å‡ºçš„æ ‡ç­¾åç§°ï¼Œä¸€å­—ä¸å·®
4. ç¦æ­¢ä½¿ç”¨æè¿°æ€§æ–‡å­—ã€ç®€åŒ–åç§°æˆ–ä»»ä½•å˜ä½“å½¢å¼
5. å¦‚æœå®ä½“ç±»å‹ä¸åœ¨æ ‡ç­¾åˆ—è¡¨ä¸­ï¼Œåˆ™ä¸è¦æ ‡æ³¨è¯¥å®ä½“
6. å…³ç³»æ ‡ç­¾è¦åŒ…å«å®Œæ•´çš„å…³ç³»è¡¨è¾¾ï¼Œä¸è¦åªæ ‡æ³¨å•ä¸ªåŠ¨è¯

ğŸ” ç‰¹åˆ«å…³æ³¨ï¼š
- æ³•å¾‹æ¡æ¬¾ï¼šè¯†åˆ«"ç¬¬Xæ¡"ã€"ç¬¬Xç« "ã€"ç¬¬XèŠ‚"ç­‰æ³•å¾‹æ¡æ¬¾æ ¼å¼
- å…³ç³»è¡¨è¾¾ï¼šè¯†åˆ«è¡¨ç¤ºä¾æ®ã€è´£ä»»ã€ç®¡è¾–ã€å› æœç­‰å…³ç³»çš„åŠ¨è¯çŸ­è¯­
- æ—¶åºå…³ç³»ï¼šè¯†åˆ«è¡¨ç¤ºæ—¶é—´å…ˆåçš„å…³ç³»è¯æ±‡
- å½±å“å…³ç³»ï¼šè¯†åˆ«è¡¨ç¤ºå½±å“ã€æ³¢åŠçš„å…³ç³»è¡¨è¾¾

ğŸ“‹ è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ç»“æœï¼š
{json_format}

ğŸ·ï¸ ä¸¥æ ¼ä½¿ç”¨ä»¥ä¸‹æ ‡ç­¾åç§°ï¼ˆå¤åˆ¶ç²˜è´´ï¼Œä¸€å­—ä¸å·®ï¼‰ï¼š
{labels_display}

âŒ ç¦æ­¢äº‹é¡¹ï¼š
- ç¦æ­¢ä½¿ç”¨æè¿°æ€§æ–‡å­—ä½œä¸ºæ ‡ç­¾ï¼ˆå¦‚"æ”¿åºœéƒ¨é—¨"åº”ä½¿ç”¨"æ”¿åºœæœºæ„"ï¼‰
- ç¦æ­¢ä½¿ç”¨ç®€åŒ–å½¢å¼ï¼ˆå¦‚"æ¡æ¬¾"åº”ä½¿ç”¨"æ³•å¾‹æ¡æ¬¾"ï¼‰
- ç¦æ­¢ä½¿ç”¨è¿‘ä¼¼è¯æ±‡ï¼ˆå¦‚"æ³•è§„"åº”ä½¿ç”¨"æ³•å¾‹æ³•è§„"ï¼‰
- ç¦æ­¢è‡ªåˆ›æ ‡ç­¾åç§°
- ç¦æ­¢åªæ ‡æ³¨å…³ç³»åŠ¨è¯çš„å•ä¸ªè¯æ±‡ï¼Œè¦æ ‡æ³¨å®Œæ•´çš„å…³ç³»è¡¨è¾¾

âœ… æ­£ç¡®ç¤ºä¾‹ï¼š
å®ä½“æ ‡ç­¾ï¼š
- æ ‡ç­¾å¿…é¡»æ˜¯ï¼š"æ³•å¾‹æ¡æ¬¾"ï¼Œä¸èƒ½æ˜¯"æ¡æ¬¾"ã€"æ³•æ¡"ã€"æ¡æ–‡"
- æ ‡ç­¾å¿…é¡»æ˜¯ï¼š"æ”¿åºœæœºæ„"ï¼Œä¸èƒ½æ˜¯"æ”¿åºœéƒ¨é—¨"ã€"æœºæ„"
- æ ‡ç­¾å¿…é¡»æ˜¯ï¼š"æ³•å¾‹æ³•è§„"ï¼Œä¸èƒ½æ˜¯"æ³•å¾‹"ã€"æ³•è§„"ã€"æ¡ä¾‹"

å…³ç³»æ ‡ç­¾ï¼š
- "æ ¹æ®ã€Šé˜²æ´ªæ³•ã€‹è§„å®š" â†’ "ä¾æ®å…³ç³»"
- "æ°´åŠ¡å±€è´Ÿè´£æ²³é“ç®¡ç†" â†’ "è´£ä»»å…³ç³»"  
- "æ´ªæ°´é€ æˆæŸå¤±" â†’ "å› æœå…³ç³»"
- "å„éƒ¨é—¨åè°ƒé…åˆ" â†’ "åè°ƒå…³ç³»"
- "æ±›æœŸæœŸé—´æ‰§è¡Œé¢„æ¡ˆ" â†’ "æ‰§è¡Œå…³ç³»"

è¯·ç¡®ä¿æ¯ä¸ªæ ‡ç­¾éƒ½ä»ä¸Šé¢çš„åˆ—è¡¨ä¸­ç²¾ç¡®å¤åˆ¶ï¼Œå…³ç³»æ ‡ç­¾è¦æ ‡æ³¨å®Œæ•´çš„å…³ç³»è¡¨è¾¾ï¼"""
        
        # è°ƒç”¨API
        api_response = self._call_modelscope_api(prompt)
        
        if api_response and api_response.strip():
            return self._format_prediction(api_response, task)
        
        # APIè°ƒç”¨å¤±è´¥æˆ–è¿”å›ç©ºå“åº”
        print("âŒ APIè°ƒç”¨å¤±è´¥æˆ–è¿”å›ç©ºå“åº”")
        return None
    
    def _call_modelscope_api(self, prompt: str) -> Optional[str]:
        """è°ƒç”¨é­”å¡”ç¤¾åŒºAPI"""
        if not self.client:
            print("âŒ OpenAIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            return None
        
        print(f"ğŸ“¤ å‘é€APIè¯·æ±‚...")
        print(f"   æ¨¡å‹: {self.model_name}")
        print(f"   æç¤ºè¯é•¿åº¦: {len(prompt)} å­—ç¬¦")
        
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": "You are a specialized Named Entity Recognition assistant for legal texts. CRITICAL: You must extract both traditional entities AND relational expressions. Use EXACT label names from the provided list. Never use descriptions, abbreviations, or variations. For relation labels, extract complete phrases that express semantic relationships between entities. Always respond with valid JSON format containing only the specified labels."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=2000,
                temperature=0.1,
                top_p=0.9,
                stream=False
            )
            
            print(f"ğŸ“¥ æ”¶åˆ°APIå“åº”")
            
            if response.choices and len(response.choices) > 0:
                content = response.choices[0].message.content
                print(f"âœ… å“åº”å†…å®¹é•¿åº¦: {len(content) if content else 0} å­—ç¬¦")
                if content:
                    print(f"ğŸ“‹ å“åº”å†…å®¹é¢„è§ˆ: {content[:300]}{'...' if len(content) > 300 else ''}")
                return content
            else:
                print("âŒ APIå“åº”ä¸­æ²¡æœ‰choices")
                return None
                
        except Exception as e:
            print(f"âŒ APIè°ƒç”¨å¤±è´¥: {str(e)}")
            print(f"   å®Œæ•´é”™è¯¯ä¿¡æ¯: {repr(e)}")
            return None
    
    def _format_prediction(self, api_response: str, task: Dict) -> Dict:
        """æ ¼å¼åŒ–é¢„æµ‹ç»“æœä¸ºLabel Studioæ ¼å¼"""
        print(f"\nğŸ”„ æ ¼å¼åŒ–é¢„æµ‹ç»“æœ:")
        print(f"   APIå“åº”é•¿åº¦: {len(api_response)} å­—ç¬¦")
        print(f"   APIå“åº”å†…å®¹: {api_response[:200]}{'...' if len(api_response) > 200 else ''}")
        
        prediction = {
            "model_version": self.get("model_version"),
            "score": 0.95,
            "result": []
        }
        
        # å°è¯•è§£æNERç»“æœ
        ner_results = self._parse_ner_response(api_response, task)
        if ner_results and len(ner_results) > 0:
            prediction["result"] = ner_results
            prediction["score"] = 0.95  # æˆåŠŸè¯†åˆ«çš„ç½®ä¿¡åº¦
            print(f"âœ… NERè§£ææˆåŠŸï¼Œè¯†åˆ«åˆ° {len(ner_results)} ä¸ªå®ä½“")
            for i, result in enumerate(ner_results):
                entity = result.get('value', {})
                text = entity.get('text', '')
                labels = entity.get('labels', [])
                start = entity.get('start', 0)
                end = entity.get('end', 0)
                print(f"   å®ä½“ {i+1}: [{text}] -> {labels} ({start}-{end})")
            return prediction
        
        # å¦‚æœæ²¡æœ‰è¯†åˆ«åˆ°ä»»ä½•å®ä½“ï¼Œè¿”å›å¤±è´¥ä¿¡æ¯
        print("âŒ NERè§£æå¤±è´¥ï¼Œæœªè¯†åˆ«åˆ°ä»»ä½•æœ‰æ•ˆå®ä½“")
        prediction["score"] = 0.0  # å¤±è´¥çš„ç½®ä¿¡åº¦
        prediction["result"] = []   # ç©ºç»“æœ
        return None  # è¿”å›Noneè¡¨ç¤ºå¤„ç†å¤±è´¥
    
    def _parse_ner_response(self, api_response: str, task: Dict) -> Optional[List[Dict]]:
        """è§£æAIè¿”å›çš„å‘½åå®ä½“è¯†åˆ«JSONç»“æœï¼Œå¹¶ç”¨æ­£åˆ™è¡¨è¾¾å¼è¿›è¡Œè¡¥å……"""
        print(f"\nğŸ” å¼€å§‹è§£æNERå“åº”...")
        
        # è·å–åŸå§‹æ–‡æœ¬
        task_data = task.get('data', {})
        original_text = ""
        for key in ['text', 'content', 'prompt', 'question', 'description', 'query']:
            if key in task_data and isinstance(task_data[key], str):
                original_text = task_data[key]
                break
        
        if not original_text:
            print("âŒ æ— æ³•è·å–åŸå§‹æ–‡æœ¬")
            return None
        
        print(f"ğŸ“ åŸå§‹æ–‡æœ¬: {original_text}")
        print(f"ğŸ“ åŸå§‹æ–‡æœ¬é•¿åº¦: {len(original_text)} å­—ç¬¦")
        
        # åˆå§‹åŒ–ç»“æœåˆ—è¡¨
        results = []
        ai_entities = []
        
        # ç¬¬ä¸€æ­¥ï¼šè§£æAIæ¨¡å‹çš„è¯†åˆ«ç»“æœ
        if api_response and api_response.strip():
            ai_entities = self._parse_ai_entities(api_response, original_text)
            if ai_entities:
                results.extend(ai_entities)
                print(f"ğŸ¤– AIæ¨¡å‹è¯†åˆ«åˆ° {len(ai_entities)} ä¸ªå®ä½“")
        else:
            print("âš ï¸ AIå“åº”ä¸ºç©ºï¼Œè·³è¿‡AIå®ä½“è§£æ")
        
        # ç¬¬äºŒæ­¥ï¼šä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è¿›è¡Œè¡¥å……è¯†åˆ«
        regex_entities = self._extract_regex_entities(original_text, ai_entities)
        if regex_entities:
            results.extend(regex_entities)
            print(f"ğŸ”§ æ­£åˆ™è¡¨è¾¾å¼è¡¥å……è¯†åˆ«åˆ° {len(regex_entities)} ä¸ªå®ä½“")
        
        # ç¬¬ä¸‰æ­¥ï¼šå»é‡å’Œæ’åº
        final_results = self._deduplicate_entities(results)
        print(f"ğŸ“Š å»é‡åæœ€ç»ˆå®ä½“æ•°é‡: {len(final_results)}")
        
        return final_results if final_results else None
    
    def _parse_ai_entities(self, api_response: str, original_text: str) -> List[Dict]:
        """è§£æAIæ¨¡å‹è¿”å›çš„å®ä½“"""
        print(f"\nğŸ¤– è§£æAIå®ä½“è¯†åˆ«ç»“æœ...")
        ai_results = []
        
        try:
            # å°è¯•ç›´æ¥è§£æJSON
            try:
                print("ğŸ”§ å°è¯•ç›´æ¥JSONè§£æ...")
                ner_data = json.loads(api_response.strip())
                print("âœ… ç›´æ¥JSONè§£ææˆåŠŸ")
            except json.JSONDecodeError as e:
                print(f"âš ï¸ ç›´æ¥JSONè§£æå¤±è´¥: {e}")
                # å°è¯•æå–JSONéƒ¨åˆ†
                import re
                print("ğŸ”§ å°è¯•æå–JSONç‰‡æ®µ...")
                
                # å¤šç§JSONæå–ç­–ç•¥
                patterns = [
                    r'\{[^{}]*"entities"[^{}]*:.*?\}',  # æœ€ä¸¥æ ¼çš„entitiesåŒ¹é…
                    r'\{.*?"entities".*?\}',            # å®½æ¾çš„entitiesåŒ¹é…
                    r'\{.*\}',                          # æœ€å®½æ¾çš„JSONåŒ¹é…
                ]
                
                ner_data = None
                for i, pattern in enumerate(patterns):
                    json_match = re.search(pattern, api_response, re.DOTALL)
                    if json_match:
                        try:
                            ner_data = json.loads(json_match.group())
                            print(f"âœ… JSONæå–æˆåŠŸ (ç­–ç•¥ {i+1})")
                            break
                        except json.JSONDecodeError:
                            print(f"âš ï¸ JSONæå–ç­–ç•¥ {i+1} å¤±è´¥")
                            continue
                
                if not ner_data:
                    print("âŒ æ‰€æœ‰JSONæå–ç­–ç•¥éƒ½å¤±è´¥")
                    print(f"ğŸ“„ åŸå§‹å“åº”å†…å®¹: {api_response}")
                    return ai_results
            
            # æ£€æŸ¥entitieså­—æ®µ
            if 'entities' not in ner_data or not isinstance(ner_data['entities'], list):
                print("âš ï¸ å“åº”ä¸­æ²¡æœ‰æœ‰æ•ˆçš„entitieså­—æ®µ")
                return ai_results
            
            entities = ner_data['entities']
            
            # è½¬æ¢ä¸ºLabel Studioæ ¼å¼
            for i, entity in enumerate(entities):
                # éªŒè¯å¿…éœ€å­—æ®µ
                if not all(key in entity for key in ['text', 'start', 'end', 'label']):
                    print(f"   âš ï¸ AIå®ä½“ {i+1} ç¼ºå°‘å¿…éœ€å­—æ®µï¼Œè·³è¿‡")
                    continue
                
                start = entity['start']
                end = entity['end']
                text = entity['text']
                original_label = entity['label']
                
                print(f"\nğŸ” å¤„ç†AIå®ä½“ {i+1}: {entity}")
                
                # ä¸¥æ ¼éªŒè¯æ ‡ç­¾
                validated_label = validate_label(original_label)
                if not validated_label:
                    print(f"   âŒ AIå®ä½“ {i+1} æ ‡ç­¾æ— æ•ˆ: '{original_label}'ï¼Œè·³è¿‡")
                    continue
                
                # ä½¿ç”¨éªŒè¯é€šè¿‡çš„æ ‡ç­¾
                label = validated_label
                if validated_label in NER_ENTITY_CONFIG:
                    description = NER_ENTITY_CONFIG[validated_label]['description']
                    print(f"   âœ… æ ‡ç­¾éªŒè¯é€šè¿‡: '{original_label}' -> '{validated_label}' (æè¿°: {description})")
                else:
                    print(f"   âœ… æ ‡ç­¾éªŒè¯é€šè¿‡: '{original_label}' -> '{label}'")
                
                # éªŒè¯ä½ç½®ä¿¡æ¯åŸºæœ¬åˆç†æ€§
                if not isinstance(start, int) or not isinstance(end, int) or start < 0:
                    print(f"   âŒ AIå®ä½“ {i+1} ä½ç½®ä¿¡æ¯æ— æ•ˆ (start={start}, end={end})ï¼Œè·³è¿‡")
                    continue
                
                print(f"   ğŸ“‹ AIæä¾›çš„æ–‡æœ¬: '{text}'")
                print(f"   ğŸ“ åŸå§‹ä½ç½®: {start}-{end}")
                
                # å…ˆå°è¯•ä¿®æ­£ä½ç½®ï¼Œå†è¿›è¡ŒèŒƒå›´æ£€æŸ¥
                corrected_start, corrected_end, corrected_text = self._correct_entity_position(
                    original_text, text, start, end
                )
                
                # æ£€æŸ¥ä¿®æ­£åçš„ä½ç½®æ˜¯å¦åˆç†
                if corrected_start is None or corrected_end is None or corrected_text is None:
                    print(f"   âŒ AIå®ä½“ {i+1} ä½ç½®ä¿®æ­£å¤±è´¥ï¼Œè·³è¿‡")
                    continue
                
                # éªŒè¯ä¿®æ­£åçš„ä½ç½®ä¸è¶…å‡ºæ–‡æœ¬é•¿åº¦
                if corrected_end > len(original_text) or corrected_start < 0:
                    print(f"   âŒ AIå®ä½“ {i+1} ä¿®æ­£åä½ç½®è¶…å‡ºæ–‡æœ¬é•¿åº¦ (start={corrected_start}, end={corrected_end}, text_len={len(original_text)})ï¼Œè·³è¿‡")
                    continue
                
                print(f"   ğŸ“‹ ä¿®æ­£åçš„æ–‡æœ¬: '{corrected_text}'")
                print(f"   ğŸ“ ä¿®æ­£åä½ç½®: {corrected_start}-{corrected_end}")
                
                if corrected_text:
                    # éªŒè¯ä¿®æ­£åçš„å®ä½“æ˜¯å¦åˆç†
                    if self._is_valid_entity(corrected_text, validated_label):
                        result = {
                            "from_name": "label",
                            "to_name": "text",
                            "type": "labels",
                            "value": {
                                "start": corrected_start,
                                "end": corrected_end,
                                "text": corrected_text,
                                "labels": [label]
                            },
                            "source": "ai"  # æ ‡è®°æ¥æºä¸ºAI
                        }
                        
                        ai_results.append(result)
                        print(f"   âœ… AIå®ä½“ {i+1} å·²æ·»åŠ : '{corrected_text}' -> {label} ({corrected_start}-{corrected_end})")
                    else:
                        print(f"   âŒ AIå®ä½“ {i+1} éªŒè¯å¤±è´¥: '{corrected_text}' ä¸æ˜¯æœ‰æ•ˆçš„ {label} å®ä½“")
                else:
                    print(f"   âŒ AIå®ä½“ {i+1} æ— æ³•ä¿®æ­£ä½ç½®ï¼Œè·³è¿‡")
            
            print(f"ğŸ¤– AIæ¨¡å‹è§£æå®Œæˆï¼Œæœ‰æ•ˆå®ä½“: {len(ai_results)}")
            return ai_results
            
        except Exception as e:
            print(f"âŒ è§£æAIå®ä½“å¼‚å¸¸: {e}")
            return ai_results
    
    def _extract_regex_entities(self, original_text: str, existing_entities: List[Dict]) -> List[Dict]:
        """ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è¡¥å……è¯†åˆ«å®ä½“"""
        print(f"\nğŸ”§ å¼€å§‹æ­£åˆ™è¡¨è¾¾å¼è¡¥å……è¯†åˆ«...")
        regex_results = []
        
        try:
            # è·å–å·²è¯†åˆ«å®ä½“çš„ä½ç½®èŒƒå›´ï¼Œé¿å…é‡å¤
            existing_ranges = set()
            for entity in existing_entities:
                value = entity.get('value', {})
                start = value.get('start', -1)
                end = value.get('end', -1)
                if start >= 0 and end > start:
                    # æ‰©å±•èŒƒå›´ä»¥é¿å…é‡å 
                    for pos in range(max(0, start-1), min(len(original_text), end+1)):
                        existing_ranges.add(pos)
            
            # ä»entity_configè·å–æ­£åˆ™æ¨¡å¼
            from entity_config import get_entity_config
            entity_config = get_entity_config()
            
            # éå†æ‰€æœ‰é…ç½®çš„å®ä½“ç±»å‹
            for label_key, config in entity_config.items():
                if 'patterns' not in config or not config['patterns']:
                    continue
                
                patterns = config['patterns']
                description = config['description']
                
                print(f"ğŸ” æ£€æŸ¥ {label_key} ({description}) çš„æ­£åˆ™æ¨¡å¼...")
                
                # å¯¹æ¯ä¸ªæ­£åˆ™æ¨¡å¼è¿›è¡ŒåŒ¹é…
                for pattern in patterns:
                    try:
                        import re
                        matches = re.finditer(pattern, original_text)
                        
                        for match in matches:
                            start = match.start()
                            end = match.end()
                            text = match.group()
                            
                            # æ£€æŸ¥æ˜¯å¦ä¸å·²è¯†åˆ«çš„å®ä½“é‡å 
                            overlapping = any(pos in existing_ranges for pos in range(start, end))
                            if overlapping:
                                print(f"   âš ï¸ æ­£åˆ™åŒ¹é… '{text}' ({start}-{end}) ä¸å·²è¯†åˆ«å®ä½“é‡å ï¼Œè·³è¿‡")
                                continue
                            
                            # éªŒè¯å®ä½“æ˜¯å¦åˆç†
                            if self._is_valid_entity(text, label_key):
                                result = {
                                    "from_name": "label",
                                    "to_name": "text",
                                    "type": "labels",
                                    "value": {
                                        "start": start,
                                        "end": end,
                                        "text": text,
                                        "labels": [label_key]  # ä½¿ç”¨æ ‡ç­¾é”®åè€Œä¸æ˜¯description
                                    },
                                    "source": "regex"  # æ ‡è®°æ¥æºä¸ºæ­£åˆ™
                                }
                                
                                regex_results.append(result)
                                print(f"   âœ… æ­£åˆ™è¯†åˆ«: '{text}' -> {label_key} (æè¿°: {description}) ({start}-{end})")
                                
                                # æ›´æ–°å·²è¯†åˆ«èŒƒå›´
                                for pos in range(start, end):
                                    existing_ranges.add(pos)
                            else:
                                print(f"   âŒ æ­£åˆ™åŒ¹é… '{text}' éªŒè¯å¤±è´¥ï¼Œè·³è¿‡")
                                
                    except re.error as e:
                        print(f"   âŒ æ­£åˆ™æ¨¡å¼é”™è¯¯ '{pattern}': {e}")
                        continue
            
            print(f"ğŸ”§ æ­£åˆ™è¡¨è¾¾å¼è¡¥å……å®Œæˆï¼Œæ–°å¢å®ä½“: {len(regex_results)}")
            return regex_results
            
        except Exception as e:
            print(f"âŒ æ­£åˆ™è¡¨è¾¾å¼è¡¥å……å¼‚å¸¸: {e}")
            return regex_results
    
    def _deduplicate_entities(self, entities: List[Dict]) -> List[Dict]:
        """å»é‡å’Œæ’åºå®ä½“"""
        print(f"\nğŸ”„ å¼€å§‹å»é‡å’Œæ’åºå®ä½“...")
        
        # æŒ‰èµ·å§‹ä½ç½®æ’åº
        sorted_entities = sorted(entities, key=lambda x: x.get('value', {}).get('start', 0))
        
        # å»é‡é€»è¾‘ï¼šå¦‚æœä¸¤ä¸ªå®ä½“ä½ç½®é‡å è¶…è¿‡50%ï¼Œä¿ç•™ç½®ä¿¡åº¦é«˜çš„
        deduplicated = []
        
        for current in sorted_entities:
            current_value = current.get('value', {})
            current_start = current_value.get('start', 0)
            current_end = current_value.get('end', 0)
            current_text = current_value.get('text', '')
            current_source = current.get('source', 'unknown')
            
            # æ£€æŸ¥æ˜¯å¦ä¸å·²æ·»åŠ çš„å®ä½“é‡å 
            should_add = True
            for i, existing in enumerate(deduplicated):
                existing_value = existing.get('value', {})
                existing_start = existing_value.get('start', 0)
                existing_end = existing_value.get('end', 0)
                existing_text = existing_value.get('text', '')
                existing_source = existing.get('source', 'unknown')
                
                # è®¡ç®—é‡å åº¦
                overlap_start = max(current_start, existing_start)
                overlap_end = min(current_end, existing_end)
                
                if overlap_start < overlap_end:  # æœ‰é‡å 
                    overlap_length = overlap_end - overlap_start
                    current_length = current_end - current_start
                    existing_length = existing_end - existing_start
                    
                    # è®¡ç®—é‡å æ¯”ä¾‹ï¼ˆç›¸å¯¹äºè¾ƒçŸ­çš„å®ä½“ï¼‰
                    min_length = min(current_length, existing_length)
                    overlap_ratio = overlap_length / min_length if min_length > 0 else 0
                    
                    if overlap_ratio > 0.5:  # é‡å è¶…è¿‡50%
                        print(f"   ğŸ”„ å‘ç°é‡å å®ä½“:")
                        print(f"      å½“å‰: '{current_text}' ({current_start}-{current_end}) [{current_source}]")
                        print(f"      å·²æœ‰: '{existing_text}' ({existing_start}-{existing_end}) [{existing_source}]")
                        print(f"      é‡å æ¯”ä¾‹: {overlap_ratio:.2%}")
                        
                        # ä¼˜å…ˆçº§ï¼šAI > æ­£åˆ™ï¼Œé•¿å®ä½“ > çŸ­å®ä½“
                        should_replace = False
                        if current_source == 'ai' and existing_source == 'regex':
                            should_replace = True
                            print(f"      ğŸ’¡ AIè¯†åˆ«ä¼˜å…ˆäºæ­£åˆ™è¯†åˆ«")
                        elif current_source == existing_source and current_length > existing_length:
                            should_replace = True
                            print(f"      ğŸ’¡ æ›´é•¿çš„å®ä½“ä¼˜å…ˆ")
                        elif current_source == existing_source and current_length == existing_length:
                            # ç›¸åŒé•¿åº¦ï¼Œä¿ç•™åŸæœ‰çš„
                            should_replace = False
                            print(f"      ğŸ’¡ ç›¸åŒæ¡ä»¶ï¼Œä¿ç•™åŸæœ‰å®ä½“")
                        
                        if should_replace:
                            deduplicated[i] = current
                            print(f"      âœ… æ›¿æ¢ä¸ºå½“å‰å®ä½“")
                        else:
                            print(f"      âœ… ä¿ç•™åŸæœ‰å®ä½“")
                        
                        should_add = False
                        break
            
            if should_add:
                deduplicated.append(current)
                print(f"   âœ… æ·»åŠ å®ä½“: '{current_text}' -> {current_value.get('labels', [])} ({current_start}-{current_end}) [{current_source}]")
        
        # æœ€ç»ˆæŒ‰ä½ç½®æ’åº
        final_results = sorted(deduplicated, key=lambda x: x.get('value', {}).get('start', 0))
        
        # ç§»é™¤sourceæ ‡è®°ï¼ˆLabel Studioä¸éœ€è¦ï¼‰
        for result in final_results:
            result.pop('source', None)
        
        print(f"ğŸ”„ å»é‡å®Œæˆï¼Œæœ€ç»ˆå®ä½“æ•°é‡: {len(final_results)}")
        return final_results
    
    def _correct_entity_position(self, original_text: str, entity_text: str, start: int, end: int) -> tuple:
        """ä¿®æ­£å®ä½“ä½ç½®"""
        # é¦–å…ˆæ£€æŸ¥åŸå§‹ä½ç½®æ˜¯å¦æ­£ç¡®
        if start < len(original_text) and end <= len(original_text):
            extracted = original_text[start:end]
            if extracted == entity_text:
                return start, end, entity_text
        
        # æ¸…ç†å®ä½“æ–‡æœ¬ï¼ˆå»é™¤å¤šä½™ç©ºæ ¼å’Œæ ‡ç‚¹ï¼‰
        clean_entity = entity_text.strip()
        if not clean_entity:
            return None, None, None
        
        # åœ¨åŸæ–‡ä¸­æœç´¢å®ä½“æ–‡æœ¬
        try:
            # å°è¯•ç²¾ç¡®åŒ¹é…
            exact_start = original_text.find(clean_entity)
            if exact_start != -1:
                exact_end = exact_start + len(clean_entity)
                print(f"   ğŸ”§ ç²¾ç¡®åŒ¹é…ä¿®æ­£: '{clean_entity}' ({exact_start}-{exact_end})")
                return exact_start, exact_end, clean_entity
            
            # å°è¯•æ¨¡ç³ŠåŒ¹é…ï¼ˆå»é™¤æ ‡ç‚¹ç¬¦å·ï¼‰
            import re
            clean_text_for_search = re.sub(r'[^\w\u4e00-\u9fff]', '', clean_entity)
            if len(clean_text_for_search) >= 2:  # è‡³å°‘2ä¸ªå­—ç¬¦æ‰è¿›è¡Œæ¨¡ç³ŠåŒ¹é…
                for i in range(len(original_text) - len(clean_text_for_search) + 1):
                    slice_text = original_text[i:i + len(clean_text_for_search)]
                    clean_slice = re.sub(r'[^\w\u4e00-\u9fff]', '', slice_text)
                    if clean_slice == clean_text_for_search:
                        print(f"   ğŸ”§ æ¨¡ç³ŠåŒ¹é…ä¿®æ­£: '{slice_text}' ({i}-{i + len(clean_text_for_search)})")
                        return i, i + len(clean_text_for_search), slice_text
            
            # å¦‚æœè¿˜æ˜¯æ‰¾ä¸åˆ°ï¼Œå°è¯•éƒ¨åˆ†åŒ¹é…
            if len(clean_entity) >= 3:
                core_part = clean_entity[:min(len(clean_entity), 5)]  # å–å‰å‡ ä¸ªå­—ç¬¦ä½œä¸ºæ ¸å¿ƒ
                core_start = original_text.find(core_part)
                if core_start != -1:
                    # å°è¯•æ‰©å±•åŒ¹é…
                    extended_end = min(core_start + len(clean_entity) + 2, len(original_text))
                    extended_text = original_text[core_start:extended_end]
                    print(f"   ğŸ”§ éƒ¨åˆ†åŒ¹é…ä¿®æ­£: '{extended_text}' ({core_start}-{extended_end})")
                    return core_start, extended_end, extended_text
            
        except Exception as e:
            print(f"   âŒ ä½ç½®ä¿®æ­£å¤±è´¥: {e}")
        
        return None, None, None
    
    def _is_valid_entity(self, text: str, label: str) -> bool:
        """ç®€åŒ–çš„å®ä½“éªŒè¯ï¼ˆåŸºç¡€è§„åˆ™éªŒè¯ï¼‰"""
        if not text or len(text.strip()) < 1:
            return False
        
        # å»é™¤é¦–å°¾æ ‡ç‚¹ç¬¦å·å’Œç©ºæ ¼
        clean_text = text.strip()
        
        # ä¸èƒ½åªæ˜¯æ ‡ç‚¹ç¬¦å·
        import re
        if re.match(r'^[^\w\u4e00-\u9fff]+$', clean_text):
            return False
        
        # åŸºç¡€é•¿åº¦éªŒè¯
        if len(clean_text) < 1:
            return False
        
        # éªŒè¯æ ‡ç­¾æ˜¯å¦æœ‰æ•ˆ
        if label not in ENTITY_LABELS:
            print(f"   âš ï¸ å®ä½“æ–‡æœ¬ '{clean_text}' çš„æ ‡ç­¾ '{label}' ä¸åœ¨æœ‰æ•ˆæ ‡ç­¾åˆ—è¡¨ä¸­")
            return False
        
        # ç‰¹æ®ŠéªŒè¯ï¼šå…³ç³»æ ‡ç­¾
        if label.endswith("å…³ç³»"):
            # å…³ç³»æ ‡ç­¾åº”è¯¥åŒ…å«åŠ¨è¯æˆ–è¿æ¥è¯
            relation_keywords = ['æ ¹æ®', 'ä¾æ®', 'æŒ‰ç…§', 'è´Ÿè´£', 'ä¸»ç®¡', 'ç®¡è¾–', 'å¯¼è‡´', 'é€ æˆ', 'å¼•èµ·', 
                               'ä¹‹å‰', 'ä¹‹å', 'åŒæ—¶', 'åŒ…æ‹¬', 'åŒ…å«', 'å±äº', 'å½±å“', 'æ³¢åŠ', 'åè°ƒ', 
                               'é…åˆ', 'æ‰§è¡Œ', 'å®æ–½', 'è¡¥å¿', 'èµ”å¿']
            
            if not any(keyword in clean_text for keyword in relation_keywords):
                print(f"   âš ï¸ å…³ç³»æ ‡ç­¾ '{label}' çš„æ–‡æœ¬ '{clean_text}' ä¸åŒ…å«å…³ç³»å…³é”®è¯")
                # å¯¹äºå…³ç³»æ ‡ç­¾ï¼Œæ”¾å®½éªŒè¯ï¼Œåªè¦ä¸æ˜¯çº¯æ ‡ç‚¹å°±æ¥å—
                pass
        
        return True
    
    def _extract_choice(self, response: str, choices: List[str]) -> Optional[str]:
        """ä»å“åº”ä¸­æå–æœ€åŒ¹é…çš„é€‰æ‹©"""
        response_lower = response.lower()
        for choice in choices:
            if choice.lower() in response_lower:
                return choice
        return choices[0] if choices else None
    
    def fit(self, event, data, **kwargs):
        """
        è®­ç»ƒ/æ›´æ–°æ¨¡å‹
        :param event: äº‹ä»¶ç±»å‹ ('ANNOTATION_CREATED', 'ANNOTATION_UPDATED', 'START_TRAINING')
        :param data: äº‹ä»¶æ•°æ®
        """
        # æ›´æ–°ç¼“å­˜æ•°æ®
        old_data = self.get('my_data')
        self.set('my_data', 'updated_data')
        self.set('model_version', 'updated_version')
        print(f"âœ… æ¨¡å‹å·²æ›´æ–° (äº‹ä»¶: {event})")

