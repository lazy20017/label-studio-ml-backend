from typing import List, Dict, Optional
import json
import os
import time
from openai import OpenAI
from label_studio_ml.model import LabelStudioMLBase
from label_studio_ml.response import ModelResponse

# å¯åŠ¨å‘½ä»¤   label-studio-ml start my_ml_backend


# ==================== å‘½åå®ä½“é…ç½® ====================
# ä»é…ç½®æ–‡ä»¶å¯¼å…¥å®ä½“é…ç½®
try:
    from entity_config import get_entity_config, get_entity_labels, get_all_categories, get_entities_by_category
    NER_ENTITY_CONFIG = get_entity_config()
    ENTITY_LABELS = get_entity_labels()
    print(f"âœ… åŠ è½½äº† {len(ENTITY_LABELS)} ç§å®ä½“ç±»å‹")
except ImportError:
    print("âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œé€€å‡ºç¨‹åº")
    exit()


# ç”ŸæˆJSONæ ¼å¼ç¤ºä¾‹
def get_json_format_example():
    """ç”ŸæˆJSONæ ¼å¼ç¤ºä¾‹"""
    return """{{
  "entities": [
    {{
      "text": "å®ä½“æ–‡æœ¬",
      "start": èµ·å§‹ä½ç½®,
      "end": ç»“æŸä½ç½®,
      "label": "å®ä½“ç±»å‹"
    }}
  ]
}}"""

def validate_label(label: str) -> str:
    """éªŒè¯æ ‡ç­¾æ˜¯å¦åœ¨æœ‰æ•ˆæ ‡ç­¾åˆ—è¡¨ä¸­"""
    if not label:
        return None
    
    clean_label = label.strip()
    
    # ç›´æ¥åŒ¹é…æ ‡ç­¾åç§°
    if clean_label in ENTITY_LABELS:
        return clean_label
    
    return None

# ğŸŒ å…¨å±€çŠ¶æ€ç®¡ç† - ç®€åŒ–çš„API Keyå’Œæ¨¡å‹åˆ‡æ¢
# ä½¿ç”¨å…¨å±€å˜é‡ç»Ÿä¸€ç®¡ç†å½“å‰çŠ¶æ€ï¼Œé¿å…å¤æ‚çš„åˆ‡æ¢é€»è¾‘
api_key_list = [
    "ms-376c277c-8f18-4c42-9ba9-c4b0911fa9b0",
    "ms-78247b29-fd23-4ef9-a86a-0e792da83f3e",
    "ms-89acac3e-5ed3-4c06-ad67-8941aef812d1",
    'ms-b980f2d1-86e3-43bc-a72e-30c6849b3148',
    'ms-6a7bc978-f320-48bc-aa67-f9c2e6c9d5c6',
    'ms-7fa00741-856a-4134-80d2-f296b15c0e76',
    'ms-ca41cec5-48ca-4a9e-9fdf-ac348a638d11',
    
]

# ğŸ”‘ å…¨å±€API KeyçŠ¶æ€
GLOBAL_API_KEY_INDEX = 0
GLOBAL_CURRENT_API_KEY = api_key_list[GLOBAL_API_KEY_INDEX]

# ğŸ¤– å…¨å±€æ¨¡å‹çŠ¶æ€  
# æ¨ç†æ¨¡å‹å¤ªæ…¢äº†
'''
    'Qwen/Qwen3-235B-A22B-Thinking-2507', 
    'deepseek-ai/DeepSeek-R1-0528',
    
'''
available_models_global = [ 


    'deepseek-ai/DeepSeek-V3',
    'Qwen/Qwen3-Coder-480B-A35B-Instruct',
    'Qwen/Qwen3-235B-A22B-Instruct-2507',
    'ZhipuAI/GLM-4.5', 
    'deepseek-ai/DeepSeek-V3.1',
 
]

# ğŸ§  æ¨ç†æ¨¡å‹åˆ—è¡¨ - ç”¨æˆ·æŒ‡å®šçš„4ä¸ªæ¨¡å‹éƒ½æŒ‰æ¨ç†æ¨¡å‹å¤„ç†
THINKING_MODELS = {
    'Qwen/Qwen3-235B-A22B-Thinking-2507',
    'ZhipuAI/GLM-4.5', 
    'deepseek-ai/DeepSeek-V3.1',
    'deepseek-ai/DeepSeek-R1-0528',
}

GLOBAL_MODEL_INDEX = 0
GLOBAL_CURRENT_MODEL = available_models_global[GLOBAL_MODEL_INDEX]

# ğŸ”„ ç®€åŒ–çš„åˆ‡æ¢å‡½æ•°
def switch_to_next_api_key():
    """åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªAPI Key"""
    global GLOBAL_API_KEY_INDEX, GLOBAL_CURRENT_API_KEY, GLOBAL_MODEL_INDEX, GLOBAL_CURRENT_MODEL
    
    old_api_key = GLOBAL_CURRENT_API_KEY
    GLOBAL_API_KEY_INDEX = (GLOBAL_API_KEY_INDEX + 1) % len(api_key_list)
    GLOBAL_CURRENT_API_KEY = api_key_list[GLOBAL_API_KEY_INDEX]
    
    # åˆ‡æ¢API Keyæ—¶é‡ç½®åˆ°ç¬¬ä¸€ä¸ªæ¨¡å‹
    GLOBAL_MODEL_INDEX = 0
    GLOBAL_CURRENT_MODEL = available_models_global[GLOBAL_MODEL_INDEX]
    
    print(f"ğŸ”‘ API Keyåˆ‡æ¢: ***{old_api_key[-8:]} â†’ ***{GLOBAL_CURRENT_API_KEY[-8:]}")
    print(f"ğŸ”„ é‡ç½®åˆ°ç¬¬ä¸€ä¸ªæ¨¡å‹: {GLOBAL_CURRENT_MODEL}")
    return True

def switch_to_next_model():
    """åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªæ¨¡å‹"""
    global GLOBAL_MODEL_INDEX, GLOBAL_CURRENT_MODEL
    
    old_model = GLOBAL_CURRENT_MODEL
    GLOBAL_MODEL_INDEX = (GLOBAL_MODEL_INDEX + 1) % len(available_models_global)
    GLOBAL_CURRENT_MODEL = available_models_global[GLOBAL_MODEL_INDEX]
    
    print(f"ğŸ”„ æ¨¡å‹åˆ‡æ¢: {old_model.split('/')[-1]} â†’ {GLOBAL_CURRENT_MODEL.split('/')[-1]}")
    
    # å¦‚æœå›åˆ°ç¬¬ä¸€ä¸ªæ¨¡å‹ï¼Œè¯´æ˜æ‰€æœ‰æ¨¡å‹éƒ½è¯•è¿‡äº†ï¼Œåˆ‡æ¢API Key
    if GLOBAL_MODEL_INDEX == 0:
        print("âš ï¸ æ‰€æœ‰æ¨¡å‹éƒ½å·²å°è¯•ï¼Œåˆ‡æ¢API Key")
        switch_to_next_api_key()
        return True
    
    return True

def get_current_api_key():
    """è·å–å½“å‰API Key"""
    return GLOBAL_CURRENT_API_KEY

def get_current_model():
    """è·å–å½“å‰æ¨¡å‹"""
    return GLOBAL_CURRENT_MODEL

def reset_global_state():
    """é‡ç½®å…¨å±€çŠ¶æ€åˆ°åˆå§‹å€¼"""
    global GLOBAL_API_KEY_INDEX, GLOBAL_CURRENT_API_KEY, GLOBAL_MODEL_INDEX, GLOBAL_CURRENT_MODEL
    
    GLOBAL_API_KEY_INDEX = 0
    GLOBAL_CURRENT_API_KEY = api_key_list[0]
    GLOBAL_MODEL_INDEX = 0 
    GLOBAL_CURRENT_MODEL = available_models_global[0]
    
    print(f"ğŸ”„ å…¨å±€çŠ¶æ€å·²é‡ç½®: API Key ***{GLOBAL_CURRENT_API_KEY[-8:]}, æ¨¡å‹ {GLOBAL_CURRENT_MODEL.split('/')[-1]}")
    return True

def is_thinking_model(model_name: str) -> bool:
    """æ£€æµ‹æ˜¯å¦ä¸ºæ¨ç†æ¨¡å‹ - æ£€æŸ¥æ˜¯å¦åœ¨æŒ‡å®šçš„æ¨ç†æ¨¡å‹åˆ—è¡¨ä¸­"""
    return model_name in THINKING_MODELS

class NewModel(LabelStudioMLBase):
    """Custom ML Backend model
    """
    
    def setup(self):
        """Configure any parameters of your model here
        """
        self.set("model_version", "2.0.0-æ´ªæ¶ç¾å®³ä¸“ç”¨ç‰ˆ")
        
        # ğŸŒ ä½¿ç”¨å…¨å±€çŠ¶æ€ç®¡ç† - ç®€åŒ–æ¶æ„
        self.api_base_url = os.getenv('MODELSCOPE_API_URL', 'https://api-inference.modelscope.cn/v1')
        
        # ğŸ¯ ç®€åŒ–çš„å¤±è´¥è®¡æ•°
        self.consecutive_failures = 0  # å½“å‰æ¨¡å‹çš„è¿ç»­å¤±è´¥æ¬¡æ•°
        self.max_failures_before_switch = 2  # è¿ç»­å¤±è´¥2æ¬¡ååˆ‡æ¢
        
        # å»¶è¿Ÿåˆå§‹åŒ–å®¢æˆ·ç«¯ï¼Œåªåœ¨éœ€è¦æ—¶è¿æ¥
        self.client = None
        self._api_initialized = False
        
        print("âœ… æ´ªæ¶ç¾å®³ä¸“ç”¨MLåç«¯åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ¯ å½“å‰æ¨¡å‹: {get_current_model().split('/')[-1]}")
        print(f"ğŸ”‘ å½“å‰API Key: ***{get_current_api_key()[-8:]}")
        print(f"ğŸ“‹ å¯ç”¨æ¨¡å‹: {len(available_models_global)} ä¸ª")
        print(f"ğŸ”‘ å¯ç”¨API Key: {len(api_key_list)} ä¸ª")
        print(f"ğŸ”„ ç®€åŒ–åˆ‡æ¢: å¤±è´¥{self.max_failures_before_switch}æ¬¡åˆ‡æ¢æ¨¡å‹ï¼Œæ‰€æœ‰æ¨¡å‹å¤±è´¥åˆ‡æ¢API Key")
        print(f"â° è¶…æ—¶è®¾ç½®: 250ç§’ï¼ˆç»™å¤§æ¨¡å‹å……è¶³å¤„ç†æ—¶é—´ï¼‰")
        print(f"ğŸŒŠ ä¸“ä¸šé¢†åŸŸ: æ´ªæ¶ç¾å®³çŸ¥è¯†æå– v2.0.0")
        print(f"ğŸš€ ç®€åŒ–ç­–ç•¥: ä½¿ç”¨å…¨å±€çŠ¶æ€ç»Ÿä¸€ç®¡ç†API Keyå’Œæ¨¡å‹åˆ‡æ¢")
    
    def reset_state(self):
        """ğŸ”„ é‡ç½®çŠ¶æ€åˆ°åˆå§‹çŠ¶æ€ï¼ˆä½¿ç”¨å…¨å±€çŠ¶æ€ï¼‰"""
        print("ğŸ”„ é‡ç½®çŠ¶æ€åˆ°åˆå§‹çŠ¶æ€...")
        reset_global_state()
        self.consecutive_failures = 0
        
        # é‡ç½®APIè¿æ¥
        self._api_initialized = False
        self.client = None
        
        print(f"âœ… çŠ¶æ€å·²é‡ç½®")
        return True
    
    def _handle_failure(self, reason: str = "æœªçŸ¥é”™è¯¯", force_switch: bool = False):
        """ğŸš¨ ç®€åŒ–çš„å¤±è´¥å¤„ç†é€»è¾‘"""
        self.consecutive_failures += 1
        current_model = get_current_model()
        
        print(f"âŒ æ¨¡å‹å¤±è´¥: {current_model.split('/')[-1]} - {reason} (è¿ç»­: {self.consecutive_failures}/{self.max_failures_before_switch})")
        
        # åˆ¤æ–­æ˜¯å¦éœ€è¦åˆ‡æ¢
        should_switch = force_switch or (self.consecutive_failures >= self.max_failures_before_switch)
        
        if should_switch:
            print(f"ğŸ”„ {'å¼ºåˆ¶' if force_switch else 'è¾¾åˆ°é˜ˆå€¼'}åˆ‡æ¢æ¨¡å‹")
            switch_to_next_model()  # ä½¿ç”¨å…¨å±€å‡½æ•°åˆ‡æ¢
            self.consecutive_failures = 0  # é‡ç½®å¤±è´¥è®¡æ•°
            
            # é‡ç½®APIè¿æ¥
            self._api_initialized = False
            self.client = None
            return True
        
        return False
    
    def _handle_success(self):
        """âœ… å¤„ç†æˆåŠŸï¼Œé‡ç½®å¤±è´¥è®¡æ•°"""
        if self.consecutive_failures > 0:
            print(f"âœ… æ¨¡å‹æ¢å¤æ­£å¸¸")
            self.consecutive_failures = 0
    
    def _should_switch_immediately(self, error_str: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦ç«‹å³åˆ‡æ¢æ¨¡å‹ï¼ˆä¸é‡è¯•ï¼‰"""
        immediate_switch_patterns = [
            # APIé™æµé”™è¯¯ - ç«‹å³åˆ‡æ¢
            "429",
            "Too Many Requests", 
            "Request limit exceeded",
            "Rate limit exceeded",
            "Quota exceeded",
            "è¯·æ±‚è¶…é™",  # ä¸­æ–‡é”™è¯¯ä¿¡æ¯
            "è¯·æ±‚é™åˆ¶",
            "è¶…å‡ºé™åˆ¶",
            "è¾¾åˆ°é™åˆ¶",
            "Exceeded limit",
            "API rate limit",
            "Usage limit exceeded",
            "Daily limit exceeded",
            "Monthly limit exceeded",
            
            # è®¤è¯/æƒé™é”™è¯¯ - ç«‹å³åˆ‡æ¢
            "401", 
            "403",
            "Unauthorized",
            "Forbidden",
            "Invalid API key",
            "API key expired",
            
            # æ¨¡å‹ä¸å¯ç”¨é”™è¯¯ - ç«‹å³åˆ‡æ¢
            "404",
            "Model not found",
            "Model unavailable",
            "Service unavailable",
            "Model is overloaded",
            
            # æœåŠ¡å™¨å†…éƒ¨é”™è¯¯ - ç«‹å³åˆ‡æ¢
            "500",
            "502", 
            "503",
            "504",
            "Internal server error",
            "Bad gateway",
            "Gateway timeout",
            
            # å‚æ•°é”™è¯¯ - ç«‹å³åˆ‡æ¢ï¼ˆæ¨¡å‹ä¸æ”¯æŒå½“å‰å‚æ•°ï¼‰
            "Invalid model",
            "Unsupported model",
            "Model does not exist",
            
            # ä¸¥é‡è¶…æ—¶é”™è¯¯ - ç«‹å³åˆ‡æ¢ï¼ˆé¿å…é•¿æ—¶é—´ç­‰å¾…ï¼‰
            "Connection timeout",  # è¿æ¥å±‚é¢çš„è¶…æ—¶
            "Read timeout",        # è¯»å–è¶…æ—¶
            "Gateway timeout"      # ç½‘å…³è¶…æ—¶
        ]
        
        error_lower = error_str.lower()
        for pattern in immediate_switch_patterns:
            if pattern.lower() in error_lower:
                return True
        
        return False
    
    def _get_error_type(self, error_str: str) -> str:
        """è·å–é”™è¯¯ç±»å‹æè¿°"""
        error_lower = error_str.lower()
        
        # ğŸš¨ é«˜ä¼˜å…ˆçº§é”™è¯¯ï¼ˆç«‹å³åˆ‡æ¢ï¼‰
        if any(x in error_lower for x in ["429", "too many requests", "rate limit", "quota exceeded", "request limit exceeded", "è¯·æ±‚è¶…é™", "è¯·æ±‚é™åˆ¶", "è¶…å‡ºé™åˆ¶", "è¾¾åˆ°é™åˆ¶", "exceeded limit", "usage limit", "daily limit", "monthly limit"]):
            return "APIé™æµ"
        elif any(x in error_lower for x in ["401", "403", "unauthorized", "forbidden", "api key"]):
            return "è®¤è¯å¤±è´¥"
        elif any(x in error_lower for x in ["404", "model not found", "model unavailable"]):
            return "æ¨¡å‹ä¸å­˜åœ¨"
        elif any(x in error_lower for x in ["500", "502", "503", "504", "internal server"]):
            return "æœåŠ¡å™¨é”™è¯¯"
        elif any(x in error_lower for x in ["invalid model", "unsupported model"]):
            return "æ¨¡å‹ä¸æ”¯æŒ"
        elif any(x in error_lower for x in ["connection timeout", "read timeout", "gateway timeout"]):
            return "ç½‘ç»œè¶…æ—¶"
        elif any(x in error_lower for x in ["timeout", "timed out"]):
            return "å¤„ç†è¶…æ—¶"
        
        # ğŸ”„ ä¸€èˆ¬é”™è¯¯ï¼ˆå¯é‡è¯•ï¼‰  
        elif any(x in error_lower for x in ["connection", "network"]):
            return "ç½‘ç»œè¿æ¥"
        elif any(x in error_lower for x in ["json", "parse", "format"]):
            return "æ ¼å¼é”™è¯¯"
        elif "empty" in error_lower or "ç©º" in error_str:
            return "ç©ºå“åº”"
        else:
            return "æœªçŸ¥é”™è¯¯"
        
    def _ensure_api_connection(self):
        """ğŸ”Œ ç¡®ä¿APIè¿æ¥å·²åˆå§‹åŒ–ï¼ˆä½¿ç”¨å…¨å±€çŠ¶æ€ï¼‰"""
        if self._api_initialized and self.client:
            return True
        
        current_api_key = get_current_api_key()
        current_model = get_current_model()
        
        try:
            print(f"ğŸ”„ è¿æ¥API... (æ¨¡å‹: {current_model.split('/')[-1]}, Key: ***{current_api_key[-8:]})")
            self.client = OpenAI(
                base_url=self.api_base_url,
                api_key=current_api_key,
                max_retries=0,  # ç¦ç”¨å†…ç½®é‡è¯•
                timeout=250.0   # 250ç§’è¶…æ—¶
            )
            
            # ç®€å•æµ‹è¯•è¿æ¥
            response = self.client.chat.completions.create(
                model=current_model,
                messages=[{"role": "user", "content": "test"}],
                max_tokens=5,
                temperature=0.1,
                timeout=250
            )
            
            self._api_initialized = True
            print(f"âœ… APIè¿æ¥æˆåŠŸ")
            return True
            
        except Exception as e:
            error_str = str(e)
            print(f"âŒ APIè¿æ¥å¤±è´¥: {error_str[:100]}")
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç«‹å³åˆ‡æ¢
            if self._should_switch_immediately(error_str):
                error_type = self._get_error_type(error_str)
                print(f"ğŸ”„ æ£€æµ‹åˆ°éœ€è¦ç«‹å³åˆ‡æ¢çš„é”™è¯¯: {error_type}")
                self._handle_failure(f"è¿æ¥-{error_type}", force_switch=True)
            else:
                self._handle_failure(f"è¿æ¥-{self._get_error_type(error_str)}")
            
            # é‡ç½®è¿æ¥çŠ¶æ€
            self.client = None
            self._api_initialized = False
            return False
    


    def predict(self, tasks: List[Dict], context: Optional[Dict] = None, **kwargs) -> ModelResponse:
        """ å‘½åå®ä½“è¯†åˆ«é¢„æµ‹
            :param tasks: Label Studio tasks in JSON format
            :param context: Label Studio context in JSON format
            :return: ModelResponse with predictions
        """
        total_tasks = len(tasks)
        predictions = []
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºå®ä½“æ ‡æ³¨ä»»åŠ¡
        if not self._is_annotation_task(tasks):
            print("â„¹ï¸ éæ ‡æ³¨ä»»åŠ¡ï¼Œè·³è¿‡å¤§æ¨¡å‹è¿æ¥")
            # è¿”å›ç©ºé¢„æµ‹ç»“æœ
            empty_predictions = []
            for task in tasks:
                empty_prediction = {
                    "model_version": self.get("model_version"),
                    "score": 0.0,
                    "result": []
                }
                empty_predictions.append(empty_prediction)
            return ModelResponse(predictions=empty_predictions)
        
        # ğŸ”Œ ç¡®ä¿APIè¿æ¥ï¼ˆç®€åŒ–é‡è¯•é€»è¾‘ï¼‰
        max_attempts = len(available_models_global)  # æœ€å¤šå°è¯•æ‰€æœ‰æ¨¡å‹
        
        for attempt in range(max_attempts):
            if self._ensure_api_connection():
                break  # è¿æ¥æˆåŠŸ
            else:
                if attempt < max_attempts - 1:
                    print(f"ğŸ”„ è¿æ¥å¤±è´¥ï¼Œå·²è‡ªåŠ¨åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªé…ç½® ({attempt + 1}/{max_attempts})")
                    continue
                else:
                    print("âŒ æ‰€æœ‰é…ç½®éƒ½æ— æ³•è¿æ¥ï¼Œè¿”å›ç©ºç»“æœ")
                    empty_predictions = []
                    for task in tasks:
                        empty_prediction = {
                            "model_version": self.get("model_version"),
                            "score": 0.0,
                            "result": [],
                            "error": f"æ‰€æœ‰{len(available_models_global)}ä¸ªæ¨¡å‹éƒ½æ— æ³•è¿æ¥"
                        }
                        empty_predictions.append(empty_prediction)
                    return ModelResponse(predictions=empty_predictions)
        
        if total_tasks > 1:
            print(f"ğŸš€ å¼€å§‹å¤„ç† {total_tasks} ä¸ªæ ‡æ³¨ä»»åŠ¡")
        
        start_time = time.time()
        
        for i, task in enumerate(tasks):
            if total_tasks > 1:  # å¤šä»»åŠ¡æ—¶æ˜¾ç¤ºè¿›åº¦
                print(f"\nğŸ”„ å¤„ç†ä»»åŠ¡ {i+1}/{total_tasks}")
            
            # è®°å½•å¼€å§‹æ—¶é—´
            task_start_time = time.time()
            
            try:
                prediction = self._process_single_task(task)
                task_end_time = time.time()
                task_duration = task_end_time - task_start_time
                
                if prediction and prediction.get('result') and len(prediction.get('result', [])) > 0:
                    # æˆåŠŸè¯†åˆ«åˆ°å®ä½“
                    predictions.append(prediction)
                    entities_count = len(prediction.get('result', []))
                    if total_tasks > 1:
                        print(f"âœ… ä»»åŠ¡ {i+1} æˆåŠŸ (è€—æ—¶: {task_duration:.1f}s, å®ä½“: {entities_count})")
                else:
                    # æœªè¯†åˆ«åˆ°å®ä½“æˆ–å¤„ç†å¤±è´¥
                    failed_prediction = {
                        "model_version": self.get("model_version"),
                        "score": 0.0,
                        "result": [],
                        "error": "æœªè¯†åˆ«åˆ°ä»»ä½•å®ä½“",
                        "status": "failed"
                    }
                    predictions.append(failed_prediction)
                    if total_tasks > 1:
                        print(f"âŒ ä»»åŠ¡ {i+1} å¤±è´¥ - æ— å®ä½“ (è€—æ—¶: {task_duration:.1f}s)")
                    
            except Exception as e:
                task_end_time = time.time()
                task_duration = task_end_time - task_start_time
                if total_tasks > 1:
                    print(f"âŒ ä»»åŠ¡ {i+1} å¼‚å¸¸ (è€—æ—¶: {task_duration:.1f}s): {str(e)[:50]}")
                failed_prediction = {
                    "model_version": self.get("model_version"),
                    "score": 0.0,
                    "result": [],
                    "error": f"å¤„ç†å¼‚å¸¸: {str(e)}",
                    "status": "failed"
                }
                predictions.append(failed_prediction)
            
        
        # å¤„ç†å®Œæˆåçš„æ€»ç»“
        end_time = time.time()
        total_duration = end_time - start_time
        processed_count = len(predictions)
        
        # ç»Ÿè®¡æˆåŠŸå’Œå¤±è´¥çš„ä»»åŠ¡
        successful_tasks = sum(1 for p in predictions if p.get('result') and len(p.get('result', [])) > 0)
        failed_tasks = processed_count - successful_tasks
        total_entities = sum(len(p.get('result', [])) for p in predictions)
        
        if total_tasks > 1:
            print(f"\nğŸ“Š å¤„ç†å®Œæˆ: {successful_tasks}/{processed_count} æˆåŠŸ, æ€»å®ä½“: {total_entities}, è€—æ—¶: {total_duration:.1f}s")
            if failed_tasks > 0:
                print(f"âš ï¸ {failed_tasks} ä¸ªä»»åŠ¡å¤„ç†å¤±è´¥")
            
            # æ˜¾ç¤ºçŠ¶æ€ç»Ÿè®¡
            self._print_status()
        
        return ModelResponse(predictions=predictions)
    
    def _is_annotation_task(self, tasks: List[Dict]) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºéœ€è¦è¿›è¡Œå®ä½“æ ‡æ³¨çš„ä»»åŠ¡"""
        if not tasks:
            return False
        
        # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦åŒ…å«éœ€è¦æ ‡æ³¨çš„æ–‡æœ¬å†…å®¹
        for task in tasks:
            task_data = task.get('data', {})
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡æœ¬å†…å®¹éœ€è¦æ ‡æ³¨
            text_keys = ['text', 'content', 'prompt', 'question', 'description', 'query']
            has_text_content = False
            
            for key, value in task_data.items():
                if isinstance(value, str) and key in text_keys and value.strip():
                    has_text_content = True
                    break
            
            if has_text_content:
                # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰æ ‡æ³¨ç»“æœï¼ˆå¦‚æœæœ‰å®Œæ•´æ ‡æ³¨åˆ™å¯èƒ½æ˜¯æŸ¥çœ‹ä»»åŠ¡ï¼‰
                annotations = task.get('annotations', [])
                if annotations:
                    # å¦‚æœæœ‰æ ‡æ³¨ä½†æ˜¯ç©ºçš„ï¼Œè¯´æ˜éœ€è¦é¢„æµ‹
                    for annotation in annotations:
                        result = annotation.get('result', [])
                        if not result:  # ç©ºæ ‡æ³¨ï¼Œéœ€è¦é¢„æµ‹
                            return True
                else:
                    # æ²¡æœ‰æ ‡æ³¨ï¼Œéœ€è¦é¢„æµ‹
                    return True
        
        return False
    
    def _process_single_task(self, task: Dict) -> Optional[Dict]:
        """å¤„ç†å•ä¸ªä»»åŠ¡"""
        task_data = task.get('data', {})
        
        # æå–æ–‡æœ¬å†…å®¹
        text_content = ""
        text_keys = ['text', 'content', 'prompt', 'question', 'description', 'query']
        
        for key, value in task_data.items():
            if isinstance(value, str) and key in text_keys:
                text_content = value
                break
        
        if not text_content:
            return None
        
        # æ„å»ºNERæç¤ºè¯ï¼ˆä½¿ç”¨é…ç½®åŒ–çš„å®ä½“æ ‡ç­¾ï¼‰
        json_format = get_json_format_example()
        
        # æŒ‰ç±»åˆ«ç»„ç»‡å®ä½“ç±»å‹è¯´æ˜
        try:
            from entity_config import get_all_categories, get_entities_by_category
            categories = get_all_categories()
            categorized_examples = ""
            
            for category in categories:
                entities = get_entities_by_category(category)
                if entities:
                    # ç‰¹æ®Šå¤„ç†å…³ç³»æ ‡ç­¾ç±»åˆ«
                    if category == "å…³ç³»æ ‡ç­¾":
                        categorized_examples += f"\nğŸ”— {category}ç±»ï¼ˆè¯­ä¹‰å…³ç³»å®ä½“ï¼‰:\n"
                        for label_key, config in list(entities.items())[:8]:  # å…³ç³»æ ‡ç­¾æ˜¾ç¤ºæ›´å¤š
                            examples = "ã€".join(config['examples'][:3])  # å…³ç³»æ ‡ç­¾æ˜¾ç¤º3ä¸ªç¤ºä¾‹
                            description = config['description']
                            categorized_examples += f"   â€¢ {description}: {examples}\n"
                    else:
                        categorized_examples += f"\nğŸ“‚ {category}ç±»:\n"
                        for label_key, config in list(entities.items())[:5]:  # æ¯ç±»æœ€å¤šæ˜¾ç¤º5ä¸ªå®ä½“ï¼Œé¿å…æç¤ºè¯è¿‡é•¿
                            examples = "ã€".join(config['examples'][:2])  # æ¯ä¸ªå®ä½“æ˜¾ç¤º2ä¸ªç¤ºä¾‹
                            description = config['description']
                            categorized_examples += f"   â€¢ {description}: {examples}\n"
            
            # ç”Ÿæˆç®€åŒ–çš„å®ä½“åˆ—è¡¨ï¼ˆä½¿ç”¨descriptionï¼‰
            entity_descriptions = []
            for label_key in ENTITY_LABELS[:20]:  # åªæ˜¾ç¤ºå‰20ä¸ªï¼Œé¿å…è¿‡é•¿
                if label_key in NER_ENTITY_CONFIG:
                    entity_descriptions.append(NER_ENTITY_CONFIG[label_key]['description'])
                else:
                    entity_descriptions.append(label_key)
            
            entity_labels_list = "ã€".join(entity_descriptions)
            if len(ENTITY_LABELS) > 20:
                entity_labels_list += f"ç­‰{len(ENTITY_LABELS)}ç§å®ä½“ç±»å‹"
                
        except ImportError:
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨åŸæ¥çš„æ ¼å¼
            categorized_examples = ""
            for label, config in NER_ENTITY_CONFIG.items():
                examples = "ã€".join(config['examples'][:2])
                categorized_examples += f"   {label}({config['description']}): {examples}\n"
            entity_labels_list = "ã€".join(ENTITY_LABELS)
        
        # ç”Ÿæˆä¸¥æ ¼çš„æ ‡ç­¾åˆ—è¡¨ï¼ˆåªæ˜¾ç¤ºæ ‡ç­¾åç§°ï¼Œä¸æ˜¾ç¤ºæè¿°ï¼‰
        valid_labels_only = list(ENTITY_LABELS)
        labels_display = "ã€".join(valid_labels_only)
        
        prompt = f"""è¯·å¯¹ä»¥ä¸‹æ–‡æœ¬è¿›è¡Œå‘½åå®ä½“è¯†åˆ«ï¼Œè¯†åˆ«å‡ºæ–‡æœ¬ä¸­å­˜åœ¨çš„æ‰€æœ‰å®ä½“ï¼ŒåŒ…æ‹¬ä¼ ç»Ÿçš„å‘½åå®ä½“å’Œå…³ç³»è¡¨è¾¾ã€‚

ğŸ“ æ–‡æœ¬å†…å®¹ï¼š
{text_content}

ğŸ¯ æ”¯æŒçš„å®ä½“ç±»å‹åŠç¤ºä¾‹ï¼š{categorized_examples}

ğŸ”— å…³ç³»æ ‡ç­¾è¯´æ˜ï¼š
å…³ç³»æ ‡ç­¾ç”¨äºæ ‡æ³¨å®ä½“ä¹‹é—´çš„è¯­ä¹‰å…³ç³»ï¼Œé€šå¸¸æ˜¯åŠ¨è¯çŸ­è¯­æˆ–è¿æ¥è¯ã€‚è¿™äº›å…³ç³»è¯åŒæ ·ä½œä¸ºå®ä½“è¿›è¡Œæ ‡æ³¨ï¼š

ğŸ’¡ å…³ç³»æ ‡ç­¾æ ‡æ³¨åŸåˆ™ï¼š
1. æ ‡æ³¨å®Œæ•´çš„å…³ç³»è¡¨è¾¾ï¼Œè€Œä¸æ˜¯å•ä¸ªè¯æ±‡
2. åŒ…å«å…³ç³»åŠ¨è¯åŠå…¶å‰åçš„ç›¸å…³æˆåˆ†
3. å…³ç³»æ ‡ç­¾é€šå¸¸è¿æ¥ä¸¤ä¸ªæˆ–å¤šä¸ªå…¶ä»–å®ä½“
4. ç¤ºä¾‹ï¼š
   - "æ ¹æ®ã€Šé˜²æ´ªæ³•ã€‹ç¬¬åæ¡è§„å®š" â†’ "æ ¹æ®...è§„å®š"æ ‡æ³¨ä¸º"ä¾æ®å…³ç³»"
   - "æ°´åˆ©éƒ¨è´Ÿè´£å…¨å›½é˜²æ±›å·¥ä½œ" â†’ "è´Ÿè´£"æ ‡æ³¨ä¸º"è´£ä»»å…³ç³»"
   - "æ´ªæ°´å¯¼è‡´å†œç”°å—æŸ" â†’ "å¯¼è‡´"æ ‡æ³¨ä¸º"å› æœå…³ç³»"
   - "å„éƒ¨é—¨åè°ƒé…åˆæŠ¢é™©æ•‘ç¾" â†’ "åè°ƒé…åˆ"æ ‡æ³¨ä¸º"åè°ƒå…³ç³»"

ğŸ¥ ç–¾ç—…ä¸å¥åº·å®ä½“è¯´æ˜ï¼š
ç–¾ç—…ä¸å¥åº·ç±»å®ä½“ç”¨äºæ ‡æ³¨ä¸æ´ªæ¶ç¾å®³ç›¸å…³çš„ç–¾ç—…ã€å¥åº·çŠ¶å†µå’ŒåŒ»ç–—é˜²ç–«æªæ–½ï¼š
1. ç–¾ç—…ç±»å‹ï¼šä¼ æŸ“ç—…ã€æ°´ç”Ÿç–¾ç—…ã€ç¯å¢ƒç—…ç­‰
2. å¥åº·çŠ¶å†µï¼šå—ä¼¤ã€ä¸­æ¯’ã€æ„ŸæŸ“ç­‰çŠ¶æ€æè¿°
3. åŒ»ç–—éœ€æ±‚ï¼šæ•‘æ²»ã€è¯å“ã€åŒ»ç–—è®¾å¤‡ç­‰éœ€æ±‚
4. é˜²ç–«æªæ–½ï¼šæ¶ˆæ¯’ã€ç–«è‹—ã€éš”ç¦»ç­‰é¢„é˜²æªæ–½
ç¤ºä¾‹ï¼š
   - "éœä¹±ã€ç—¢ç–¾ç­‰è‚ é“ä¼ æŸ“ç—…" â†’ "ç–¾ç—…ç±»å‹"
   - "ç¾æ°‘èº«ä½“çŠ¶å†µè‰¯å¥½" â†’ "å¥åº·çŠ¶å†µ"
   - "æ€¥éœ€æŠ—ç”Ÿç´ å’Œæ¶ˆæ¯’ç”¨å“" â†’ "åŒ»ç–—éœ€æ±‚"
   - "å¯¹ç¾åŒºè¿›è¡Œå…¨é¢æ¶ˆæ¯’" â†’ "é˜²ç–«æªæ–½"

ğŸ‘¥ äººå‘˜ä¿¡æ¯å®ä½“è¯´æ˜ï¼š
äººå‘˜ä¿¡æ¯ç±»å®ä½“ç”¨äºæ ‡æ³¨ä¸äººå‘˜ç›¸å…³çš„å…·ä½“ä¿¡æ¯ï¼š
1. äººå‘˜ä¿¡æ¯ï¼šå§“åã€å¹´é¾„ã€æ€§åˆ«ã€èº«ä»½ç­‰ä¸ªäººåŸºæœ¬ä¿¡æ¯
2. èŒåŠ¡èŒç§°ï¼šèŒä½ã€èŒçº§ã€ä¸“ä¸šæŠ€æœ¯èŒç§°ç­‰
3. ä¸“ä¸šæŠ€èƒ½ï¼šä¸“ä¸šèƒ½åŠ›ã€æŠ€æœ¯ç‰¹é•¿ã€å·¥ä½œç»éªŒç­‰
4. è”ç³»æ–¹å¼ï¼šç”µè¯ã€åœ°å€ã€é‚®ç®±ç­‰è”ç³»ä¿¡æ¯
ç¤ºä¾‹ï¼š
   - "å¼ ä¸‰ï¼Œç”·ï¼Œ45å²ï¼Œå…šå‘˜" â†’ "äººå‘˜ä¿¡æ¯"
   - "é«˜çº§å·¥ç¨‹å¸ˆã€é¡¹ç›®è´Ÿè´£äºº" â†’ "èŒåŠ¡èŒç§°"
   - "å…·æœ‰20å¹´æ°´åˆ©å·¥ç¨‹ç»éªŒ" â†’ "ä¸“ä¸šæŠ€èƒ½"
   - "è”ç³»ç”µè¯ï¼š139****8888" â†’ "è”ç³»æ–¹å¼"

ğŸ”¢ æ—¶é—´æ•°é‡å®ä½“è¯´æ˜ï¼š
æ—¶é—´æ•°é‡ç±»å®ä½“ç”¨äºæ ‡æ³¨å„ç§æ—¶é—´å’Œæ•°é‡çš„å…·ä½“ä¿¡æ¯ï¼š
1. æ—¶é—´æ•°é‡ï¼šå…·ä½“çš„æ—¶é—´é•¿åº¦ã€æœŸé™ã€æ—¶é•¿ç­‰
2. æŒç»­æ—¶é—´ï¼šäº‹ä»¶æˆ–çŠ¶æ€çš„æŒç»­æ—¶é•¿
3. é¢‘ç‡å‘¨æœŸï¼šé‡å¤å‘ç”Ÿçš„æ—¶é—´é—´éš”ã€é¢‘ç‡ç­‰
4. æ•°é‡è§„æ¨¡ï¼šäººæ•°ã€ç‰©èµ„æ•°é‡ã€è§„æ¨¡å¤§å°ç­‰
ç¤ºä¾‹ï¼š
   - "è¿ç»­é™é›¨72å°æ—¶" â†’ "æ—¶é—´æ•°é‡"
   - "è­¦æŠ¥æŒç»­3å¤©" â†’ "æŒç»­æ—¶é—´"
   - "æ¯éš”2å°æ—¶å·¡æŸ¥ä¸€æ¬¡" â†’ "é¢‘ç‡å‘¨æœŸ"
   - "è½¬ç§»ç¾¤ä¼—5000äºº" â†’ "æ•°é‡è§„æ¨¡"

âš ï¸ ä¸¥æ ¼è¦æ±‚ï¼š
1. è¯†åˆ«æ–‡æœ¬ä¸­çœŸå®å­˜åœ¨çš„æ‰€æœ‰å®ä½“ï¼ŒåŒ…æ‹¬ä¼ ç»Ÿå®ä½“å’Œå…³ç³»
2. å‡†ç¡®æ ‡æ³¨å®ä½“çš„èµ·å§‹å’Œç»“æŸä½ç½®ï¼ˆåŸºäºå­—ç¬¦ä½ç½®ï¼‰
3. æ ‡ç­¾åç§°å¿…é¡»ä¸¥æ ¼ä½¿ç”¨ä¸‹é¢åˆ—å‡ºçš„æ ‡ç­¾åç§°ï¼Œä¸€å­—ä¸å·®
4. ç¦æ­¢ä½¿ç”¨æè¿°æ€§æ–‡å­—ã€ç®€åŒ–åç§°æˆ–ä»»ä½•å˜ä½“å½¢å¼
5. å¦‚æœå®ä½“ç±»å‹ä¸åœ¨æ ‡ç­¾åˆ—è¡¨ä¸­ï¼Œåˆ™ä¸è¦æ ‡æ³¨è¯¥å®ä½“
6. å…³ç³»æ ‡ç­¾è¦åŒ…å«å®Œæ•´çš„å…³ç³»è¡¨è¾¾ï¼Œä¸è¦åªæ ‡æ³¨å•ä¸ªåŠ¨è¯

ğŸ” ç‰¹åˆ«å…³æ³¨ï¼š
- æ³•å¾‹æ¡æ¬¾ï¼šè¯†åˆ«"ç¬¬Xæ¡"ã€"ç¬¬Xç« "ã€"ç¬¬XèŠ‚"ç­‰æ³•å¾‹æ¡æ¬¾æ ¼å¼
- å…³ç³»è¡¨è¾¾ï¼šè¯†åˆ«è¡¨ç¤ºä¾æ®ã€è´£ä»»ã€ç®¡è¾–ã€å› æœç­‰å…³ç³»çš„åŠ¨è¯çŸ­è¯­
- æ—¶åºå…³ç³»ï¼šè¯†åˆ«è¡¨ç¤ºæ—¶é—´å…ˆåçš„å…³ç³»è¯æ±‡
- å½±å“å…³ç³»ï¼šè¯†åˆ«è¡¨ç¤ºå½±å“ã€æ³¢åŠçš„å…³ç³»è¡¨è¾¾

ğŸ“‹ è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ç»“æœï¼š
{json_format}

ğŸ·ï¸ ä¸¥æ ¼ä½¿ç”¨ä»¥ä¸‹æ ‡ç­¾åç§°ï¼ˆå¤åˆ¶ç²˜è´´ï¼Œä¸€å­—ä¸å·®ï¼‰ï¼š
{labels_display}

âŒ ç¦æ­¢äº‹é¡¹ï¼š
- ç¦æ­¢ä½¿ç”¨æè¿°æ€§æ–‡å­—ä½œä¸ºæ ‡ç­¾ï¼ˆå¦‚"æ”¿åºœéƒ¨é—¨"åº”ä½¿ç”¨"æ”¿åºœæœºæ„"ï¼‰
- ç¦æ­¢ä½¿ç”¨ç®€åŒ–å½¢å¼ï¼ˆå¦‚"æ¡æ¬¾"åº”ä½¿ç”¨"æ³•å¾‹æ¡æ¬¾"ï¼‰
- ç¦æ­¢ä½¿ç”¨è¿‘ä¼¼è¯æ±‡ï¼ˆå¦‚"æ³•è§„"åº”ä½¿ç”¨"æ³•å¾‹æ³•è§„"ï¼‰
- ç¦æ­¢è‡ªåˆ›æ ‡ç­¾åç§°
- ç¦æ­¢åªæ ‡æ³¨å…³ç³»åŠ¨è¯çš„å•ä¸ªè¯æ±‡ï¼Œè¦æ ‡æ³¨å®Œæ•´çš„å…³ç³»è¡¨è¾¾

âœ… æ­£ç¡®ç¤ºä¾‹ï¼š
å®ä½“æ ‡ç­¾ï¼š
- æ ‡ç­¾å¿…é¡»æ˜¯ï¼š"æ³•å¾‹æ¡æ¬¾"ï¼Œä¸èƒ½æ˜¯"æ¡æ¬¾"ã€"æ³•æ¡"ã€"æ¡æ–‡"
- æ ‡ç­¾å¿…é¡»æ˜¯ï¼š"æ”¿åºœæœºæ„"ï¼Œä¸èƒ½æ˜¯"æ”¿åºœéƒ¨é—¨"ã€"æœºæ„"
- æ ‡ç­¾å¿…é¡»æ˜¯ï¼š"æ³•å¾‹æ³•è§„"ï¼Œä¸èƒ½æ˜¯"æ³•å¾‹"ã€"æ³•è§„"ã€"æ¡ä¾‹"

å…³ç³»æ ‡ç­¾ï¼š
- "æ ¹æ®ã€Šé˜²æ´ªæ³•ã€‹è§„å®š" â†’ "ä¾æ®å…³ç³»"
- "æ°´åŠ¡å±€è´Ÿè´£æ²³é“ç®¡ç†" â†’ "è´£ä»»å…³ç³»"  
- "æ´ªæ°´é€ æˆæŸå¤±" â†’ "å› æœå…³ç³»"
- "å„éƒ¨é—¨åè°ƒé…åˆ" â†’ "åè°ƒå…³ç³»"
- "æ±›æœŸæœŸé—´æ‰§è¡Œé¢„æ¡ˆ" â†’ "æ‰§è¡Œå…³ç³»"

ç–¾ç—…ä¸å¥åº·æ ‡ç­¾ï¼š
- "éœä¹±ç–«æƒ…" â†’ "ç–¾ç—…ç±»å‹"
- "ä¼¤å‘˜æƒ…å†µç¨³å®š" â†’ "å¥åº·çŠ¶å†µ"
- "éœ€è¦åŒ»ç–—æ•‘åŠ©" â†’ "åŒ»ç–—éœ€æ±‚"
- "å¼€å±•é˜²ç–«æ¶ˆæ¯’" â†’ "é˜²ç–«æªæ–½"

äººå‘˜ä¿¡æ¯æ ‡ç­¾ï¼š
- "ææ˜ï¼Œå·¥ç¨‹å¸ˆ" â†’ "äººå‘˜ä¿¡æ¯"
- "é˜²æ±›æŒ‡æŒ¥é•¿" â†’ "èŒåŠ¡èŒç§°"
- "æ°´åˆ©ä¸“ä¸šæŠ€æœ¯" â†’ "ä¸“ä¸šæŠ€èƒ½"
- "ç”µè¯13912345678" â†’ "è”ç³»æ–¹å¼"

æ—¶é—´æ•°é‡æ ‡ç­¾ï¼š
- "æŒç»­48å°æ—¶" â†’ "æ—¶é—´æ•°é‡"
- "è­¦æˆ’æœŸ3å¤©" â†’ "æŒç»­æ—¶é—´"
- "æ¯2å°æ—¶ä¸€æ¬¡" â†’ "é¢‘ç‡å‘¨æœŸ"
- "è½¬ç§»5000äºº" â†’ "æ•°é‡è§„æ¨¡"

è¯·ç¡®ä¿æ¯ä¸ªæ ‡ç­¾éƒ½ä»ä¸Šé¢çš„åˆ—è¡¨ä¸­ç²¾ç¡®å¤åˆ¶ï¼Œå…³ç³»æ ‡ç­¾è¦æ ‡æ³¨å®Œæ•´çš„å…³ç³»è¡¨è¾¾ï¼"""
        
        # è°ƒç”¨API
        api_response = self._call_modelscope_api(prompt)
        
        if api_response and api_response.strip():
            return self._format_prediction(api_response, task)
        
        # APIè°ƒç”¨å¤±è´¥æˆ–è¿”å›ç©ºå“åº”
        print("âŒ APIè°ƒç”¨å¤±è´¥æˆ–è¿”å›ç©ºå“åº”")
        return None
    
    def _call_modelscope_api(self, prompt: str) -> Optional[str]:
        """ğŸš€ ç®€åŒ–çš„APIè°ƒç”¨ï¼ˆä½¿ç”¨å…¨å±€çŠ¶æ€ç®¡ç†ï¼‰"""
        max_total_attempts = len(available_models_global) * 2  # æ€»å…±å°è¯•æ¬¡æ•°
        
        for attempt in range(max_total_attempts):
            # ç¡®ä¿APIè¿æ¥å¯ç”¨
            if not self._ensure_api_connection():
                continue  # å·²ç»åœ¨è¿æ¥æ—¶å¤„ç†äº†åˆ‡æ¢ï¼Œç»§ç»­ä¸‹ä¸€æ¬¡å°è¯•
            
            current_model = get_current_model()
            try:
                print(f"ğŸ”„ è°ƒç”¨API (å°è¯• {attempt + 1}/{max_total_attempts})")
                print(f"   ğŸ“¡ æ¨¡å‹: {current_model.split('/')[-1]} | â° è¶…æ—¶: 250s | ğŸ’¾ æœ€å¤§token: 2000")
                
                start_time = time.time()
                
                # æ£€æµ‹æ˜¯å¦ä¸ºæ¨ç†æ¨¡å‹
                is_thinking_model_flag = is_thinking_model(current_model)
                
                if is_thinking_model_flag:
                    # æ¨ç†æ¨¡å‹ä½¿ç”¨æµå¼å¤„ç†
                    print("   ğŸ§  æ£€æµ‹åˆ°æ¨ç†æ¨¡å‹ï¼Œä½¿ç”¨æµå¼å¤„ç†")
                    content = self._handle_thinking_model_stream(current_model, prompt)
                else:
                    # æ™®é€šæ¨¡å‹ä½¿ç”¨éæµå¼å¤„ç†
                    print("   ğŸ“¡ æ™®é€šæ¨¡å‹ï¼Œä½¿ç”¨éæµå¼å¤„ç†")
                    response = self.client.chat.completions.create(
                        model=current_model,
                        messages=[
                            {"role": "system", "content": "ğŸŒŠ You are a specialized Knowledge Extraction Expert for Flood Disaster Management domain. ä¸“æ³¨ï¼šæ´ªæ¶ç¾å®³æ³•å¾‹æ³•è§„ã€åº”æ€¥é¢„æ¡ˆã€æŠ€æœ¯æ ‡å‡†ã€‚èƒ½åŠ›ï¼šæ³•å¾‹æ¡æ¬¾ã€åº”æ€¥æµç¨‹ã€ç»„ç»‡èŒè´£ã€æŠ€æœ¯æ ‡å‡†ã€å…³ç³»æŠ½å–ã€‚CRITICAL: You must extract both traditional entities AND relational expressions. Use EXACT label names from the provided list. Never use descriptions, abbreviations, or variations. For relation labels, extract complete phrases that express semantic relationships between entities. Always respond with valid JSON format containing only the specified labels."},
                            {"role": "user", "content": prompt}
                        ],
                        max_tokens=2000,
                        temperature=0.1,
                        top_p=0.9,
                        stream=False,
                        timeout=250
                    )
                    
                    if response.choices and len(response.choices) > 0:
                        content = response.choices[0].message.content
                        # ğŸ“‹ è¯¦ç»†è¾“å‡ºæ™®é€šæ¨¡å‹æ¥æ”¶åˆ°çš„ä¿¡æ¯
                        print(f"\nğŸ“¥ =====  æ™®é€šæ¨¡å‹å“åº”ä¿¡æ¯  =====")
                        print(f"ğŸ“ å“åº”å†…å®¹é•¿åº¦: {len(content) if content else 0}")
                        if content:
                            print(f"ğŸ“ å®Œæ•´å“åº”å†…å®¹:\n{content}")
                        print(f"ğŸ“¥ ==============================\n")
                    else:
                        content = None
                        print("âŒ æ™®é€šæ¨¡å‹å“åº”ä¸ºç©ºæˆ–æ— choices")
                
                end_time = time.time()
                api_duration = end_time - start_time
                
                if content and content.strip():
                    # æˆåŠŸ
                    self._handle_success()
                    print(f"   âœ… æˆåŠŸ (è€—æ—¶: {api_duration:.1f}s, é•¿åº¦: {len(content)})")
                    return content
                else:
                    print(f"âš ï¸ è¿”å›ç©ºå†…å®¹")
                    self._handle_failure("ç©ºå“åº”")
                        
            except Exception as e:
                error_str = str(e)
                print(f"âŒ APIå¼‚å¸¸: {error_str[:100]}")
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦ç«‹å³åˆ‡æ¢
                if self._should_switch_immediately(error_str):
                    error_type = self._get_error_type(error_str)
                    print(f"ğŸ”„ ç«‹å³åˆ‡æ¢é”™è¯¯: {error_type}")
                    self._handle_failure(f"ç«‹å³åˆ‡æ¢-{error_type}", force_switch=True)
                else:
                    self._handle_failure(f"APIå¼‚å¸¸-{self._get_error_type(error_str)}")
        
        print("âŒ æ‰€æœ‰å°è¯•éƒ½å¤±è´¥")
        return None
    
    def _handle_thinking_model_stream(self, model: str, prompt: str) -> Optional[str]:
        """å¤„ç†æ¨ç†æ¨¡å‹çš„æµå¼å“åº”"""
        try:
            response = self.client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "ğŸŒŠ You are a specialized Knowledge Extraction Expert for Flood Disaster Management domain. ä¸“æ³¨ï¼šæ´ªæ¶ç¾å®³æ³•å¾‹æ³•è§„ã€åº”æ€¥é¢„æ¡ˆã€æŠ€æœ¯æ ‡å‡†ã€‚èƒ½åŠ›ï¼šæ³•å¾‹æ¡æ¬¾ã€åº”æ€¥æµç¨‹ã€ç»„ç»‡èŒè´£ã€æŠ€æœ¯æ ‡å‡†ã€å…³ç³»æŠ½å–ã€‚CRITICAL: You must extract both traditional entities AND relational expressions. Use EXACT label names from the provided list. Never use descriptions, abbreviations, or variations. For relation labels, extract complete phrases that express semantic relationships between entities. Always respond with valid JSON format containing only the specified labels."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=2000,
                temperature=0.1,
                top_p=0.9,
                stream=True,  # æ¨ç†æ¨¡å‹ä½¿ç”¨æµå¼
                timeout=250
            )
            
            reasoning_content = ""
            answer_content = ""
            done_reasoning = False
            
            print("   ğŸ”„ å¼€å§‹æ¥æ”¶æµå¼å“åº”...")
            
            for chunk in response:
                if hasattr(chunk.choices[0].delta, 'reasoning_content') and chunk.choices[0].delta.reasoning_content:
                    # æ¨ç†è¿‡ç¨‹å†…å®¹
                    reasoning_chunk = chunk.choices[0].delta.reasoning_content
                    reasoning_content += reasoning_chunk
                    
                elif hasattr(chunk.choices[0].delta, 'content') and chunk.choices[0].delta.content:
                    # æœ€ç»ˆç­”æ¡ˆå†…å®¹
                    answer_chunk = chunk.choices[0].delta.content
                    if not done_reasoning:
                        print("   ğŸ§  æ¨ç†å®Œæˆï¼Œå¼€å§‹è¾“å‡ºç­”æ¡ˆ")
                        done_reasoning = True
                    answer_content += answer_chunk
            
            # ğŸ“‹ è¯¦ç»†è¾“å‡ºæ¥æ”¶åˆ°çš„ä¿¡æ¯ï¼Œæ–¹ä¾¿è°ƒè¯•
            print(f"\nğŸ“¥ =====  æ¥æ”¶åˆ°çš„å®Œæ•´å“åº”ä¿¡æ¯  =====")
            print(f"ğŸ§  æ¨ç†å†…å®¹é•¿åº¦: {len(reasoning_content)}")
            if reasoning_content:
                print(f"ğŸ§  æ¨ç†å†…å®¹å‰500å­—ç¬¦:\n{reasoning_content[:500]}")
                if len(reasoning_content) > 500:
                    print(f"ğŸ§  æ¨ç†å†…å®¹å500å­—ç¬¦:\n{reasoning_content[-500:]}")
            
            print(f"\nğŸ“ ç­”æ¡ˆå†…å®¹é•¿åº¦: {len(answer_content)}")
            if answer_content:
                print(f"ğŸ“ å®Œæ•´ç­”æ¡ˆå†…å®¹:\n{answer_content}")
            
            print(f"ğŸ“¥ ================================\n")
            
            # ä¼˜å…ˆä½¿ç”¨ç­”æ¡ˆå†…å®¹ï¼Œå¦‚æœç­”æ¡ˆå†…å®¹ä¸ºç©ºåˆ™ä½¿ç”¨æ¨ç†å†…å®¹
            if answer_content.strip():
                print(f"   âœ… ä½¿ç”¨ç­”æ¡ˆå†…å®¹è¿›è¡Œè§£æ")
                # å¯¹äºDeepSeekæ¨¡å‹ï¼Œæ£€æŸ¥ç­”æ¡ˆå†…å®¹æ˜¯å¦å®Œæ•´
                if 'deepseek' in model.lower():
                    print(f"   ğŸ”§ DeepSeekæ¨¡å‹ï¼Œæ£€æŸ¥JSONå®Œæ•´æ€§...")
                    if not self._is_json_complete(answer_content):
                        print(f"   âš ï¸ DeepSeekè¿”å›çš„JSONä¸å®Œæ•´ï¼Œå°è¯•ä¿®å¤")
                        repaired = self._repair_incomplete_json(answer_content)
                        if repaired:
                            return repaired
                return answer_content.strip()
            elif reasoning_content.strip():
                print(f"   âš ï¸ ç­”æ¡ˆå†…å®¹ä¸ºç©ºï¼Œå°è¯•ä»æ¨ç†å†…å®¹æå–")
                # ä»æ¨ç†å†…å®¹ä¸­æå–æœ€ç»ˆç­”æ¡ˆ
                extracted = self._extract_answer_from_reasoning(reasoning_content)
                if extracted:
                    print(f"   ğŸ“¤ ä»æ¨ç†å†…å®¹æå–çš„ç»“æœ:\n{extracted[:500]}")
                return extracted
            else:
                print(f"   âŒ æ¨ç†å’Œç­”æ¡ˆå†…å®¹éƒ½ä¸ºç©º")
                return None
                
        except Exception as e:
            print(f"   âŒ æµå¼å¤„ç†å¤±è´¥: {str(e)[:100]}")
            raise e
    
    def _extract_answer_from_reasoning(self, reasoning_content: str) -> Optional[str]:
        """ä»æ¨ç†å†…å®¹ä¸­æå–æœ€ç»ˆç­”æ¡ˆ"""
        import re
        
        # å°è¯•æå–JSONéƒ¨åˆ†
        json_patterns = [
            r'```json\s*(.*?)\s*```',  # ```json ä»£ç å—
            r'\{[^{}]*"entities"[^{}]*:.*?\}',  # entities JSON
            r'\{.*?"entities".*?\}',  # å®½æ¾çš„entitiesåŒ¹é…
            r'\{.*\}',  # æœ€åçš„JSONåŒ¹é…
        ]
        
        for pattern in json_patterns:
            matches = re.findall(pattern, reasoning_content, re.DOTALL)
            if matches:
                # è¿”å›æœ€åä¸€ä¸ªåŒ¹é…çš„JSONï¼ˆé€šå¸¸æ˜¯æœ€ç»ˆç»“æœï¼‰
                return matches[-1].strip()
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°JSONï¼Œå°è¯•æå–ç­”æ¡ˆéƒ¨åˆ†
        answer_patterns = [
            r'(?:æœ€ç»ˆç­”æ¡ˆ|ç­”æ¡ˆ|ç»“æœ)[ï¼š:]\s*(.*)',
            r'(?:Final Answer|Answer)[ï¼š:]\s*(.*)',
            r'(?:å› æ­¤|æ‰€ä»¥|ç»¼ä¸Š)[ï¼Œ,]?\s*(.*)',
        ]
        
        for pattern in answer_patterns:
            match = re.search(pattern, reasoning_content, re.IGNORECASE | re.DOTALL)
            if match:
                return match.group(1).strip()
        
        # å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼Œè¿”å›æ¨ç†å†…å®¹çš„ååŠéƒ¨åˆ†
        lines = reasoning_content.strip().split('\n')
        if len(lines) > 10:
            return '\n'.join(lines[-5:])  # è¿”å›æœ€å5è¡Œ
        
        return reasoning_content.strip()
    
    def _repair_incomplete_json(self, json_str: str) -> Optional[str]:
        """ä¿®å¤ä¸å®Œæ•´çš„JSONå­—ç¬¦ä¸²"""
        try:
            print(f"ğŸ”§ å¼€å§‹ä¿®å¤JSON...")
            
            # æ¸…ç†å­—ç¬¦ä¸²
            cleaned = json_str.strip()
            if not cleaned:
                return None
            
            # æå–JSONéƒ¨åˆ†ï¼ˆå¦‚æœæœ‰ä»£ç å—ï¼‰
            import re
            json_match = re.search(r'\{.*', cleaned, re.DOTALL)
            if json_match:
                cleaned = json_match.group()
            
            print(f"ğŸ”§ æ¸…ç†åçš„JSONé•¿åº¦: {len(cleaned)}")
            print(f"ğŸ”§ æ¸…ç†åçš„JSONæœ«å°¾50å­—ç¬¦: ...{cleaned[-50:]}")
            
            # é¦–å…ˆå°è¯•ä¿®å¤å¸¸è§çš„JSONè¯­æ³•é”™è¯¯
            repaired = cleaned
            
            # ä¿®å¤1: ç§»é™¤æœ«å°¾å¤šä½™çš„é€—å·
            repaired = re.sub(r',\s*}', '}', repaired)
            repaired = re.sub(r',\s*]', ']', repaired)
            
            # ä¿®å¤2: ç¡®ä¿JSONæ­£ç¡®ç»“æŸ
            if '"entities"' in repaired and '[' in repaired:
                # ç»Ÿè®¡æ•´ä¸ªJSONçš„èŠ±æ‹¬å·å’Œæ–¹æ‹¬å·å¹³è¡¡æƒ…å†µ
                total_open_braces = repaired.count('{')
                total_close_braces = repaired.count('}')
                total_open_brackets = repaired.count('[')
                total_close_brackets = repaired.count(']')
                
                print(f"ğŸ”§ æ•´ä½“æ‹¬å·ç»Ÿè®¡: å¼€èŠ±æ‹¬å·{total_open_braces}, é—­èŠ±æ‹¬å·{total_close_braces}")
                print(f"ğŸ”§ æ•´ä½“æ–¹æ‹¬å·ç»Ÿè®¡: å¼€æ–¹æ‹¬å·{total_open_brackets}, é—­æ–¹æ‹¬å·{total_close_brackets}")
                
                # æ£€æŸ¥æ˜¯å¦ä»¥æ­£ç¡®çš„ç¬¦å·ç»“å°¾
                last_char = repaired.rstrip()[-1] if repaired.rstrip() else ''
                print(f"ğŸ”§ JSONæœ€åå­—ç¬¦: '{last_char}'")
                
                # è®¡ç®—éœ€è¦è¡¥å…¨çš„æ‹¬å·æ•°é‡
                missing_close_braces = total_open_braces - total_close_braces
                missing_close_brackets = total_open_brackets - total_close_brackets
                
                # é’ˆå¯¹DeepSeekå¸¸è§çš„æƒ…å†µï¼šentitiesæ•°ç»„æ­£ç¡®ä½†ç¼ºå°‘æœ€å¤–å±‚èŠ±æ‹¬å·
                if last_char == ']' and missing_close_braces == 1 and missing_close_brackets == 0:
                    print(f"ğŸ”§ æ£€æµ‹åˆ°DeepSeekå…¸å‹é”™è¯¯ï¼šç¼ºå°‘æœ€å¤–å±‚èŠ±æ‹¬å·")
                    repaired += '\n}'
                    print(f"ğŸ”§ æ·»åŠ æœ€å¤–å±‚èŠ±æ‹¬å·åçš„JSON:\n{repaired}")
                    try:
                        json.loads(repaired)
                        print(f"âœ… æ·»åŠ æœ€å¤–å±‚èŠ±æ‹¬å·ä¿®å¤æˆåŠŸ")
                        return repaired
                    except json.JSONDecodeError as e:
                        print(f"âŒ æ·»åŠ èŠ±æ‹¬å·åä»æœ‰é”™è¯¯: {str(e)}")
                
                # å°è¯•ç›´æ¥è§£æçœ‹æ˜¯å¦æœ‰å…¶ä»–è¯­æ³•é”™è¯¯
                if missing_close_braces == 0 and missing_close_brackets == 0:
                    print(f"ğŸ”§ æ‹¬å·å·²å¹³è¡¡ï¼Œæ£€æŸ¥è¯­æ³•é”™è¯¯...")
                    try:
                        json.loads(repaired)
                        print(f"âœ… JSONå·²ç»æœ‰æ•ˆ")
                        return repaired
                    except json.JSONDecodeError as e:
                        print(f"ğŸ”§ JSONè¯­æ³•é”™è¯¯: {str(e)}")
                        
                        # ä¿®å¤3: å¤„ç†ä¸å®Œæ•´çš„æœ€åä¸€ä¸ªå®ä½“å¯¹è±¡
                        if "Expecting ',' delimiter" in str(e):
                            print(f"ğŸ”§ å¤„ç†ä¸å®Œæ•´çš„å®ä½“å¯¹è±¡...")
                            
                            # æ‰¾åˆ°æœ€åä¸€ä¸ªå®Œæ•´çš„å®ä½“
                            entity_pattern = r'\{\s*"text":\s*"[^"]*",\s*"start":\s*\d+,\s*"end":\s*\d+,\s*"label":\s*"[^"]*"\s*\}'
                            matches = list(re.finditer(entity_pattern, repaired))
                            
                            if matches:
                                # æ‰¾åˆ°æœ€åä¸€ä¸ªå®Œæ•´å®ä½“çš„ç»“æŸä½ç½®
                                last_match = matches[-1]
                                last_entity_end = last_match.end()
                                
                                # æ„å»ºä¿®å¤åçš„JSON
                                entities_part = repaired[:last_entity_end]
                                repaired = entities_part + '\n  ]\n}'
                                
                                print(f"ğŸ”§ ç§»é™¤ä¸å®Œæ•´å®ä½“åçš„JSON:\n{repaired}")
                                try:
                                    json.loads(repaired)
                                    print(f"âœ… ç§»é™¤ä¸å®Œæ•´å®ä½“ä¿®å¤æˆåŠŸ")
                                    return repaired
                                except:
                                    pass
                
                # ä¸€èˆ¬çš„æ‹¬å·è¡¥å…¨é€»è¾‘
                if missing_close_braces > 0 or missing_close_brackets > 0:
                    print(f"ğŸ”§ éœ€è¦è¡¥å…¨: {missing_close_braces}ä¸ª}}, {missing_close_brackets}ä¸ª]")
                    
                    # è¡¥å…¨èŠ±æ‹¬å·
                    for _ in range(missing_close_braces):
                        repaired += '\n    }'
                    
                    # è¡¥å…¨æ–¹æ‹¬å·
                    for _ in range(missing_close_brackets):
                        repaired += '\n  ]'
                    
                    # ç¡®ä¿æœ€å¤–å±‚ä»¥èŠ±æ‹¬å·ç»“å°¾
                    if not repaired.rstrip().endswith('}') and total_open_braces > total_close_braces:
                        repaired += '\n}'
                    
                    print(f"ğŸ”§ è¡¥å…¨æ‹¬å·åçš„JSON:\n{repaired}")
                    try:
                        json.loads(repaired)
                        print(f"âœ… è¡¥å…¨æ‹¬å·ä¿®å¤æˆåŠŸ")
                        return repaired
                    except json.JSONDecodeError as e2:
                        print(f"âŒ è¡¥å…¨æ‹¬å·åä»æœ‰é”™è¯¯: {str(e2)}")
            
            # æœ€åçš„å°è¯•ï¼šé‡æ„JSON
            print(f"ğŸ”§ å°è¯•é‡æ„JSON...")
            if '"entities"' in repaired:
                # æå–æ‰€æœ‰å¯èƒ½çš„å®ä½“
                entity_pattern = r'"text":\s*"([^"]*)",\s*"start":\s*(\d+),\s*"end":\s*(\d+),\s*"label":\s*"([^"]*)"'
                entities_matches = re.findall(entity_pattern, repaired)
                
                if entities_matches:
                    print(f"ğŸ”§ æ‰¾åˆ° {len(entities_matches)} ä¸ªå®Œæ•´å®ä½“ï¼Œé‡æ„JSON")
                    
                    # é‡æ–°æ„å»ºJSON
                    entities_list = []
                    for text, start, end, label in entities_matches:
                        entity = {
                            "text": text,
                            "start": int(start),
                            "end": int(end),
                            "label": label
                        }
                        entities_list.append(entity)
                    
                    reconstructed = {
                        "entities": entities_list
                    }
                    
                    reconstructed_json = json.dumps(reconstructed, ensure_ascii=False, indent=2)
                    print(f"ğŸ”§ é‡æ„çš„JSON:\n{reconstructed_json}")
                    return reconstructed_json
            
            print("âŒ æ‰€æœ‰ä¿®å¤ç­–ç•¥éƒ½å¤±è´¥")
            return None
            
        except Exception as e:
            print(f"âŒ JSONä¿®å¤å¼‚å¸¸: {str(e)}")
            return None
    
    def _is_json_complete(self, json_str: str) -> bool:
        """æ£€æŸ¥JSONå­—ç¬¦ä¸²æ˜¯å¦å®Œæ•´"""
        try:
            # ç®€å•çš„å®Œæ•´æ€§æ£€æŸ¥
            cleaned = json_str.strip()
            if not cleaned:
                return False
            
            # æ£€æŸ¥åŸºæœ¬ç»“æ„
            if not cleaned.startswith('{'):
                return False
            
            # æ£€æŸ¥èŠ±æ‹¬å·å¹³è¡¡
            open_braces = cleaned.count('{')
            close_braces = cleaned.count('}')
            
            # æ£€æŸ¥æ–¹æ‹¬å·å¹³è¡¡
            open_brackets = cleaned.count('[')
            close_brackets = cleaned.count(']')
            
            print(f"ğŸ”§ å®Œæ•´æ€§æ£€æŸ¥: å¼€æ‹¬å·{open_braces}, é—­æ‹¬å·{close_braces}, å¼€æ–¹æ‹¬å·{open_brackets}, é—­æ–¹æ‹¬å·{close_brackets}")
            print(f"ğŸ”§ JSONå¼€å§‹: '{cleaned[:20]}...', ç»“æŸ: '...{cleaned[-20:]}'")
            
            # æ£€æŸ¥æ˜¯å¦å¹³è¡¡
            if open_braces != close_braces or open_brackets != close_brackets:
                print(f"ğŸ”§ æ‹¬å·ä¸å¹³è¡¡")
                return False
            
            # å³ä½¿æ‹¬å·å¹³è¡¡ï¼Œä¹Ÿè¦æ£€æŸ¥æ˜¯å¦ä»¥}ç»“å°¾
            if not cleaned.endswith('}'):
                print(f"ğŸ”§ JSONä¸ä»¥}}ç»“å°¾")
                return False
            
            # å°è¯•è§£æJSON
            try:
                json.loads(cleaned)
                print(f"ğŸ”§ JSONè§£ææˆåŠŸï¼Œæ ¼å¼å®Œæ•´")
                return True
            except json.JSONDecodeError as e:
                print(f"ğŸ”§ JSONè§£æå¤±è´¥ï¼Œæœ‰è¯­æ³•é”™è¯¯: {str(e)}")
                return False
                
        except Exception as e:
            print(f"ğŸ”§ å®Œæ•´æ€§æ£€æŸ¥å¼‚å¸¸: {str(e)}")
            return False
    
    def _map_invalid_label(self, invalid_label: str) -> Optional[str]:
        """æ˜ å°„æ— æ•ˆæ ‡ç­¾åˆ°æœ‰æ•ˆæ ‡ç­¾"""
        # å¸¸è§çš„æ ‡ç­¾æ˜ å°„å…³ç³»
        label_mapping = {
            # åœ°ç†ç›¸å…³æ˜ å°„
            "å½±å“èŒƒå›´": "è¡Œæ”¿åŒºåˆ’",
            "åœ°ç†ä½ç½®": "è¡Œæ”¿åŒºåˆ’", 
            "åœ°åŒº": "è¡Œæ”¿åŒºåˆ’",
            "åŒºåŸŸ": "è¡Œæ”¿åŒºåˆ’",
            "èŒƒå›´": "è¡Œæ”¿åŒºåˆ’",
            
            # æ—¶é—´ç›¸å…³æ˜ å°„
            "æ—¶é—´": "æ—¶é—´èŠ‚ç‚¹",
            "æ—¥æœŸ": "æ—¶é—´èŠ‚ç‚¹",
            "æœŸé—´": "æ—¶é—´èŠ‚ç‚¹",
            
            # ç¾å®³ç›¸å…³æ˜ å°„
            "ç¾å®³": "ç¾å®³ç±»å‹",
            "è‡ªç„¶ç¾å®³": "ç¾å®³ç±»å‹",
            "äº‹æ•…": "ç¾å®³ç±»å‹",
            
            # æœºæ„ç›¸å…³æ˜ å°„
            "æœºæ„": "æ”¿åºœæœºæ„",
            "éƒ¨é—¨": "æ”¿åºœæœºæ„",
            "ç»„ç»‡": "æ”¿åºœæœºæ„",
            
            # æ³•å¾‹ç›¸å…³æ˜ å°„
            "æ³•å¾‹": "æ³•å¾‹æ³•è§„",
            "æ³•è§„": "æ³•å¾‹æ³•è§„",
            "æ¡ä¾‹": "æ³•å¾‹æ³•è§„",
            "è§„å®š": "æ³•å¾‹æ³•è§„",
            
            # æ•°æ®ç›¸å…³æ˜ å°„
            "æ•°æ®": "é™é›¨æ•°æ®",
            "æ•°é‡": "é™é›¨æ•°æ®",
            "é‡çº§": "é™é›¨æ•°æ®",
        }
        
        # ç›´æ¥æ˜ å°„
        if invalid_label in label_mapping:
            mapped = label_mapping[invalid_label]
            if mapped in ENTITY_LABELS:
                return mapped
        
        # æ¨¡ç³ŠåŒ¹é…ï¼ˆåŒ…å«å…³ç³»ï¼‰
        invalid_lower = invalid_label.lower()
        for invalid_key, valid_label in label_mapping.items():
            if invalid_key.lower() in invalid_lower or invalid_lower in invalid_key.lower():
                if valid_label in ENTITY_LABELS:
                    return valid_label
        
        # å¦‚æœè¿˜æ˜¯æ‰¾ä¸åˆ°ï¼Œå°è¯•ç›¸ä¼¼åº¦åŒ¹é…
        for valid_label in ENTITY_LABELS:
            # ç®€å•çš„ç›¸ä¼¼åº¦æ£€æŸ¥ï¼ˆå…±åŒå­—ç¬¦ï¼‰
            common_chars = set(invalid_label) & set(valid_label)
            if len(common_chars) >= min(2, len(invalid_label) // 2):
                return valid_label
        
        return None
    
    def _print_status(self):
        """ğŸ“Š ç®€åŒ–çš„çŠ¶æ€æ˜¾ç¤º"""
        current_model = get_current_model()
        current_api_key = get_current_api_key()
        
        print(f"\nğŸ¤– å½“å‰çŠ¶æ€:")
        print(f"   ğŸ¯ æ¨¡å‹: {current_model.split('/')[-1]} (å¤±è´¥: {self.consecutive_failures}/{self.max_failures_before_switch})")
        print(f"   ğŸ”‘ API Key: ***{current_api_key[-8:]} ({GLOBAL_API_KEY_INDEX + 1}/{len(api_key_list)})")
        print(f"   ğŸ“‹ å¯ç”¨æ¨¡å‹: {len(available_models_global)} ä¸ª")
        print(f"   ğŸ”„ å…¨å±€çŠ¶æ€ç®¡ç†: ç®€åŒ–åˆ‡æ¢é€»è¾‘")
    
    def get_status(self) -> Dict:
        """ğŸ” è·å–ç®€åŒ–çŠ¶æ€ä¿¡æ¯"""
        return {
            "current_model": get_current_model(),
            "current_api_key": f"***{get_current_api_key()[-8:]}",
            "consecutive_failures": self.consecutive_failures,
            "max_failures_before_switch": self.max_failures_before_switch,
            "available_models": available_models_global.copy(),
            "total_api_keys": len(api_key_list),
            "global_model_index": GLOBAL_MODEL_INDEX,
            "global_api_key_index": GLOBAL_API_KEY_INDEX,
            "management_type": "simplified_global_state"
        }
    
    def _format_prediction(self, api_response: str, task: Dict) -> Dict:
        """æ ¼å¼åŒ–é¢„æµ‹ç»“æœä¸ºLabel Studioæ ¼å¼"""
        
        prediction = {
            "model_version": self.get("model_version"),
            "score": 0.95,
            "result": []
        }
        
        # å°è¯•è§£æNERç»“æœ
        ner_results = self._parse_ner_response(api_response, task)
        if ner_results and len(ner_results) > 0:
            prediction["result"] = ner_results
            prediction["score"] = 0.95
            return prediction
        
        # å¦‚æœæ²¡æœ‰è¯†åˆ«åˆ°ä»»ä½•å®ä½“ï¼Œè¿”å›å¤±è´¥ä¿¡æ¯
        prediction["score"] = 0.0
        prediction["result"] = []
        return None
    
    def _parse_ner_response(self, api_response: str, task: Dict) -> Optional[List[Dict]]:
        """è§£æAIè¿”å›çš„å‘½åå®ä½“è¯†åˆ«JSONç»“æœï¼Œå¹¶ç”¨æ­£åˆ™è¡¨è¾¾å¼è¿›è¡Œè¡¥å……"""
        
        # è·å–åŸå§‹æ–‡æœ¬
        task_data = task.get('data', {})
        original_text = ""
        for key in ['text', 'content', 'prompt', 'question', 'description', 'query']:
            if key in task_data and isinstance(task_data[key], str):
                original_text = task_data[key]
                break
        
        if not original_text:
            return None
        
        # åˆå§‹åŒ–ç»“æœåˆ—è¡¨
        results = []
        ai_entities = []
        
        # ç¬¬ä¸€æ­¥ï¼šè§£æAIæ¨¡å‹çš„è¯†åˆ«ç»“æœ
        if api_response and api_response.strip():
            ai_entities = self._parse_ai_entities(api_response, original_text)
            if ai_entities:
                results.extend(ai_entities)
        
        # ç¬¬äºŒæ­¥ï¼šä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è¿›è¡Œè¡¥å……è¯†åˆ«
        regex_entities = self._extract_regex_entities(original_text, ai_entities)
        if regex_entities:
            results.extend(regex_entities)
        
        # ç¬¬ä¸‰æ­¥ï¼šå»é‡å’Œæ’åº
        final_results = self._deduplicate_entities(results)
        
        return final_results if final_results else None
    
    def _parse_ai_entities(self, api_response: str, original_text: str) -> List[Dict]:
        """è§£æAIæ¨¡å‹è¿”å›çš„å®ä½“"""
        ai_results = []
        
        print(f"\nğŸ” =====  å¼€å§‹è§£æAIå“åº”  =====")
        print(f"ğŸ“ åŸå§‹å“åº”é•¿åº¦: {len(api_response)}")
        print(f"ğŸ“ åŸå§‹å“åº”å†…å®¹:\n{api_response}")
        print(f"ğŸ” ============================\n")
        
        try:
            # å°è¯•ç›´æ¥è§£æJSON
            try:
                print("ğŸ” å°è¯•ç›´æ¥è§£æJSON...")
                ner_data = json.loads(api_response.strip())
                print("âœ… ç›´æ¥è§£æJSONæˆåŠŸ")
            except json.JSONDecodeError as e:
                print(f"âŒ ç›´æ¥JSONè§£æå¤±è´¥: {str(e)}")
                # å°è¯•æå–JSONéƒ¨åˆ†
                import re
                
                # å¤šç§JSONæå–ç­–ç•¥
                patterns = [
                    r'\{[^{}]*"entities"[^{}]*:.*?\}',  # æœ€ä¸¥æ ¼çš„entitiesåŒ¹é…
                    r'\{.*?"entities".*?\}',            # å®½æ¾çš„entitiesåŒ¹é…
                    r'\{.*\}',                          # æœ€å®½æ¾çš„JSONåŒ¹é…
                ]
                
                ner_data = None
                for i, pattern in enumerate(patterns):
                    print(f"ğŸ” å°è¯•æ¨¡å¼ {i+1}: {pattern}")
                    json_match = re.search(pattern, api_response, re.DOTALL)
                    if json_match:
                        extracted_json = json_match.group()
                        print(f"ğŸ” æ¨¡å¼ {i+1} æå–åˆ°: {extracted_json[:200]}")
                        try:
                            ner_data = json.loads(extracted_json)
                            print(f"âœ… æ¨¡å¼ {i+1} è§£ææˆåŠŸ")
                            break
                        except json.JSONDecodeError as e2:
                            print(f"âŒ æ¨¡å¼ {i+1} è§£æå¤±è´¥: {str(e2)}")
                            continue
                
                if not ner_data:
                    print("âŒ æ‰€æœ‰JSONæå–æ¨¡å¼éƒ½å¤±è´¥ï¼Œå°è¯•JSONä¿®å¤...")
                    # å°è¯•ä¿®å¤ä¸å®Œæ•´çš„JSON
                    repaired_json = self._repair_incomplete_json(api_response)
                    if repaired_json:
                        try:
                            ner_data = json.loads(repaired_json)
                            print("âœ… JSONä¿®å¤æˆåŠŸ")
                        except json.JSONDecodeError as e3:
                            print(f"âŒ JSONä¿®å¤åä»ç„¶è§£æå¤±è´¥: {str(e3)}")
                            return ai_results
                    else:
                        print("âŒ JSONä¿®å¤å¤±è´¥")
                        return ai_results
            
            # æ£€æŸ¥entitieså­—æ®µ
            if 'entities' not in ner_data or not isinstance(ner_data['entities'], list):
                print(f"âŒ ç¼ºå°‘entitieså­—æ®µæˆ–æ ¼å¼é”™è¯¯")
                print(f"ğŸ“ è§£æåˆ°çš„æ•°æ®ç»“æ„: {type(ner_data)}")
                print(f"ğŸ“ æ•°æ®å†…å®¹: {ner_data}")
                return ai_results
            
            entities = ner_data['entities']
            print(f"âœ… æ‰¾åˆ°entitieså­—æ®µï¼ŒåŒ…å« {len(entities)} ä¸ªå®ä½“")
            
            # è½¬æ¢ä¸ºLabel Studioæ ¼å¼
            for i, entity in enumerate(entities):
                print(f"\nğŸ” å¤„ç†å®ä½“ {i+1}/{len(entities)}: {entity}")
                # éªŒè¯å¿…éœ€å­—æ®µ
                required_fields = ['text', 'start', 'end', 'label']
                missing_fields = [field for field in required_fields if field not in entity]
                if missing_fields:
                    print(f"   âŒ ç¼ºå°‘å¿…éœ€å­—æ®µ: {missing_fields}")
                    continue
                
                start = entity['start']
                end = entity['end']
                text = entity['text']
                original_label = entity['label']
                
                print(f"   ğŸ“ åŸå§‹å®ä½“: text='{text}', start={start}, end={end}, label='{original_label}'")
                
                # ä¸¥æ ¼éªŒè¯æ ‡ç­¾
                validated_label = validate_label(original_label)
                if not validated_label:
                    print(f"   âŒ æ ‡ç­¾éªŒè¯å¤±è´¥: '{original_label}' ä¸åœ¨æœ‰æ•ˆæ ‡ç­¾åˆ—è¡¨ä¸­")
                    print(f"   ğŸ“ æœ‰æ•ˆæ ‡ç­¾åˆ—è¡¨å‰10ä¸ª: {list(ENTITY_LABELS)[:10]}")
                    # å°è¯•æ ‡ç­¾æ˜ å°„ä¿®æ­£
                    mapped_label = self._map_invalid_label(original_label)
                    if mapped_label:
                        print(f"   ğŸ”§ å°è¯•æ ‡ç­¾æ˜ å°„: '{original_label}' â†’ '{mapped_label}'")
                        validated_label = mapped_label
                    else:
                        continue
                
                print(f"   âœ… æ ‡ç­¾éªŒè¯æˆåŠŸ: '{original_label}' â†’ '{validated_label}'")
                
                # ä½¿ç”¨éªŒè¯é€šè¿‡çš„æ ‡ç­¾
                label = validated_label
                
                # éªŒè¯ä½ç½®ä¿¡æ¯åŸºæœ¬åˆç†æ€§
                if not isinstance(start, int) or not isinstance(end, int) or start < 0:
                    print(f"   âŒ ä½ç½®ä¿¡æ¯æ ¼å¼é”™è¯¯: start={start}({type(start)}), end={end}({type(end)})")
                    continue
                
                print(f"   ğŸ” å¼€å§‹ä½ç½®ä¿®æ­£...")
                # å…ˆå°è¯•ä¿®æ­£ä½ç½®ï¼Œå†è¿›è¡ŒèŒƒå›´æ£€æŸ¥
                corrected_start, corrected_end, corrected_text = self._correct_entity_position(
                    original_text, text, start, end
                )
                
                # æ£€æŸ¥ä¿®æ­£åçš„ä½ç½®æ˜¯å¦åˆç†
                if corrected_start is None or corrected_end is None or corrected_text is None:
                    print(f"   âŒ ä½ç½®ä¿®æ­£å¤±è´¥: æ— æ³•åœ¨åŸæ–‡ä¸­æ‰¾åˆ°å®ä½“")
                    continue
                
                # éªŒè¯ä¿®æ­£åçš„ä½ç½®ä¸è¶…å‡ºæ–‡æœ¬é•¿åº¦
                if corrected_end > len(original_text) or corrected_start < 0:
                    print(f"   âŒ ä¿®æ­£åä½ç½®è¶…å‡ºèŒƒå›´: start={corrected_start}, end={corrected_end}, æ–‡æœ¬é•¿åº¦={len(original_text)}")
                    continue
                
                print(f"   âœ… ä½ç½®ä¿®æ­£æˆåŠŸ: start={corrected_start}, end={corrected_end}, text='{corrected_text}'")
                
                if corrected_text:
                    # éªŒè¯ä¿®æ­£åçš„å®ä½“æ˜¯å¦åˆç†
                    if self._is_valid_entity(corrected_text, validated_label):
                        result = {
                            "from_name": "label",
                            "to_name": "text",
                            "type": "labels",
                            "value": {
                                "start": corrected_start,
                                "end": corrected_end,
                                "text": corrected_text,
                                "labels": [label]
                            },
                            "source": "ai"  # æ ‡è®°æ¥æºä¸ºAI
                        }
                        
                        ai_results.append(result)
                        print(f"   âœ… å®ä½“æ·»åŠ æˆåŠŸ: '{corrected_text}' [{label}]")
                    else:
                        print(f"   âŒ å®ä½“éªŒè¯å¤±è´¥: '{corrected_text}' ä¸ç¬¦åˆ {validated_label} ç±»å‹è¦æ±‚")
            
            print(f"\nğŸ“Š AIå®ä½“è§£æç»“æœ: æˆåŠŸå¤„ç† {len(ai_results)} ä¸ªå®ä½“")
            return ai_results
            
        except Exception as e:
            print(f"âŒ AIå®ä½“è§£æå¼‚å¸¸: {str(e)}")
            return ai_results
    
    def _extract_regex_entities(self, original_text: str, existing_entities: List[Dict]) -> List[Dict]:
        """ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è¡¥å……è¯†åˆ«å®ä½“"""
        regex_results = []
        
        try:
            # è·å–å·²è¯†åˆ«å®ä½“çš„ä½ç½®èŒƒå›´ï¼Œé¿å…é‡å¤
            existing_ranges = set()
            for entity in existing_entities:
                value = entity.get('value', {})
                start = value.get('start', -1)
                end = value.get('end', -1)
                if start >= 0 and end > start:
                    # æ‰©å±•èŒƒå›´ä»¥é¿å…é‡å 
                    for pos in range(max(0, start-1), min(len(original_text), end+1)):
                        existing_ranges.add(pos)
            
            # ä»entity_configè·å–æ­£åˆ™æ¨¡å¼
            from entity_config import get_entity_config
            entity_config = get_entity_config()
            
            # éå†æ‰€æœ‰é…ç½®çš„å®ä½“ç±»å‹
            for label_key, config in entity_config.items():
                if 'patterns' not in config or not config['patterns']:
                    continue
                
                patterns = config['patterns']
                description = config['description']
                
                # å¯¹æ¯ä¸ªæ­£åˆ™æ¨¡å¼è¿›è¡ŒåŒ¹é…
                for pattern in patterns:
                    try:
                        import re
                        matches = re.finditer(pattern, original_text)
                        
                        for match in matches:
                            start = match.start()
                            end = match.end()
                            text = match.group()
                            
                            # æ£€æŸ¥æ˜¯å¦ä¸å·²è¯†åˆ«çš„å®ä½“é‡å 
                            overlapping = any(pos in existing_ranges for pos in range(start, end))
                            if overlapping:
                                continue
                            
                            # éªŒè¯å®ä½“æ˜¯å¦åˆç†
                            if self._is_valid_entity(text, label_key):
                                result = {
                                    "from_name": "label",
                                    "to_name": "text",
                                    "type": "labels",
                                    "value": {
                                        "start": start,
                                        "end": end,
                                        "text": text,
                                        "labels": [label_key]  # ä½¿ç”¨æ ‡ç­¾é”®åè€Œä¸æ˜¯description
                                    },
                                    "source": "regex"  # æ ‡è®°æ¥æºä¸ºæ­£åˆ™
                                }
                                
                                regex_results.append(result)
                                
                                # æ›´æ–°å·²è¯†åˆ«èŒƒå›´
                                for pos in range(start, end):
                                    existing_ranges.add(pos)
                                
                    except re.error:
                        continue
            
            return regex_results
            
        except Exception:
            return regex_results
    
    def _deduplicate_entities(self, entities: List[Dict]) -> List[Dict]:
        """å»é‡å’Œæ’åºå®ä½“"""
        
        # æŒ‰èµ·å§‹ä½ç½®æ’åº
        sorted_entities = sorted(entities, key=lambda x: x.get('value', {}).get('start', 0))
        
        # å»é‡é€»è¾‘ï¼šå¦‚æœä¸¤ä¸ªå®ä½“ä½ç½®é‡å è¶…è¿‡50%ï¼Œä¿ç•™ç½®ä¿¡åº¦é«˜çš„
        deduplicated = []
        
        for current in sorted_entities:
            current_value = current.get('value', {})
            current_start = current_value.get('start', 0)
            current_end = current_value.get('end', 0)
            current_text = current_value.get('text', '')
            current_source = current.get('source', 'unknown')
            
            # æ£€æŸ¥æ˜¯å¦ä¸å·²æ·»åŠ çš„å®ä½“é‡å 
            should_add = True
            for i, existing in enumerate(deduplicated):
                existing_value = existing.get('value', {})
                existing_start = existing_value.get('start', 0)
                existing_end = existing_value.get('end', 0)
                existing_text = existing_value.get('text', '')
                existing_source = existing.get('source', 'unknown')
                
                # è®¡ç®—é‡å åº¦
                overlap_start = max(current_start, existing_start)
                overlap_end = min(current_end, existing_end)
                
                if overlap_start < overlap_end:  # æœ‰é‡å 
                    overlap_length = overlap_end - overlap_start
                    current_length = current_end - current_start
                    existing_length = existing_end - existing_start
                    
                    # è®¡ç®—é‡å æ¯”ä¾‹ï¼ˆç›¸å¯¹äºè¾ƒçŸ­çš„å®ä½“ï¼‰
                    min_length = min(current_length, existing_length)
                    overlap_ratio = overlap_length / min_length if min_length > 0 else 0
                    
                    if overlap_ratio > 0.5:  # é‡å è¶…è¿‡50%
                        
                        # ä¼˜å…ˆçº§ï¼šAI > æ­£åˆ™ï¼Œé•¿å®ä½“ > çŸ­å®ä½“
                        should_replace = False
                        if current_source == 'ai' and existing_source == 'regex':
                            should_replace = True
                        elif current_source == existing_source and current_length > existing_length:
                            should_replace = True
                        
                        if should_replace:
                            deduplicated[i] = current
                        
                        should_add = False
                        break
            
            if should_add:
                deduplicated.append(current)
        
        # æœ€ç»ˆæŒ‰ä½ç½®æ’åº
        final_results = sorted(deduplicated, key=lambda x: x.get('value', {}).get('start', 0))
        
        # ç§»é™¤sourceæ ‡è®°ï¼ˆLabel Studioä¸éœ€è¦ï¼‰
        for result in final_results:
            result.pop('source', None)
        
        return final_results
    
    def _correct_entity_position(self, original_text: str, entity_text: str, start: int, end: int) -> tuple:
        """ä¿®æ­£å®ä½“ä½ç½®"""
        # é¦–å…ˆæ£€æŸ¥åŸå§‹ä½ç½®æ˜¯å¦æ­£ç¡®
        if start < len(original_text) and end <= len(original_text):
            extracted = original_text[start:end]
            if extracted == entity_text:
                return start, end, entity_text
        
        # æ¸…ç†å®ä½“æ–‡æœ¬ï¼ˆå»é™¤å¤šä½™ç©ºæ ¼å’Œæ ‡ç‚¹ï¼‰
        clean_entity = entity_text.strip()
        if not clean_entity:
            return None, None, None
        
        # åœ¨åŸæ–‡ä¸­æœç´¢å®ä½“æ–‡æœ¬
        try:
            # å°è¯•ç²¾ç¡®åŒ¹é…
            exact_start = original_text.find(clean_entity)
            if exact_start != -1:
                exact_end = exact_start + len(clean_entity)
                return exact_start, exact_end, clean_entity
            
            # å°è¯•æ¨¡ç³ŠåŒ¹é…ï¼ˆå»é™¤æ ‡ç‚¹ç¬¦å·ï¼‰
            import re
            clean_text_for_search = re.sub(r'[^\w\u4e00-\u9fff]', '', clean_entity)
            if len(clean_text_for_search) >= 2:  # è‡³å°‘2ä¸ªå­—ç¬¦æ‰è¿›è¡Œæ¨¡ç³ŠåŒ¹é…
                for i in range(len(original_text) - len(clean_text_for_search) + 1):
                    slice_text = original_text[i:i + len(clean_text_for_search)]
                    clean_slice = re.sub(r'[^\w\u4e00-\u9fff]', '', slice_text)
                    if clean_slice == clean_text_for_search:
                        return i, i + len(clean_text_for_search), slice_text
            
            # å¦‚æœè¿˜æ˜¯æ‰¾ä¸åˆ°ï¼Œå°è¯•éƒ¨åˆ†åŒ¹é…
            if len(clean_entity) >= 3:
                core_part = clean_entity[:min(len(clean_entity), 5)]  # å–å‰å‡ ä¸ªå­—ç¬¦ä½œä¸ºæ ¸å¿ƒ
                core_start = original_text.find(core_part)
                if core_start != -1:
                    # å°è¯•æ‰©å±•åŒ¹é…
                    extended_end = min(core_start + len(clean_entity) + 2, len(original_text))
                    extended_text = original_text[core_start:extended_end]
                    return core_start, extended_end, extended_text
            
        except Exception:
            pass
        
        return None, None, None
    
    def _is_valid_entity(self, text: str, label: str) -> bool:
        """ç®€åŒ–çš„å®ä½“éªŒè¯ï¼ˆåŸºç¡€è§„åˆ™éªŒè¯ï¼‰"""
        if not text or len(text.strip()) < 1:
            return False
        
        # å»é™¤é¦–å°¾æ ‡ç‚¹ç¬¦å·å’Œç©ºæ ¼
        clean_text = text.strip()
        
        # ä¸èƒ½åªæ˜¯æ ‡ç‚¹ç¬¦å·
        import re
        if re.match(r'^[^\w\u4e00-\u9fff]+$', clean_text):
            return False
        
        # åŸºç¡€é•¿åº¦éªŒè¯
        if len(clean_text) < 1:
            return False
        
        # éªŒè¯æ ‡ç­¾æ˜¯å¦æœ‰æ•ˆ
        if label not in ENTITY_LABELS:
            return False
        
        # ç‰¹æ®ŠéªŒè¯ï¼šå…³ç³»æ ‡ç­¾
        if label.endswith("å…³ç³»"):
            # å…³ç³»æ ‡ç­¾åº”è¯¥åŒ…å«åŠ¨è¯æˆ–è¿æ¥è¯
            relation_keywords = ['æ ¹æ®', 'ä¾æ®', 'æŒ‰ç…§', 'è´Ÿè´£', 'ä¸»ç®¡', 'ç®¡è¾–', 'å¯¼è‡´', 'é€ æˆ', 'å¼•èµ·', 
                               'ä¹‹å‰', 'ä¹‹å', 'åŒæ—¶', 'åŒ…æ‹¬', 'åŒ…å«', 'å±äº', 'å½±å“', 'æ³¢åŠ', 'åè°ƒ', 
                               'é…åˆ', 'æ‰§è¡Œ', 'å®æ–½', 'è¡¥å¿', 'èµ”å¿']
            
            if not any(keyword in clean_text for keyword in relation_keywords):
                # å¯¹äºå…³ç³»æ ‡ç­¾ï¼Œæ”¾å®½éªŒè¯ï¼Œåªè¦ä¸æ˜¯çº¯æ ‡ç‚¹å°±æ¥å—
                pass
        
        return True
    
    
    def fit(self, event, data, **kwargs):
        """è®­ç»ƒ/æ›´æ–°æ¨¡å‹"""
        self.set('my_data', 'updated_data')
        self.set('model_version', 'updated_version')
        print(f"âœ… æ¨¡å‹å·²æ›´æ–° ({event})")

