from typing import List, Dict, Optional
import json
import os
from openai import OpenAI
from label_studio_ml.model import LabelStudioMLBase
from label_studio_ml.response import ModelResponse


# ==================== å‘½åå®ä½“é…ç½® ====================
# ä»é…ç½®æ–‡ä»¶å¯¼å…¥å®ä½“é…ç½®
try:
    from entity_config import get_entity_config, get_entity_labels
    NER_ENTITY_CONFIG = get_entity_config()
    ENTITY_LABELS = get_entity_labels()
    print(f"âœ… ä»é…ç½®æ–‡ä»¶åŠ è½½äº† {len(ENTITY_LABELS)} ç§å®ä½“ç±»å‹")
except ImportError:
    # å¦‚æœé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
    print("âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
    NER_ENTITY_CONFIG = {
        "PER": {"description": "äººå", "examples": ["å¼ ä¸‰", "æå››"], "invalid_patterns": [r'å‘ç”Ÿ', r'èµ·ç«']},
        "LOC": {"description": "åœ°å", "examples": ["åŒ—äº¬", "ä¸Šæµ·"], "invalid_patterns": []},
        "ORG": {"description": "ç»„ç»‡", "examples": ["å…¬å¸", "å­¦æ ¡"], "invalid_patterns": []},
        "TIME": {"description": "æ—¶é—´", "examples": ["ä»Šå¤©", "æ˜å¤©"], "valid_patterns": [r'\d+å¹´', r'\d+æœˆ']},
        "EVENT": {"description": "äº‹ä»¶", "examples": ["ä¼šè®®", "æ´»åŠ¨", "ç«ç¾","èµ·ç«","æ‰‘ç­"], "invalid_patterns": []},
        "QUANTITY": {"description": "æ•°é‡", "examples": ["100ä¸ª", "50ä¸‡"], "valid_patterns": [r'\d+']},
    }
    ENTITY_LABELS = list(NER_ENTITY_CONFIG.keys())

# ç”Ÿæˆå®ä½“ç±»å‹è¯´æ˜æ–‡æœ¬
def get_entity_types_description():
    """ç”Ÿæˆå®ä½“ç±»å‹çš„è¯´æ˜æ–‡æœ¬"""
    descriptions = []
    for label, config in NER_ENTITY_CONFIG.items():
        descriptions.append(f"{label}({config['description']})")
    return "ã€".join(descriptions)

# ç”ŸæˆJSONæ ¼å¼ç¤ºä¾‹
def get_json_format_example():
    """ç”ŸæˆJSONæ ¼å¼ç¤ºä¾‹"""
    return """{{
  "entities": [
    {{
      "text": "å®ä½“æ–‡æœ¬",
      "start": èµ·å§‹ä½ç½®,
      "end": ç»“æŸä½ç½®,
      "label": "å®ä½“ç±»å‹"
    }}
  ]
}}"""


class NewModel(LabelStudioMLBase):
    """Custom ML Backend model
    """
    
    def setup(self):
        """Configure any parameters of your model here
        """
        self.set("model_version", "0.0.1")
        
        # é­”å¡”ç¤¾åŒºAPIé…ç½®
        self.api_key = os.getenv('MODELSCOPE_API_KEY', 'ms-d200fd06-f07f-4be8-a6a8-9ebf76dd103a')
        self.api_base_url = os.getenv('MODELSCOPE_API_URL', 'https://api-inference.modelscope.cn/v1')
        # æ¨èçš„æ¨¡å‹é€‰æ‹©ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰:
        # 1. Qwen/Qwen3-235B-A22B-Instruct-2507 - æœ€é€‚åˆç»“æ„åŒ–è¾“å‡º
        # 2. Qwen/Qwen3-Coder-480B-A35B-Instruct - ä»£ç å’Œç»“æ„åŒ–æ•°æ®å¤„ç†
        # 3. Qwen/Qwen3-235B-A22B-Thinking-2507 - æ€ç»´é“¾æ¨¡å‹ï¼ˆè¾“å‡ºæ ¼å¼å¤æ‚ï¼‰
        self.model_name = "Qwen/Qwen3-235B-A22B-Instruct-2507"  # æ›´é€‚åˆNERä»»åŠ¡
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        if self.api_key:
            try:
                self.client = OpenAI(
                    base_url=self.api_base_url,
                    api_key=self.api_key
                )
                print(f"âœ… æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ: {self.model_name}")
            except Exception as e:
                print(f"âŒ å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
                self.client = None
        else:
            print(f"âš ï¸ è¯·è®¾ç½®MODELSCOPE_API_KEYç¯å¢ƒå˜é‡")
            self.client = None
        
        # æ£€æŸ¥APIè¿æ¥
        self._check_api_connection()
        
        # æ˜¾ç¤ºå½“å‰é…ç½®çš„å®ä½“æ ‡ç­¾
        self._show_entity_config()
        
    def _check_api_connection(self):
        """æ£€æŸ¥é­”å¡”ç¤¾åŒºAPIè¿æ¥"""
        if not self.client:
            print(f"âŒ å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            return
        
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[{"role": "user", "content": "test"}],
                max_tokens=5,
                temperature=0.1
            )
            print(f"âœ… APIè¿æ¥æˆåŠŸ")
        except Exception as e:
            print(f"âŒ APIè¿æ¥å¤±è´¥: {str(e)[:100]}")
    
    def _show_entity_config(self):
        """æ˜¾ç¤ºå½“å‰é…ç½®çš„å®ä½“æ ‡ç­¾"""
        print(f"\nğŸ“‹ å½“å‰æ”¯æŒçš„å‘½åå®ä½“ç±»å‹:")
        print("="*50)
        
        for i, (label, config) in enumerate(NER_ENTITY_CONFIG.items(), 1):
            print(f"  {i}. {label} - {config['description']}")
            if config['examples']:
                examples = "ã€".join(config['examples'][:3])
                print(f"     ç¤ºä¾‹: {examples}")
        
        print(f"\nğŸ’¡ å¦‚éœ€ä¿®æ”¹å®ä½“ç±»å‹ï¼Œè¯·ç¼–è¾‘model.pyé¡¶éƒ¨çš„NER_ENTITY_CONFIGé…ç½®")
        print("="*50)
            


    def predict(self, tasks: List[Dict], context: Optional[Dict] = None, **kwargs) -> ModelResponse:
        """ å‘½åå®ä½“è¯†åˆ«é¢„æµ‹
            :param tasks: Label Studio tasks in JSON format
            :param context: Label Studio context in JSON format
            :return: ModelResponse with predictions
        """
        predictions = []
        
        for i, task in enumerate(tasks):
            try:
                prediction = self._process_single_task(task)
                if prediction:
                    predictions.append(prediction)
                else:
                    predictions.append({
                        "model_version": self.get("model_version"),
                        "score": 0.0,
                        "result": []
                    })
            except Exception as e:
                print(f"âŒ ä»»åŠ¡ {i+1} å¤„ç†å¤±è´¥: {e}")
                predictions.append({
                    "model_version": self.get("model_version"),
                    "score": 0.0,
                    "result": []
                })
        
        # è¾“å‡ºæœ€ç»ˆè¿”å›çš„JSONç»“æœ
        print("\n" + "="*60)
        print("ğŸ“¤ æœ€ç»ˆè¿”å›çš„JSONç»“æœ:")
        print("="*60)
        for i, prediction in enumerate(predictions):
            print(f"\n--- é¢„æµ‹ç»“æœ {i+1} ---")
            print(json.dumps(prediction, indent=2, ensure_ascii=False))
        print("\n" + "="*60)
        
        return ModelResponse(predictions=predictions)
    
    def _process_single_task(self, task: Dict) -> Optional[Dict]:
        """å¤„ç†å•ä¸ªä»»åŠ¡"""
        task_data = task.get('data', {})
        
        # æå–æ–‡æœ¬å†…å®¹
        text_content = ""
        text_keys = ['text', 'content', 'prompt', 'question', 'description', 'query']
        
        for key, value in task_data.items():
            if isinstance(value, str) and key in text_keys:
                text_content = value
                break
        
        if not text_content:
            return None
        
        # æ„å»ºNERæç¤ºè¯ï¼ˆä½¿ç”¨é…ç½®åŒ–çš„å®ä½“æ ‡ç­¾ï¼‰
        entity_types_desc = get_entity_types_description()
        json_format = get_json_format_example()
        
        # ç”Ÿæˆç¤ºä¾‹
        examples_text = ""
        for label, config in NER_ENTITY_CONFIG.items():
            examples = "ã€".join(config['examples'][:3])  # å–å‰3ä¸ªç¤ºä¾‹
            examples_text += f"   {label}({config['description']}): {examples}\n"
        
        prompt = f"""è¯·å¯¹ä»¥ä¸‹æ–‡æœ¬è¿›è¡Œå‘½åå®ä½“è¯†åˆ«ï¼Œè¯†åˆ«å‡ºä»¥ä¸‹ç±»å‹çš„å®ä½“ï¼š

æ–‡æœ¬å†…å®¹ï¼š
{text_content}

å®ä½“ç±»å‹è¯´æ˜ï¼š
{examples_text}
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ç»“æœï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–å…¶ä»–å†…å®¹ï¼š
{json_format}

æ”¯æŒçš„å®ä½“ç±»å‹ï¼š{entity_types_desc}"""
        
        # è°ƒç”¨API
        api_response = self._call_modelscope_api(prompt)
        
        if api_response:
            return self._format_prediction(api_response, task)
        
        return None
    
    def _call_modelscope_api(self, prompt: str) -> Optional[str]:
        """è°ƒç”¨é­”å¡”ç¤¾åŒºAPI"""
        if not self.client:
            print("âŒ OpenAIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            return None
        
        print(f"ğŸ“¤ å‘é€APIè¯·æ±‚...")
        print(f"   æ¨¡å‹: {self.model_name}")
        print(f"   æç¤ºè¯é•¿åº¦: {len(prompt)} å­—ç¬¦")
        
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": "You are a helpful assistant specialized in Named Entity Recognition. Always respond with valid JSON format."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=2000,
                temperature=0.1,
                top_p=0.9,
                stream=False
            )
            
            print(f"ğŸ“¥ æ”¶åˆ°APIå“åº”")
            
            if response.choices and len(response.choices) > 0:
                content = response.choices[0].message.content
                print(f"âœ… å“åº”å†…å®¹é•¿åº¦: {len(content) if content else 0} å­—ç¬¦")
                if content:
                    print(f"ğŸ“‹ å“åº”å†…å®¹é¢„è§ˆ: {content[:300]}{'...' if len(content) > 300 else ''}")
                return content
            else:
                print("âŒ APIå“åº”ä¸­æ²¡æœ‰choices")
                return None
                
        except Exception as e:
            print(f"âŒ APIè°ƒç”¨å¤±è´¥: {str(e)}")
            print(f"   å®Œæ•´é”™è¯¯ä¿¡æ¯: {repr(e)}")
            return None
    
    def _format_prediction(self, api_response: str, task: Dict) -> Dict:
        """æ ¼å¼åŒ–é¢„æµ‹ç»“æœä¸ºLabel Studioæ ¼å¼"""
        print(f"\nğŸ”„ æ ¼å¼åŒ–é¢„æµ‹ç»“æœ:")
        print(f"   APIå“åº”é•¿åº¦: {len(api_response)} å­—ç¬¦")
        print(f"   APIå“åº”å†…å®¹: {api_response[:200]}{'...' if len(api_response) > 200 else ''}")
        
        prediction = {
            "model_version": self.get("model_version"),
            "score": 0.95,
            "result": []
        }
        
        # å°è¯•è§£æNERç»“æœ
        ner_results = self._parse_ner_response(api_response, task)
        if ner_results:
            prediction["result"] = ner_results
            print(f"âœ… NERè§£ææˆåŠŸï¼Œè¯†åˆ«åˆ° {len(ner_results)} ä¸ªå®ä½“")
            for i, result in enumerate(ner_results):
                entity = result.get('value', {})
                text = entity.get('text', '')
                labels = entity.get('labels', [])
                start = entity.get('start', 0)
                end = entity.get('end', 0)
                print(f"   å®ä½“ {i+1}: [{text}] -> {labels} ({start}-{end})")
            return prediction
        
        # å¤‡ç”¨æ–¹æ¡ˆï¼šè¿”å›åŸå§‹æ–‡æœ¬
        print("âš ï¸ NERè§£æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬æ ¼å¼")
        prediction["result"].append({
            "from_name": "prediction",
            "to_name": "text",
            "type": "textarea",
            "value": {
                "text": [api_response]
            }
        })
        
        return prediction
    
    def _parse_ner_response(self, api_response: str, task: Dict) -> Optional[List[Dict]]:
        """è§£æAIè¿”å›çš„å‘½åå®ä½“è¯†åˆ«JSONç»“æœ"""
        print(f"\nğŸ” å¼€å§‹è§£æNERå“åº”...")
        
        if not api_response or not api_response.strip():
            print("âŒ APIå“åº”ä¸ºç©º")
            return None
        
        try:
            # å°è¯•ç›´æ¥è§£æJSON
            try:
                print("ğŸ”§ å°è¯•ç›´æ¥JSONè§£æ...")
                ner_data = json.loads(api_response.strip())
                print("âœ… ç›´æ¥JSONè§£ææˆåŠŸ")
            except json.JSONDecodeError as e:
                print(f"âš ï¸ ç›´æ¥JSONè§£æå¤±è´¥: {e}")
                # å°è¯•æå–JSONéƒ¨åˆ†
                import re
                print("ğŸ”§ å°è¯•æå–JSONç‰‡æ®µ...")
                
                # å¤šç§JSONæå–ç­–ç•¥
                patterns = [
                    r'\{[^{}]*"entities"[^{}]*:.*?\}',  # æœ€ä¸¥æ ¼çš„entitiesåŒ¹é…
                    r'\{.*?"entities".*?\}',            # å®½æ¾çš„entitiesåŒ¹é…
                    r'\{.*\}',                          # æœ€å®½æ¾çš„JSONåŒ¹é…
                ]
                
                ner_data = None
                for i, pattern in enumerate(patterns):
                    json_match = re.search(pattern, api_response, re.DOTALL)
                    if json_match:
                        try:
                            ner_data = json.loads(json_match.group())
                            print(f"âœ… JSONæå–æˆåŠŸ (ç­–ç•¥ {i+1})")
                            break
                        except json.JSONDecodeError:
                            print(f"âš ï¸ JSONæå–ç­–ç•¥ {i+1} å¤±è´¥")
                            continue
                
                if not ner_data:
                    print("âŒ æ‰€æœ‰JSONæå–ç­–ç•¥éƒ½å¤±è´¥")
                    print(f"ğŸ“„ åŸå§‹å“åº”å†…å®¹: {api_response}")
                    return None
            
            # æ£€æŸ¥entitieså­—æ®µ
            if 'entities' not in ner_data or not isinstance(ner_data['entities'], list):
                return None
            
            entities = ner_data['entities']
            
            # è·å–åŸå§‹æ–‡æœ¬
            task_data = task.get('data', {})
            original_text = ""
            for key in ['text', 'content', 'prompt', 'question', 'description', 'query']:
                if key in task_data and isinstance(task_data[key], str):
                    original_text = task_data[key]
                    break
            
            if not original_text:
                return None
            
            print(f"ğŸ“ åŸå§‹æ–‡æœ¬: {original_text}")
            print(f"ğŸ“ åŸå§‹æ–‡æœ¬é•¿åº¦: {len(original_text)} å­—ç¬¦")
            
            # è½¬æ¢ä¸ºLabel Studioæ ¼å¼
            results = []
            for i, entity in enumerate(entities):
                # éªŒè¯å¿…éœ€å­—æ®µ
                if not all(key in entity for key in ['text', 'start', 'end', 'label']):
                    print(f"   âš ï¸ å®ä½“ {i+1} ç¼ºå°‘å¿…éœ€å­—æ®µï¼Œè·³è¿‡")
                    continue
                
                start = entity['start']
                end = entity['end']
                text = entity['text']
                label = entity['label']
                
                print(f"\nğŸ” å¤„ç†å®ä½“ {i+1}: {entity}")
                
                # éªŒè¯ä½ç½®ä¿¡æ¯åŸºæœ¬åˆç†æ€§
                if not isinstance(start, int) or not isinstance(end, int) or start < 0 or end <= start:
                    print(f"   âŒ å®ä½“ {i+1} ä½ç½®ä¿¡æ¯æ— æ•ˆ (start={start}, end={end})ï¼Œè·³è¿‡")
                    continue
                
                # éªŒè¯ä½ç½®ä¸è¶…å‡ºæ–‡æœ¬é•¿åº¦
                if end > len(original_text):
                    print(f"   âŒ å®ä½“ {i+1} ç»“æŸä½ç½®è¶…å‡ºæ–‡æœ¬é•¿åº¦ (end={end}, text_len={len(original_text)})ï¼Œè·³è¿‡")
                    continue
                
                # æå–å®é™…æ–‡æœ¬è¿›è¡ŒéªŒè¯å’Œä¿®æ­£
                extracted_text = original_text[start:end]
                
                print(f"   ğŸ“‹ AIæä¾›çš„æ–‡æœ¬: '{text}'")
                print(f"   ğŸ“‹ ä½ç½®æå–çš„æ–‡æœ¬: '{extracted_text}'")
                print(f"   ğŸ“ ä½ç½®: {start}-{end}")
                
                # å¦‚æœæ–‡æœ¬ä¸åŒ¹é…ï¼Œå°è¯•ä¿®æ­£
                corrected_start, corrected_end, corrected_text = self._correct_entity_position(
                    original_text, text, start, end
                )
                
                if corrected_text:
                    # éªŒè¯ä¿®æ­£åçš„å®ä½“æ˜¯å¦åˆç†ï¼ˆé•¿åº¦ä¸èƒ½å¤ªçŸ­ï¼Œä¸èƒ½åªæ˜¯æ ‡ç‚¹ç¬¦å·ï¼‰
                    if self._is_valid_entity(corrected_text, label):
                        result = {
                            "from_name": "label",
                            "to_name": "text",
                            "type": "labels",
                            "value": {
                                "start": corrected_start,
                                "end": corrected_end,
                                "text": corrected_text,
                                "labels": [label]
                            }
                        }
                        
                        results.append(result)
                        print(f"   âœ… å®ä½“ {i+1} å·²æ·»åŠ : '{corrected_text}' -> {label} ({corrected_start}-{corrected_end})")
                    else:
                        print(f"   âŒ å®ä½“ {i+1} éªŒè¯å¤±è´¥: '{corrected_text}' ä¸æ˜¯æœ‰æ•ˆçš„ {label} å®ä½“")
                else:
                    print(f"   âŒ å®ä½“ {i+1} æ— æ³•ä¿®æ­£ä½ç½®ï¼Œè·³è¿‡")
            
            print(f"\nğŸ“Š æœ€ç»ˆæœ‰æ•ˆå®ä½“æ•°é‡: {len(results)}")
            return results if results else None
            
        except Exception as e:
            print(f"âŒ è§£æNERç»“æœå¼‚å¸¸: {e}")
            return None
    
    def _correct_entity_position(self, original_text: str, entity_text: str, start: int, end: int) -> tuple:
        """ä¿®æ­£å®ä½“ä½ç½®"""
        # é¦–å…ˆæ£€æŸ¥åŸå§‹ä½ç½®æ˜¯å¦æ­£ç¡®
        if start < len(original_text) and end <= len(original_text):
            extracted = original_text[start:end]
            if extracted == entity_text:
                return start, end, entity_text
        
        # æ¸…ç†å®ä½“æ–‡æœ¬ï¼ˆå»é™¤å¤šä½™ç©ºæ ¼å’Œæ ‡ç‚¹ï¼‰
        clean_entity = entity_text.strip()
        if not clean_entity:
            return None, None, None
        
        # åœ¨åŸæ–‡ä¸­æœç´¢å®ä½“æ–‡æœ¬
        try:
            # å°è¯•ç²¾ç¡®åŒ¹é…
            exact_start = original_text.find(clean_entity)
            if exact_start != -1:
                exact_end = exact_start + len(clean_entity)
                print(f"   ğŸ”§ ç²¾ç¡®åŒ¹é…ä¿®æ­£: '{clean_entity}' ({exact_start}-{exact_end})")
                return exact_start, exact_end, clean_entity
            
            # å°è¯•æ¨¡ç³ŠåŒ¹é…ï¼ˆå»é™¤æ ‡ç‚¹ç¬¦å·ï¼‰
            import re
            clean_text_for_search = re.sub(r'[^\w\u4e00-\u9fff]', '', clean_entity)
            if len(clean_text_for_search) >= 2:  # è‡³å°‘2ä¸ªå­—ç¬¦æ‰è¿›è¡Œæ¨¡ç³ŠåŒ¹é…
                for i in range(len(original_text) - len(clean_text_for_search) + 1):
                    slice_text = original_text[i:i + len(clean_text_for_search)]
                    clean_slice = re.sub(r'[^\w\u4e00-\u9fff]', '', slice_text)
                    if clean_slice == clean_text_for_search:
                        print(f"   ğŸ”§ æ¨¡ç³ŠåŒ¹é…ä¿®æ­£: '{slice_text}' ({i}-{i + len(clean_text_for_search)})")
                        return i, i + len(clean_text_for_search), slice_text
            
            # å¦‚æœè¿˜æ˜¯æ‰¾ä¸åˆ°ï¼Œå°è¯•éƒ¨åˆ†åŒ¹é…
            if len(clean_entity) >= 3:
                core_part = clean_entity[:min(len(clean_entity), 5)]  # å–å‰å‡ ä¸ªå­—ç¬¦ä½œä¸ºæ ¸å¿ƒ
                core_start = original_text.find(core_part)
                if core_start != -1:
                    # å°è¯•æ‰©å±•åŒ¹é…
                    extended_end = min(core_start + len(clean_entity) + 2, len(original_text))
                    extended_text = original_text[core_start:extended_end]
                    print(f"   ğŸ”§ éƒ¨åˆ†åŒ¹é…ä¿®æ­£: '{extended_text}' ({core_start}-{extended_end})")
                    return core_start, extended_end, extended_text
            
        except Exception as e:
            print(f"   âŒ ä½ç½®ä¿®æ­£å¤±è´¥: {e}")
        
        return None, None, None
    
    def _is_valid_entity(self, text: str, label: str) -> bool:
        """éªŒè¯å®ä½“æ˜¯å¦åˆç†ï¼ˆä½¿ç”¨é…ç½®åŒ–çš„éªŒè¯è§„åˆ™ï¼‰"""
        if not text or len(text.strip()) < 1:
            return False
        
        # å»é™¤é¦–å°¾æ ‡ç‚¹ç¬¦å·å’Œç©ºæ ¼
        clean_text = text.strip()
        
        # ä¸èƒ½åªæ˜¯æ ‡ç‚¹ç¬¦å·
        import re
        if re.match(r'^[^\w\u4e00-\u9fff]+$', clean_text):
            return False
        
        # é•¿åº¦éªŒè¯
        if len(clean_text) < 1:
            return False
        
        # æ£€æŸ¥æ ‡ç­¾æ˜¯å¦åœ¨é…ç½®ä¸­
        if label not in NER_ENTITY_CONFIG:
            return True  # å¦‚æœä¸åœ¨é…ç½®ä¸­ï¼Œé»˜è®¤é€šè¿‡
        
        config = NER_ENTITY_CONFIG[label]
        
        # æ£€æŸ¥æ— æ•ˆæ¨¡å¼ï¼ˆå¦‚æœé…ç½®äº†ï¼‰
        if 'invalid_patterns' in config:
            for pattern in config['invalid_patterns']:
                if re.search(pattern, clean_text):
                    return False
        
        # æ£€æŸ¥æœ‰æ•ˆæ¨¡å¼ï¼ˆå¦‚æœé…ç½®äº†ï¼‰
        if 'valid_patterns' in config:
            valid_patterns = config['valid_patterns']
            has_valid_pattern = any(re.search(pattern, clean_text) for pattern in valid_patterns)
            if not has_valid_pattern and len(clean_text) < 4:
                return False
        
        return True
    
    def _extract_choice(self, response: str, choices: List[str]) -> Optional[str]:
        """ä»å“åº”ä¸­æå–æœ€åŒ¹é…çš„é€‰æ‹©"""
        response_lower = response.lower()
        for choice in choices:
            if choice.lower() in response_lower:
                return choice
        return choices[0] if choices else None
    
    def fit(self, event, data, **kwargs):
        """
        è®­ç»ƒ/æ›´æ–°æ¨¡å‹
        :param event: äº‹ä»¶ç±»å‹ ('ANNOTATION_CREATED', 'ANNOTATION_UPDATED', 'START_TRAINING')
        :param data: äº‹ä»¶æ•°æ®
        """
        # æ›´æ–°ç¼“å­˜æ•°æ®
        old_data = self.get('my_data')
        self.set('my_data', 'updated_data')
        self.set('model_version', 'updated_version')
        print(f"âœ… æ¨¡å‹å·²æ›´æ–° (äº‹ä»¶: {event})")

